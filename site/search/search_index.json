{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"/]+|(?!\\b)(?=[A-Z][a-z])|\\.(?!\\d)|&[lg]t;","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"\ud83c\udfe0 My Kubernetes Homelab Platform","text":"<p>\ud83d\ude80 A modern, extensible homelab powered by Kubernetes</p> <p>This repository contains the configuration for a comprehensive Kubernetes-based homelab platform running on k3s. The system is designed as a modular, scalable foundation for home automation, media management, personal cloud services, and infrastructure experimentation. Built with cloud-native principles, it enables easy addition of new services while maintaining security and reliability.</p> <p>Design Philosophy</p> <p>This setup embraces the Infrastructure as Code (IaC) paradigm, using declarative configurations to ensure reproducibility and maintainability. The architecture follows cloud-native principles while being optimized for home deployment.</p>"},{"location":"#-platform-capabilities","title":"\u2728 Platform Capabilities","text":"<ul> <li> <p> Enterprise-Grade Infrastructure</p> </li> <li> <p>Production-ready Kubernetes platform</p> </li> <li>High availability configuration options</li> <li>Declarative infrastructure management</li> <li> <p>Multi-environment support (staging/production)</p> </li> <li> <p> Personal Cloud Services</p> </li> <li> <p>File sync and sharing (Nextcloud)</p> </li> <li>Photo management with AI features (Immich)</li> <li>Recipe organization and meal planning (Tandoor)</li> <li> <p>Expandable for additional services</p> </li> <li> <p> Media Center Functionality</p> </li> <li> <p>Automated content management</p> </li> <li>Streaming server capabilities</li> <li>Multi-device access</li> <li> <p>Quality optimization</p> </li> <li> <p> Zero-Trust Security Model</p> </li> <li> <p>End-to-end encryption for all services</p> </li> <li>Certificate-based authentication</li> <li>Network policy enforcement</li> <li> <p>Secrets management</p> </li> <li> <p> Modern DevOps Practices</p> </li> <li> <p>GitOps-based deployment</p> </li> <li>Continuous integration/deployment</li> <li>Infrastructure as Code</li> <li>Automated operations</li> <li> <p>Automated dependency management (Renovate)</p> </li> <li> <p> Enterprise Monitoring</p> </li> <li> <p>Full observability stack (Prometheus, Grafana, Loki, Jaeger)</p> </li> <li>Pre-configured Grafana dashboards for all services</li> <li>ServiceMonitor-based metrics collection</li> <li>Distributed tracing</li> <li>Centralized logging</li> <li> <p>Performance analytics</p> </li> <li> <p> Advanced Networking</p> </li> <li> <p>Software-defined networking</p> </li> <li>Load balancing</li> <li>Ingress control</li> <li> <p>Service mesh ready</p> </li> <li> <p> Platform Extensibility</p> </li> <li> <p>Modular architecture</p> </li> <li>Easy service integration</li> <li>Custom resource definitions</li> <li> <p>API-driven management</p> </li> <li> <p> Mobile-friendly Interface</p> </li> <li> <p>Responsive design across all services</p> </li> <li>Native app support where available</li> <li>Progressive Web App capabilities</li> </ul>"},{"location":"#quick-navigation","title":"Quick Navigation","text":"<ul> <li> <p> Getting Started</p> <p>Learn how to deploy and configure the platform</p> </li> <li> <p>:material-architecture:{ .lg .middle } Architecture</p> <p>Understand the system design and components</p> </li> <li> <p> Services</p> <p>Explore the available services and applications</p> </li> <li> <p> Configuration</p> <p>Manage and customize your deployment</p> </li> </ul>"},{"location":"#-credits","title":"\ud83d\udc4f Credits","text":"<p>This project builds upon htk8s, enhanced with additional features and modern tooling.</p>"},{"location":"#abbreviations","title":"Abbreviations","text":""},{"location":"architecture/","title":"Architecture","text":"<p>Understanding the architecture of the homelab platform is essential for effective operation, customization, and troubleshooting.</p>"},{"location":"architecture/#architecture-overview","title":"Architecture Overview","text":"<p>The platform is built on a microservices architecture, leveraging Kubernetes orchestration for scalability, reliability, and maintainability. Each component is designed to be modular, allowing for independent updates and scaling.</p>"},{"location":"architecture/#key-design-principles","title":"Key Design Principles","text":"<p>Infrastructure as Code</p> <p>All infrastructure is defined declaratively using Kubernetes manifests and Kustomize overlays. This ensures reproducibility and version control.</p> <p>GitOps Workflow</p> <p>Changes are applied through Git commits, with ArgoCD automatically synchronizing the cluster state with the repository.</p> <p>Security First</p> <p>Multiple layers of security protect services and data, from network policies to encrypted secrets and TLS termination.</p> <p>Observability</p> <p>Comprehensive monitoring, logging, and tracing provide full visibility into system behavior and performance.</p>"},{"location":"architecture/#architecture-deep-dive","title":"Architecture Deep Dive","text":"<p>Explore the detailed architecture documentation:</p> <ul> <li> <p> Overview</p> <p>High-level system design and architecture diagrams</p> </li> <li> <p> Kubernetes Infrastructure</p> <p>k3s cluster configuration and resource management</p> </li> <li> <p> Networking</p> <p>Ingress, load balancing, and certificate management</p> </li> <li> <p> Storage</p> <p>Persistent storage and volume management</p> </li> <li> <p> Security</p> <p>Security layers and protection mechanisms</p> </li> <li> <p> Configuration Management</p> <p>GitOps and Kustomize-based configuration</p> </li> <li> <p> CI/CD</p> <p>Continuous integration and deployment pipelines</p> </li> <li> <p> Observability</p> <p>Monitoring, logging, and distributed tracing</p> </li> </ul>"},{"location":"architecture/#architecture-diagrams","title":"Architecture Diagrams","text":""},{"location":"architecture/#system-overview","title":"System Overview","text":"<p>The system employs a layered architecture:</p> <pre><code>graph TB\n    subgraph \"External Access\"\n        Client[Clients]\n        DNS[DNS/Cloudflare]\n    end\n\n    subgraph \"Ingress Layer\"\n        Traefik[Traefik]\n        CertManager[cert-manager]\n        MetalLB[MetalLB]\n    end\n\n    subgraph \"Application Layer\"\n        Apps[Applications]\n        Media[Media Services]\n        Cloud[Personal Cloud]\n    end\n\n    subgraph \"Data Layer\"\n        PG[PostgreSQL]\n        Redis[Redis]\n        Valkey[Valkey]\n        Storage[Persistent Storage]\n    end\n\n    subgraph \"Observability\"\n        Prometheus[Prometheus]\n        Grafana[Grafana]\n        Loki[Loki]\n    end\n\n    Client --&gt; DNS\n    DNS --&gt; MetalLB\n    MetalLB --&gt; Traefik\n    Traefik --&gt; Apps\n    Traefik --&gt; Media\n    Traefik --&gt; Cloud\n    Apps --&gt; PG\n    Apps --&gt; Redis\n    Apps --&gt; Valkey\n    Apps --&gt; Storage\n    CertManager --&gt; Traefik\n\n    Prometheus --&gt; Grafana\n    Loki --&gt; Grafana\n    Apps -.-&gt; | metrics | Prometheus\n    Apps -.-&gt; | logs | Loki</code></pre>"},{"location":"architecture/#namespace-organization","title":"Namespace Organization","text":"<p>The platform is organized into three dedicated namespaces:</p> <pre><code>graph LR\n    subgraph \"htpc\"\n        Media[Media Services]\n    end\n\n    subgraph \"infra\"\n        Core[Core Infrastructure]\n    end\n\n    subgraph \"utils\"\n        Utils[Utility Applications]\n    end</code></pre>"},{"location":"architecture/#next-steps","title":"Next Steps","text":"<p>Dive deeper into specific architectural components:</p> <ul> <li>Learn about Kubernetes Infrastructure for cluster details</li> <li>Explore Networking for ingress and routing</li> <li>Review Security for protection layers</li> <li>Understand Observability for monitoring</li> </ul>"},{"location":"architecture/#abbreviations","title":"Abbreviations","text":""},{"location":"architecture/cicd/","title":"CI/CD Architecture","text":"<p>The continuous integration and deployment pipeline ensures reliable and automated delivery of infrastructure changes.</p>"},{"location":"architecture/cicd/#pipeline-overview","title":"Pipeline Overview","text":"<p>The CI/CD pipeline is designed for reliability, automation, and GitOps principles.</p>"},{"location":"architecture/cicd/#pipeline-stages","title":"Pipeline Stages","text":"Stage Tool Purpose Implementation Details Lint yamllint YAML Validation - Syntax checking- Style enforcement- Custom rules Test kubeconform Manifest Validation - Schema validation- Version checking- Resource validation Build kustomize Generate install.yaml - Overlay composition- Resource generation- Configuration merging Deploy kubectl Apply to Cluster - Rolling updates- Health checking- Rollback capability"},{"location":"architecture/cicd/#pipeline-design-principles","title":"Pipeline Design Principles","text":""},{"location":"architecture/cicd/#1-automation-first","title":"1. Automation First","text":""},{"location":"architecture/cicd/#zero-touch-deployment","title":"Zero-Touch Deployment","text":"<ul> <li>Automatic deployment on Git push</li> <li>No manual intervention required</li> <li>Consistent deployment process</li> <li>Reduced human error</li> </ul>"},{"location":"architecture/cicd/#automated-testing","title":"Automated Testing","text":"<ul> <li>Syntax validation</li> <li>Schema validation</li> <li>Security scanning</li> <li>Configuration testing</li> </ul>"},{"location":"architecture/cicd/#self-healing-capabilities","title":"Self-Healing Capabilities","text":"<ul> <li>Automatic rollback on failure</li> <li>Health check monitoring</li> <li>Pod restart on crash</li> <li>ArgoCD auto-sync</li> </ul>"},{"location":"architecture/cicd/#continuous-verification","title":"Continuous Verification","text":"<ul> <li>Post-deployment health checks</li> <li>Metrics monitoring</li> <li>Log analysis</li> <li>Alert generation</li> </ul>"},{"location":"architecture/cicd/#2-quality-gates","title":"2. Quality Gates","text":""},{"location":"architecture/cicd/#syntax-validation","title":"Syntax Validation","text":"<p>Use yamllint with a configuration file to validate YAML syntax and enforce style rules across base and overlay directories.</p>"},{"location":"architecture/cicd/#configuration-testing","title":"Configuration Testing","text":"<p>Validate Kubernetes resource schemas using kubeconform in strict mode to catch configuration errors.</p>"},{"location":"architecture/cicd/#resource-validation","title":"Resource Validation","text":"<p>Use kubectl's server-side dry-run to validate resources against the actual cluster API.</p>"},{"location":"architecture/cicd/#3-deployment-strategy","title":"3. Deployment Strategy","text":""},{"location":"architecture/cicd/#recreate-strategy","title":"Recreate Strategy","text":"<p>Most deployments in this platform use the <code>Recreate</code> strategy, which:</p> <ul> <li>Terminates all existing pods before creating new ones</li> <li>Ensures only one version runs at a time</li> <li>Prevents resource conflicts for stateful applications</li> <li>Suitable for applications requiring exclusive access to persistent volumes</li> </ul> <p>Strategy Choice</p> <p>The Recreate strategy is used for stateful applications like Tandoor, media services, and utilities that require exclusive access to persistent storage. This ensures data consistency and prevents file locking issues.</p>"},{"location":"architecture/cicd/#automated-rollbacks","title":"Automated Rollbacks","text":"<p>Kubernetes Deployments support automatic rollbacks by maintaining revision history (default: 10 revisions). Rollback can be triggered manually using <code>kubectl rollout undo</code>.</p>"},{"location":"architecture/cicd/#4-monitoring-integration","title":"4. Monitoring Integration","text":""},{"location":"architecture/cicd/#deployment-metrics","title":"Deployment Metrics","text":"<ul> <li>Deployment duration</li> <li>Success/failure rate</li> <li>Rollback frequency</li> <li>Resource utilization</li> </ul>"},{"location":"architecture/cicd/#performance-tracking","title":"Performance Tracking","text":"<ul> <li>Response time trends</li> <li>Error rate changes</li> <li>Resource consumption</li> <li>User impact metrics</li> </ul>"},{"location":"architecture/cicd/#error-reporting","title":"Error Reporting","text":"<ul> <li>Deployment failures</li> <li>Application errors</li> <li>Infrastructure issues</li> <li>Security violations</li> </ul>"},{"location":"architecture/cicd/#alert-generation","title":"Alert Generation","text":"<ul> <li>Slack notifications</li> <li>Email alerts</li> <li>PagerDuty integration</li> <li>Webhook triggers</li> </ul>"},{"location":"architecture/cicd/#automated-dependency-management","title":"Automated Dependency Management","text":"<p>The platform uses Renovate Bot for automated dependency updates.</p>"},{"location":"architecture/cicd/#features","title":"Features","text":"<p>\ud83e\udd16 Automated Updates</p> <ul> <li>Docker images in Kubernetes manifests</li> <li>Helm chart versions</li> <li>CRD URLs from GitHub releases</li> <li>Pre-commit hook versions</li> <li>GitHub Action versions</li> </ul> <p>\ud83d\udd04 Auto-Merge Capabilities</p> <ul> <li>Minor and patch updates auto-merge</li> <li>Major updates require manual review</li> <li>Configurable merge strategies</li> <li>CI validation before merge</li> </ul> <p>\ud83d\udcdd Custom Regex Managers</p> <ul> <li>Extract versions from various formats</li> <li>Custom update patterns</li> <li>Flexible version detection</li> </ul> <p>\ud83d\udd10 Multi-Registry Support</p> <ul> <li>GitHub Container Registry (ghcr.io)</li> <li>Docker Hub (docker.io)</li> <li>Quay.io</li> <li>Custom registries</li> </ul> <p>\ud83c\udfaf Intelligent Tracking</p> <ul> <li>Follow semantic versioning</li> <li>Respect version constraints</li> <li>Track release notes</li> <li>Group related updates</li> </ul>"},{"location":"architecture/cicd/#renovate-configuration","title":"Renovate Configuration","text":"<p>Renovate is configured to:</p> <ul> <li>Auto-merge minor and patch updates</li> <li>Require manual review for major updates</li> <li>Use custom regex managers for version extraction</li> <li>Respect rate limits and schedule constraints</li> </ul> View renovate.json <p>{   \"\\(schema\": \"https://docs.renovatebot.com/renovate-schema.json\",   \"extends\": [     \"config:recommended\",     \":enablePreCommit\",     \":rebaseStalePrs\"   ],   \"timezone\": \"Europe/Berlin\",   \"labels\": [     \"dependencies\",     \"automated\"   ],   \"hostRules\": [     {       \"matchHost\": \"ghcr.io\",       \"timeout\": 60000     },     {       \"matchHost\": \"docker.io\",       \"timeout\": 60000     }   ],   \"customManagers\": [     {       \"customType\": \"regex\",       \"description\": \"Update Immich controller tag in Helm values files\",       \"managerFilePatterns\": [         \"/(^|/)values.*\\\\.ya?ml\\)/\"       ],       \"matchStrings\": [         \"controllers:\\s*\\n(?:[^\\n]\\n)?\\s*tag:\\s*[\\\"']?(?v?\\d+\\.\\d+\\.\\d+)[\\\"']?\"       ],       \"depNameTemplate\": \"immich-app/immich\",       \"datasourceTemplate\": \"github-releases\",       \"versioningTemplate\": \"docker\"     },     {       \"customType\": \"regex\",       \"description\": \"Update Docker images in Kubernetes YAML manifests\",       \"managerFilePatterns\": [         \"/(^|/).\\.ya?ml\\(/\"       ],       \"matchStrings\": [         \"(?&lt;indentation&gt;\\\\s*)image:\\\\s*[\\\"']?(?&lt;depName&gt;[^:\\\\s\\\"']+):(?&lt;currentValue&gt;[^\\\\s\\\"']+)[\\\"']?\\\\s*(?:#.*)?\\)\"       ],       \"datasourceTemplate\": \"docker\",       \"versioningTemplate\": \"docker\"     },     {       \"customType\": \"regex\",       \"description\": \"Update GitHub release URLs in scripts\",       \"managerFilePatterns\": [         \"/(^|/).\\.sh\\(/\"       ],       \"matchStrings\": [         \"https://github\\\\.com/(?&lt;depName&gt;[^/]+/[^/]+)/releases/download/(?&lt;currentValue&gt;[^/]+)/\"       ],       \"datasourceTemplate\": \"github-releases\"     },     {       \"customType\": \"regex\",       \"description\": \"Update CRD URLs with GitHub tags\",       \"managerFilePatterns\": [         \"/(^|/).*kustomization\\\\.ya?ml\\)/\"       ],       \"matchStrings\": [         \"https://raw\\.githubusercontent\\.com/(?[<sup>/]+/[</sup>/]+)/refs/tags/(?[^/]+)/\"       ],       \"datasourceTemplate\": \"github-tags\"     },     {       \"customType\": \"regex\",       \"description\": \"Update cert-manager CRD URLs\",       \"managerFilePatterns\": [         \"/(^|/).kustomization\\.ya?ml\\(/\"       ],       \"matchStrings\": [         \"https://github\\\\.com/jetstack/cert-manager/releases/download/(?&lt;currentValue&gt;v[0-9.]+)/cert-manager\\\\.crds\\\\.yaml\"       ],       \"depNameTemplate\": \"jetstack/cert-manager\",       \"datasourceTemplate\": \"github-releases\"     }   ],   \"kubernetes\": {     \"managerFilePatterns\": [       \"/(^|/).*\\\\.ya?ml\\)/\"     ]   },   \"helm-values\": {     \"managerFilePatterns\": [       \"/(^|/)values.\\.ya?ml\\(/\"     ]   },   \"kustomize\": {     \"managerFilePatterns\": [       \"/(^|/)kustomization\\\\.ya?ml\\)/\"     ]   },   \"packageRules\": [     {       \"matchUpdateTypes\": [         \"minor\",         \"patch\"       ],       \"automerge\": true     }   ] }"},{"location":"architecture/cicd/#managed-components","title":"Managed Components","text":"Docker ImagesHelm ChartsCRDs <p>Image tags in Kubernetes manifests are automatically updated to latest versions.</p> <p>Chart dependencies and versions are tracked and updated.</p> <p>CRD URLs from GitHub releases are automatically updated to new versions.</p> <p>Automation Philosophy</p> <p>Renovate keeps the platform up-to-date with minimal manual intervention while maintaining stability through smart auto-merge policies and comprehensive testing.</p>"},{"location":"architecture/cicd/#gitops-with-argocd","title":"GitOps with ArgoCD","text":""},{"location":"architecture/cicd/#core-features","title":"Core Features","text":"<p>ArgoCD provides:</p> <ul> <li>Automatic sync from Git</li> <li>Live application state view</li> <li>Configuration drift detection</li> <li>Health status monitoring</li> <li>One-click rollback</li> <li>Multi-cluster management</li> </ul>"},{"location":"architecture/cicd/#application-configuration","title":"Application Configuration","text":"<p>ArgoCD Applications define:</p> <ul> <li>Source repository and path</li> <li>Target cluster and namespace</li> <li>Sync policies (automated, pruning, self-heal)</li> <li>Retry logic with exponential backoff</li> </ul> View ArgoCD Application <p>apiVersion: argoproj.io/v1alpha1 kind: ApplicationSet metadata:   name: homelab-apps spec:   generators:     - list:         elements:           - path: argocd           - path: htpc           - path: utils           - path: infra   template:     metadata:       name: \"{{path}}-apps\"     spec:       project: default       source:         repoURL: https://github.com/chaitanya2692/my-homelab.git         targetRevision: main         path: overlays/{{path}}       destination:         server: https://kubernetes.default.svc         namespace: \"{{path}}\"       syncPolicy:         automated:           prune: true         syncOptions:           - CreateNamespace=true           - ApplyOutOfSyncOnly=true           - ServerSideApply=true # Recommended       # --- Add or modify this block ---       ignoreDifferences:         # Ignore fields added by CNPG operator to ALL Cluster specs         - group: postgresql.cnpg.io           kind: Cluster           jsonPointers:             - /spec/managed/roles/0/connectionLimit # Field added by CNPG             - /spec/managed/roles/0/ensure # Field added by CNPG             - /spec/managed/roles/0/inherit # Field added by CNPG             - /status # Always ignore status         # Ignore fields added by Kubernetes to the StatefulSet volumeClaimTemplate         - group: apps           kind: StatefulSet           name: recipes-postgresql           namespace: utils           jsonPointers:             - /spec/volumeClaimTemplates/0/apiVersion # Field added by K8s             - /spec/volumeClaimTemplates/0/kind # Field added by K8s             - /status # Always ignore status</p>"},{"location":"architecture/cicd/#sync-strategies","title":"Sync Strategies","text":""},{"location":"architecture/cicd/#automatic-sync","title":"Automatic Sync","text":"<p>The platform uses ArgoCD's automatic sync policy:</p> <ul> <li>Auto-sync: Automatically syncs when Git changes are detected</li> <li>Auto-prune: Removes resources deleted from Git</li> <li>Self-healing: Not enabled in current configuration</li> </ul>"},{"location":"architecture/cicd/#sync-options","title":"Sync Options","text":"<p>Configured sync options:</p> <ul> <li><code>CreateNamespace=true</code>: Automatically creates target namespaces</li> <li><code>ApplyOutOfSyncOnly=true</code>: Only syncs resources that are out of sync</li> <li><code>ServerSideApply=true</code>: Uses server-side apply for better conflict resolution</li> </ul>"},{"location":"architecture/cicd/#manual-sync","title":"Manual Sync","text":"<p>Manual sync is available through ArgoCD UI or CLI:</p> <ul> <li>Explicit sync trigger via UI or <code>argocd app sync</code></li> <li>Review changes before applying</li> <li>Useful for controlled deployments</li> </ul>"},{"location":"architecture/cicd/#continuous-integration","title":"Continuous Integration","text":""},{"location":"architecture/cicd/#github-actions-workflow","title":"GitHub Actions Workflow","text":"<p>The platform uses GitHub Actions for continuous integration:</p> View Pull Request CI Workflow <p>name: Pull Request CI on: [pull_request] # yamllint disable-line rule:truthy</p> <p>jobs:   yaml-lint:     runs-on: ubuntu-latest     steps:       - uses: actions/checkout@v5.0.1       - name: yaml-lint         uses: ibiqlik/action-yamllint@v3.1.1         with:           config_file: .yamllint.yml</p> <p>markdownlint:     runs-on: ubuntu-latest     steps:       - uses: actions/checkout@v5.0.1       - name: markdownlint-cli2-action         uses: DavidAnson/markdownlint-cli2-action@v21         with:           fix: true           globs: \"**/*.md\"           config: .markdownlint.yaml</p> <p>validate:     runs-on: ubuntu-latest     needs: [markdownlint, yaml-lint]     steps:       - name: Checkout         uses: actions/checkout@v5.0.1       - name: Setup yq         uses: fluxcd/pkg/actions/yq@main       - name: Setup kubeconform         uses: fluxcd/pkg/actions/kubeconform@main       - name: Setup kustomize         uses: fluxcd/pkg/actions/kustomize@main       - name: Setup ksops         run: source &lt;(curl -s https://raw.githubusercontent.com/viaduct-ai/kustomize-sops/master/scripts/install-ksops-archive.sh)       - name: Setup AGE key         run: |           echo \"${{ secrets.AGE_KEY }}\" &gt; /tmp/age-key.txt           chmod 600 /tmp/age-key.txt       - name: Validate manifests         env:           SOPS_AGE_KEY_FILE: /tmp/age-key.txt         run: ./scripts/validate.sh</p> <p>detect-secrets:     runs-on: ubuntu-latest     needs: [yaml-lint]     steps:       - name: Checkout         uses: actions/checkout@v5.0.1       - name: TruffleHog OSS         uses: trufflesecurity/trufflehog@v3.91.1         with:           path: ./           base: ${{ github.event.repository.default_branch }}           head: HEAD</p> <p>test-build:     needs: [validate, detect-secrets]     runs-on: ubuntu-latest     steps:       - name: Checkout         uses: actions/checkout@v5.0.1       - name: Setup kustomize         uses: fluxcd/pkg/actions/kustomize@main       - name: Setup ksops         run: source &lt;(curl -s https://raw.githubusercontent.com/viaduct-ai/kustomize-sops/master/scripts/install-ksops-archive.sh)       - name: Setup AGE key         run: |           echo \"${{ secrets.AGE_KEY }}\" &gt; /tmp/age-key.txt           chmod 600 /tmp/age-key.txt       - name: Test kustomize build         env:           SOPS_AGE_KEY_FILE: /tmp/age-key.txt         run: ./scripts/update-manifests.sh</p>"},{"location":"architecture/cicd/#deployment-workflow","title":"Deployment Workflow","text":""},{"location":"architecture/cicd/#standard-deployment","title":"Standard Deployment","text":"Text Only<pre><code>```mermaid\nflowchart TD\n    A[Developer commits changes] --&gt; B[Create Pull Request]\n    B --&gt; C{CI Pipeline}\n    C --&gt; D[YAML Lint]\n    C --&gt; E[Markdown Lint]\n    C --&gt; F[Secret Detection]\n    D --&gt; G[Validate Manifests]\n    E --&gt; G\n    G --&gt; H[Test Kustomize Build]\n    F --&gt; H\n    H --&gt; I{All Checks Pass?}\n    I --&gt;|No| J[Fix Issues]\n    J --&gt; A\n    I --&gt;|Yes| K[Merge to main]\n    K --&gt; L[ArgoCD Detects Change]\n    L --&gt; M[ArgoCD Auto-Sync]\n    M --&gt; N[Apply CRDs]\n    N --&gt; O[Wait for CRDs Established]\n    O --&gt; P[Apply Resources]\n    P --&gt; Q[Health Checks]\n    Q --&gt; R{Healthy?}\n    R --&gt;|Yes| S[Deployment Complete]\n    R --&gt;|No| T[Manual Investigation]\n```\n</code></pre> <ol> <li>Developer commits changes</li> <li>CI pipeline runs<ul> <li>Lint YAML and Markdown</li> <li>Validate schemas with kubeconform</li> <li>Security scan with TruffleHog</li> <li>Test kustomize build</li> </ul> </li> <li>Merge to main branch</li> <li>ArgoCD detects change</li> <li>ArgoCD auto-syncs cluster</li> <li>Resources applied (CRDs first, then other resources)</li> <li>Health checks monitored</li> <li>Deployment complete</li> </ol>"},{"location":"architecture/cicd/#emergency-deployment","title":"Emergency Deployment","text":"Text Only<pre><code>```mermaid\nflowchart TD\n    A[Critical Issue Detected] --&gt; B[Create Hotfix Branch]\n    B --&gt; C[Implement Fix]\n    C --&gt; D[Fast-Track PR Review]\n    D --&gt; E{CI Passes?}\n    E --&gt;|No| C\n    E --&gt;|Yes| F[Merge to main]\n    F --&gt; G[Manual ArgoCD Sync]\n    G --&gt; H[Monitor Closely]\n    H --&gt; I{Issue Resolved?}\n    I --&gt;|Yes| J[Document Incident]\n    I --&gt;|No| K[Rollback]\n    K --&gt; L[Investigate Further]\n```\n</code></pre> <ol> <li>Hotfix branch created</li> <li>Fast-track review process</li> <li>Merge to main</li> <li>Manual ArgoCD sync (if immediate deployment needed)</li> <li>Monitor closely for issues</li> <li>Document incident and post-mortem</li> </ol>"},{"location":"architecture/cicd/#cicd-pipeline-flow","title":"CI/CD Pipeline Flow","text":"Text Only<pre><code>```mermaid\nflowchart LR\n    A[Git Push] --&gt; B{Event Type}\n    B --&gt;|Pull Request| C[Pull Request CI]\n    B --&gt;|Merge to main| D[Merge CI]\n\n    C --&gt; E[yaml-lint]\n    C --&gt; F[markdownlint]\n    C --&gt; G[detect-secrets]\n    E --&gt; H[validate]\n    F --&gt; H\n    G --&gt; I[test-build]\n    H --&gt; I\n\n    D --&gt; J[detect-secrets]\n\n    I --&gt; K[PR Approved]\n    K --&gt; L[Merge]\n    L --&gt; M[ArgoCD Auto-Sync]\n```\n</code></pre>"},{"location":"architecture/cicd/#related-documentation","title":"Related Documentation","text":"<ul> <li>Configuration Management - GitOps details</li> <li>Getting Started: Scripts - Automation scripts</li> </ul>"},{"location":"architecture/cicd/#abbreviations","title":"Abbreviations","text":""},{"location":"architecture/configuration-management/","title":"Configuration Management","text":"<p>The configuration system follows modern GitOps principles using Kustomize for declarative configuration management.</p>"},{"location":"architecture/configuration-management/#gitops-principles","title":"GitOps Principles","text":"<pre><code>flowchart LR\n    subgraph \"Developer\"\n        DEV[Developer]\n    end\n\n    subgraph \"Git Repository\"\n        GIT[GitHub&lt;br/&gt;my-homelab]\n    end\n\n    subgraph \"ArgoCD\"\n        ARGO[ArgoCD&lt;br/&gt;ApplicationSet]\n    end\n\n    subgraph \"Kubernetes Cluster\"\n        K8S[Workloads]\n    end\n\n    DEV --&gt;|1. Push Changes| GIT\n    GIT --&gt;|2. Poll/Webhook| ARGO\n    ARGO --&gt;|3. Sync| K8S\n    K8S --&gt;|4. Monitor| ARGO\n    ARGO --&gt;|5. Detect Drift| GIT\n\n    style DEV fill:#4caf50\n    style GIT fill:#ff9800\n    style ARGO fill:#e91e63\n    style K8S fill:#2196f3</code></pre> <p>Configuration Strategy</p> <p>The configuration management system is designed to be maintainable, secure, and scalable while following GitOps best practices.</p>"},{"location":"architecture/configuration-management/#git-as-single-source-of-truth","title":"Git as Single Source of Truth","text":"<ul> <li>All configurations versioned in Git</li> <li>Changes applied through Git commits</li> <li>Audit trail of all modifications</li> <li>Easy rollback to previous states</li> </ul>"},{"location":"architecture/configuration-management/#declarative-configuration","title":"Declarative Configuration","text":"<ul> <li>Desired state defined in YAML</li> <li>Kubernetes reconciles actual state</li> <li>No manual cluster modifications</li> <li>Automated drift correction</li> </ul>"},{"location":"architecture/configuration-management/#automated-synchronization","title":"Automated Synchronization","text":"<ul> <li>ArgoCD watches Git repository</li> <li>Automatic deployment on changes</li> <li>Configurable sync policies</li> <li>Manual sync available when needed</li> </ul>"},{"location":"architecture/configuration-management/#directory-structure","title":"Directory Structure","text":"<pre><code>graph TD\n    subgraph \"Base Layer\"\n        B1[base/infra]\n        B2[base/htpc]\n        B3[base/utils]\n        B4[base/argocd]\n    end\n\n    subgraph \"Overlay Layer\"\n        O1[overlays/infra]\n        O2[overlays/htpc]\n        O3[overlays/utils]\n        O4[overlays/argocd]\n    end\n\n    subgraph \"Environment Components\"\n        E1[production-infra]\n        E2[production-ingress]\n        E3[staging-infra]\n        E4[staging-ingress]\n    end\n\n    subgraph \"ArgoCD\"\n        A[ApplicationSet]\n    end\n\n    B1 --&gt; O1\n    B2 --&gt; O2\n    B3 --&gt; O3\n    B4 --&gt; O4\n\n    E1 --&gt; O1\n    E2 --&gt; O1\n    E2 --&gt; O2\n    E2 --&gt; O3\n\n    O1 --&gt; A\n    O2 --&gt; A\n    O3 --&gt; A\n    O4 --&gt; A\n\n    style A fill:#e91e63</code></pre> Text Only<pre><code>.\n\u251c\u2500\u2500 base/                          # Base configurations\n\u2502   \u251c\u2500\u2500 htpc/                      # Media services\n\u2502   \u2502   \u251c\u2500\u2500 kustomization.yaml\n\u2502   \u2502   \u251c\u2500\u2500 jellyfin/\n\u2502   \u2502   \u251c\u2500\u2500 sonarr/\n\u2502   \u2502   \u251c\u2500\u2500 radarr/\n\u2502   \u2502   \u2514\u2500\u2500 ...\n\u2502   \u251c\u2500\u2500 infra/                     # Infrastructure\n\u2502   \u2502   \u251c\u2500\u2500 kustomization.yaml\n\u2502   \u2502   \u251c\u2500\u2500 traefik/\n\u2502   \u2502   \u251c\u2500\u2500 cert-manager/\n\u2502   \u2502   \u251c\u2500\u2500 monitoring/\n\u2502   \u2502   \u2514\u2500\u2500 ...\n\u2502   \u2514\u2500\u2500 utils/                     # Utilities\n\u2502       \u251c\u2500\u2500 kustomization.yaml\n\u2502       \u251c\u2500\u2500 nextcloud/\n\u2502       \u251c\u2500\u2500 immich/\n\u2502       \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 overlays/                      # Environment overlays\n\u2502   \u251c\u2500\u2500 argocd/\n\u2502   \u2502   \u2514\u2500\u2500 kustomization.yaml\n\u2502   \u2514\u2500\u2500 environment/\n\u2502       \u251c\u2500\u2500 staging-infra/\n\u2502       \u251c\u2500\u2500 staging-ingress/\n\u2502       \u251c\u2500\u2500 production-infra/\n\u2502       \u2514\u2500\u2500 production-ingress/\n\u2514\u2500\u2500 scripts/                       # Automation scripts\n    \u251c\u2500\u2500 bootstrap.sh\n    \u251c\u2500\u2500 kickstart.sh\n    \u2514\u2500\u2500 ...\n</code></pre>"},{"location":"architecture/configuration-management/#base-configurations","title":"Base Configurations","text":"<p>Base configurations contain common settings shared across environments.</p>"},{"location":"architecture/configuration-management/#structure","title":"Structure","text":"<p>Each service has its own directory:</p> Text Only<pre><code>base/utils/nextcloud/\n\u251c\u2500\u2500 deployment.yaml          # Application deployment\n\u251c\u2500\u2500 service.yaml            # Kubernetes service\n\u251c\u2500\u2500 ingress-route.yaml     # Traefik ingress\n\u251c\u2500\u2500 persistent-volume-claim.yaml\n\u251c\u2500\u2500 configmap.yaml         # Configuration\n\u2514\u2500\u2500 kustomization.yaml     # Kustomize config\n</code></pre>"},{"location":"architecture/configuration-management/#example-kustomization","title":"Example Kustomization","text":"View Base Utils Kustomization YAML<pre><code>---\napiVersion: kustomize.config.k8s.io/v1beta1\nkind: Kustomization\n\nnamespace: utils\n\nresources:\n  - homepage\n  - nextcloud\n  - immich\n  - tandoor\n  - cnpg\n  - ingress-route.yaml\n  - persistent-volume-claim.yaml\n</code></pre> View Base Infrastructure Kustomization YAML<pre><code>---\napiVersion: kustomize.config.k8s.io/v1beta1\nkind: Kustomization\n\nnamespace: infra\n\nresources:\n  - cert-manager\n  - metallb\n  - traefik\n  - local-path-provisioner\n  - monitoring\n  - ingress-route.yaml\n  - persistent-volume-claim.yaml\n</code></pre> View Base HTPC Kustomization YAML<pre><code>---\napiVersion: kustomize.config.k8s.io/v1beta1\nkind: Kustomization\n\nnamespace: htpc\n\nresources:\n  - flaresolverr\n  - jellyfin\n  - prowlarr\n  - radarr\n  - sonarr\n  - transmission\n  - scraparr\n  - ingress-route.yaml\n  - persistent-volume-claim.yaml\n</code></pre>"},{"location":"architecture/configuration-management/#environment-overlays","title":"Environment Overlays","text":"<p>Overlays customize base configurations for specific environments.</p>"},{"location":"architecture/configuration-management/#environment-components","title":"Environment Components","text":"<p>This project uses Kustomize Components for environment-specific configurations, allowing flexible composition of certificate issuers and ingress routes.</p> View Staging Infrastructure Component YAML<pre><code>---\napiVersion: kustomize.config.k8s.io/v1alpha1\nkind: Component\npatches:\n  # Certificate patch\n  - target:\n      kind: Certificate\n      name: cluster-certificate\n      namespace: infra\n    patch: |-\n      apiVersion: cert-manager.io/v1\n      kind: Certificate\n      metadata:\n        name: cluster-certificate\n        namespace: infra\n      spec:\n        secretName: staging-certificate-secret\n  # ClusterIssuer patch\n  - target:\n      kind: ClusterIssuer\n      name: letsencrypt-issuer\n    patch: |-\n      apiVersion: cert-manager.io/v1\n      kind: ClusterIssuer\n      metadata:\n        name: letsencrypt-issuer\n      spec:\n        acme:\n          server: https://acme-staging-v02.api.letsencrypt.org/directory\n          privateKeySecretRef:\n            name: letsencrypt-staging\n</code></pre> View Staging Ingress Component YAML<pre><code>---\napiVersion: kustomize.config.k8s.io/v1alpha1\nkind: Component\npatches:\n  - target:\n      kind: IngressRoute\n    patch: |-\n      ---\n      apiVersion: traefik.io/v1alpha1\n      kind: IngressRoute\n      metadata:\n        name: ingressroute\n        annotations:\n          kubernetes.io/ingress.class: traefik-external\n      spec:\n        tls:\n          secretName: staging-certificate-secret\n</code></pre> <p>The staging environment:</p> <ul> <li>Uses Let's Encrypt staging server for certificates</li> <li>Patches certificate secret names</li> <li>Modifies ingress routes to use staging certificates</li> </ul> View Production Infrastructure Component YAML<pre><code>---\napiVersion: kustomize.config.k8s.io/v1alpha1\nkind: Component\npatches:\n  # Certificate patch\n  - target:\n      kind: Certificate\n      name: cluster-certificate\n      namespace: infra\n    patch: |-\n      apiVersion: cert-manager.io/v1\n      kind: Certificate\n      metadata:\n        name: cluster-certificate\n        namespace: infra\n      spec:\n        secretName: production-certificate-secret\n  # ClusterIssuer patch\n  - target:\n      kind: ClusterIssuer\n      name: letsencrypt-issuer\n    patch: |-\n      apiVersion: cert-manager.io/v1\n      kind: ClusterIssuer\n      metadata:\n        name: letsencrypt-issuer\n      spec:\n        acme:\n          server: https://acme-v02.api.letsencrypt.org/directory\n          privateKeySecretRef:\n            name: letsencrypt-production\n</code></pre> View Production Ingress Component YAML<pre><code>---\napiVersion: kustomize.config.k8s.io/v1alpha1\nkind: Component\npatches:\n  - target:\n      kind: IngressRoute\n    patch: |-\n      ---\n      apiVersion: traefik.io/v1alpha1\n      kind: IngressRoute\n      metadata:\n        name: ingressroute\n        annotations:\n          kubernetes.io/ingress.class: traefik-external\n      spec:\n        tls:\n          secretName: production-certificate-secret\n</code></pre> <p>The production environment:</p> <ul> <li>Uses Let's Encrypt production server for certificates</li> <li>Patches certificate secret names for production</li> <li>Modifies ingress routes to use production certificates</li> </ul> View Infrastructure Overlay YAML<pre><code>apiVersion: kustomize.config.k8s.io/v1beta1\nkind: Kustomization\n\nresources:\n  - ../../base/infra\n\ncomponents:\n  - ../environment/production-infra # Change to staging-infra for staging\n  - ../environment/production-ingress # Change to staging-ingress for staging\n</code></pre>"},{"location":"architecture/configuration-management/#configuration-principles","title":"Configuration Principles","text":""},{"location":"architecture/configuration-management/#1-immutability","title":"1. Immutability","text":""},{"location":"architecture/configuration-management/#version-control-everything","title":"Version Control Everything","text":"<ul> <li>All changes tracked in Git</li> <li>Commit messages describe changes</li> <li>Branch protection for main branch</li> <li>Code review before merge</li> </ul>"},{"location":"architecture/configuration-management/#no-direct-modifications","title":"No Direct Modifications","text":"<ul> <li>No <code>kubectl edit</code> in production</li> <li>All changes through GitOps</li> <li>Infrastructure as Code</li> <li>Reproducible deployments</li> </ul>"},{"location":"architecture/configuration-management/#automated-rollback","title":"Automated Rollback","text":"<ul> <li>Git revert for rollbacks</li> <li>ArgoCD history tracking</li> <li>Quick recovery from issues</li> </ul>"},{"location":"architecture/configuration-management/#change-history","title":"Change History","text":"<ul> <li>Full audit trail in Git</li> <li>Who changed what and when</li> <li>Reason for changes in commits</li> </ul>"},{"location":"architecture/configuration-management/#2-separation-of-concerns","title":"2. Separation of Concerns","text":""},{"location":"architecture/configuration-management/#environment-specific-settings","title":"Environment-Specific Settings","text":"<p>Overlays modify only environment-specific values (e.g., replica count: 1 for staging, 3 for production) using strategic merge patches or JSON patches.</p>"},{"location":"architecture/configuration-management/#shared-configurations","title":"Shared Configurations","text":"<p>Base configurations contain common resources shared across all environments (deployment.yaml, service.yaml, configmap.yaml).</p>"},{"location":"architecture/configuration-management/#clear-dependencies","title":"Clear Dependencies","text":"<p>Explicitly reference ConfigMaps and Secrets using <code>configMapRef</code> or <code>secretRef</code> in container specs for clear dependency tracking.</p>"},{"location":"architecture/configuration-management/#modular-design","title":"Modular Design","text":"<p>Each service is self-contained and can be deployed independently.</p>"},{"location":"architecture/configuration-management/#3-validation","title":"3. Validation","text":""},{"location":"architecture/configuration-management/#schema-validation","title":"Schema Validation","text":"Bash<pre><code># Validate Kubernetes schemas\nkubeconform -strict -summary base/\n</code></pre>"},{"location":"architecture/configuration-management/#configuration-testing","title":"Configuration Testing","text":"Bash<pre><code># Build and validate manifests\nkustomize build overlays/production-infra/ | kubectl apply --dry-run=client -f -\n</code></pre>"},{"location":"architecture/configuration-management/#drift-detection","title":"Drift Detection","text":"<p>ArgoCD continuously monitors for drift:</p> <ul> <li>Compares Git state with cluster state</li> <li>Alerts on unexpected changes</li> <li>Can auto-sync or require manual approval</li> </ul>"},{"location":"architecture/configuration-management/#4-secret-management","title":"4. Secret Management","text":""},{"location":"architecture/configuration-management/#encrypted-at-rest","title":"Encrypted at Rest","text":"<ul> <li>Kubernetes Secrets with base64 encoding</li> <li>Etcd encryption for secret storage</li> <li>External secrets integration possible</li> </ul>"},{"location":"architecture/configuration-management/#environment-separation","title":"Environment Separation","text":"Text Only<pre><code>base/utils/nextcloud/secret.yaml  # Template\noverlays/staging/secret-patch.yaml  # Staging values\noverlays/production/secret-patch.yaml  # Production values\n</code></pre>"},{"location":"architecture/configuration-management/#access-auditing","title":"Access Auditing","text":"<ul> <li>Kubernetes audit logs</li> <li>Track secret access</li> <li>Alert on unauthorized access</li> </ul>"},{"location":"architecture/configuration-management/#automated-rotation","title":"Automated Rotation","text":"<ul> <li>Regular credential rotation</li> <li>Automated where supported</li> <li>Manual rotation procedures documented</li> </ul>"},{"location":"architecture/configuration-management/#argocd-integration","title":"ArgoCD Integration","text":""},{"location":"architecture/configuration-management/#applicationset-definition","title":"ApplicationSet Definition","text":"<p>The project uses an ApplicationSet to manage multiple applications from a single definition.</p> View ApplicationSet Configuration YAML<pre><code>---\napiVersion: argoproj.io/v1alpha1\nkind: ApplicationSet\nmetadata:\n  name: homelab-apps\nspec:\n  generators:\n    - list:\n        elements:\n          - path: argocd\n          - path: htpc\n          - path: utils\n          - path: infra\n  template:\n    metadata:\n      name: \"{{path}}-apps\"\n    spec:\n      project: default\n      source:\n        repoURL: https://github.com/chaitanya2692/my-homelab.git\n        targetRevision: main\n        path: overlays/{{path}}\n      destination:\n        server: https://kubernetes.default.svc\n        namespace: \"{{path}}\"\n      syncPolicy:\n        automated:\n          prune: true\n        syncOptions:\n          - CreateNamespace=true\n          - ApplyOutOfSyncOnly=true\n          - ServerSideApply=true # Recommended\n      # --- Add or modify this block ---\n      ignoreDifferences:\n        # Ignore fields added by CNPG operator to ALL Cluster specs\n        - group: postgresql.cnpg.io\n          kind: Cluster\n          jsonPointers:\n            - /spec/managed/roles/0/connectionLimit # Field added by CNPG\n            - /spec/managed/roles/0/ensure # Field added by CNPG\n            - /spec/managed/roles/0/inherit # Field added by CNPG\n            - /status # Always ignore status\n        # Ignore fields added by Kubernetes to the StatefulSet volumeClaimTemplate\n        - group: apps\n          kind: StatefulSet\n          name: recipes-postgresql\n          namespace: utils\n          jsonPointers:\n            - /spec/volumeClaimTemplates/0/apiVersion # Field added by K8s\n            - /spec/volumeClaimTemplates/0/kind # Field added by K8s\n            - /status # Always ignore status\n</code></pre> <p>This ApplicationSet:</p> <ul> <li>Creates applications for <code>argocd</code>, <code>infra</code>, <code>htpc</code>, and <code>utils</code> namespaces</li> <li>Uses a list generator to define applications</li> <li>Configures automated sync with pruning</li> <li>Enables server-side apply for better performance</li> <li>Handles CNPG operator field differences</li> </ul>"},{"location":"architecture/configuration-management/#configuration-workflow","title":"Configuration Workflow","text":""},{"location":"architecture/configuration-management/#making-changes","title":"Making Changes","text":"<ol> <li> <p>Create Branch</p> Bash<pre><code>git checkout -b feature/update-service\n</code></pre> </li> <li> <p>Modify Configuration</p> <p>Edit YAML files in base or overlays</p> </li> <li> <p>Validate Locally</p> Bash<pre><code>./scripts/validate.sh\nkustomize build overlays/production/ | kubectl apply --dry-run=client -f -\n</code></pre> </li> <li> <p>Commit and Push</p> Bash<pre><code>git add .\ngit commit -m \"Update service configuration\"\ngit push origin feature/update-service\n</code></pre> </li> <li> <p>Create Pull Request</p> <p>Review changes before merging</p> </li> <li> <p>Merge to Main</p> <p>ArgoCD automatically syncs changes</p> </li> </ol>"},{"location":"architecture/configuration-management/#emergency-rollback","title":"Emergency Rollback","text":"Bash<pre><code># Option 1: Git revert\ngit revert &lt;commit-hash&gt;\ngit push origin main\n\n# Option 2: ArgoCD rollback\nargocd app rollback &lt;app-name&gt; &lt;revision&gt;\n\n# Option 3: Manual sync to previous version\nargocd app sync &lt;app-name&gt; --revision &lt;git-commit&gt;\n</code></pre>"},{"location":"architecture/configuration-management/#best-practices","title":"Best Practices","text":""},{"location":"architecture/configuration-management/#configuration-organization","title":"Configuration Organization","text":"<ul> <li>Logical grouping: Group related resources</li> <li>Clear naming: Descriptive resource names</li> <li>Consistent structure: Follow established patterns</li> <li>Documentation: Comment complex configurations</li> </ul>"},{"location":"architecture/configuration-management/#version-control","title":"Version Control","text":"<ul> <li>Meaningful commits: Descriptive commit messages</li> <li>Atomic changes: One logical change per commit</li> <li>Feature branches: Isolate changes</li> <li>Code review: Peer review before merge</li> </ul>"},{"location":"architecture/configuration-management/#testing","title":"Testing","text":"<ul> <li>Validate locally: Test before committing</li> <li>Staging first: Deploy to staging environment</li> <li>Gradual rollout: Phased production deployment</li> <li>Monitor: Watch metrics after deployment</li> </ul>"},{"location":"architecture/configuration-management/#security","title":"Security","text":"<ul> <li>No secrets in Git: Use secret management</li> <li>Least privilege: Minimal RBAC permissions</li> <li>Regular audits: Review configurations</li> <li>Encryption: Encrypt sensitive data</li> </ul>"},{"location":"architecture/configuration-management/#troubleshooting","title":"Troubleshooting","text":""},{"location":"architecture/configuration-management/#argocd-sync-issues","title":"ArgoCD Sync Issues","text":"Bash<pre><code># Check application status\nargocd app get &lt;app-name&gt;\n\n# View sync status\nargocd app sync &lt;app-name&gt; --dry-run\n\n# Force sync\nargocd app sync &lt;app-name&gt; --force\n</code></pre>"},{"location":"architecture/configuration-management/#kustomize-build-errors","title":"Kustomize Build Errors","text":"Bash<pre><code># Validate kustomization\nkustomize build &lt;path&gt; --enable-helm\n\n# Check for missing resources\nkustomize build &lt;path&gt; --load-restrictor LoadRestrictionsNone\n</code></pre>"},{"location":"architecture/configuration-management/#configuration-drift","title":"Configuration Drift","text":"Bash<pre><code># Detect drift\nargocd app diff &lt;app-name&gt;\n\n# View differences\nkubectl diff -f &lt;manifest&gt;\n\n# Sync to desired state\nargocd app sync &lt;app-name&gt;\n</code></pre>"},{"location":"architecture/configuration-management/#related-documentation","title":"Related Documentation","text":"<ul> <li>Kubernetes Infrastructure - Cluster configuration</li> <li>CI/CD - Deployment pipelines</li> <li>Configuration: Secrets - Secret management</li> </ul>"},{"location":"architecture/configuration-management/#abbreviations","title":"Abbreviations","text":""},{"location":"architecture/kubernetes-infrastructure/","title":"Kubernetes Infrastructure","text":"<p>The platform is built on k3s, a lightweight Kubernetes distribution optimized for resource-constrained environments and edge computing.</p>"},{"location":"architecture/kubernetes-infrastructure/#k3s-overview","title":"k3s Overview","text":"<p>k3s is a certified Kubernetes distribution designed for:</p> <ul> <li>Edge computing: Low resource footprint</li> <li>IoT: ARM support</li> <li>CI/CD: Quick startup times</li> <li>Homelab: Perfect balance of features and simplicity</li> </ul>"},{"location":"architecture/kubernetes-infrastructure/#key-features","title":"Key Features","text":"<p>\u26a1 Lightweight</p> <ul> <li>Single binary &lt; 100MB</li> <li>Minimal memory footprint (~512MB)</li> <li>Quick installation and updates</li> <li>Built-in containerd runtime</li> </ul> <p>\ud83d\udd27 Batteries Included</p> <ul> <li>Traefik ingress controller</li> <li>Local-path-provisioner for storage</li> <li>ServiceLB load balancer</li> <li>CoreDNS for DNS resolution</li> </ul> <p>\ud83d\udd12 Production Ready</p> <ul> <li>CNCF certified Kubernetes</li> <li>Automated TLS certificate generation</li> <li>Support for SELinux</li> <li>Regular security updates</li> </ul>"},{"location":"architecture/kubernetes-infrastructure/#cluster-configuration","title":"Cluster Configuration","text":""},{"location":"architecture/kubernetes-infrastructure/#single-node-setup","title":"Single Node Setup","text":"<p>This homelab uses a single-node k3s cluster. Installation details and prerequisites are covered in the Installation Guide.</p> Bash<pre><code># Check cluster status\nkubectl get nodes\n\n# Verify k3s service\nsudo systemctl status k3s\n\n# View cluster info\nkubectl cluster-info\n</code></pre>"},{"location":"architecture/kubernetes-infrastructure/#namespace-organization","title":"Namespace Organization","text":"<p>The platform uses four dedicated namespaces for logical separation:</p> <pre><code>graph TB\n    subgraph \"argocd namespace\"\n        A[ArgoCD Controller]\n    end\n\n    subgraph \"infra namespace\"\n        B[Traefik Ingress]\n        C[cert-manager]\n        D[MetalLB]\n        E[Monitoring Stack]\n        F[Storage Provisioner]\n    end\n\n    subgraph \"utils namespace\"\n        G[Homepage]\n        H[Nextcloud]\n        I[Immich]\n        J[Tandoor]\n        K[CNPG Operator]\n    end\n\n    subgraph \"htpc namespace\"\n        L[Media Services]\n        M[Jellyfin]\n        N[Arr Stack]\n    end\n\n    A --&gt; B\n    A --&gt; C\n    A --&gt; D\n    A --&gt; E\n    A --&gt; F\n    A --&gt; G\n    A --&gt; H\n    A --&gt; I\n    A --&gt; J\n    A --&gt; K\n    A --&gt; L\n    A --&gt; M\n    A --&gt; N\n\n    style A fill:#e8733b\n    style B fill:#4caf50\n    style E fill:#2196f3</code></pre>"},{"location":"architecture/kubernetes-infrastructure/#namespace-structure","title":"Namespace Structure","text":"argocd"},{"location":"architecture/kubernetes-infrastructure/#gitops-controller","title":"GitOps Controller","text":"<p>Purpose: Dedicated namespace for ArgoCD application</p> <p>Components:</p> <ul> <li>ArgoCD Server</li> <li>ArgoCD Repo Server</li> <li>ArgoCD Application Controller</li> <li>ArgoCD Redis</li> <li>ArgoCD Notifications Controller</li> </ul> View ArgoCD Namespace Configuration YAML<pre><code>---\napiVersion: kustomize.config.k8s.io/v1beta1\nkind: Kustomization\n\nnamespace: argocd\n\nresources:\n  - ingress-route.yaml\n  - application.yaml\n  - argo-non-crds.yaml\n  - servicemonitor.yaml\n\npatches:\n  - target:\n      kind: ConfigMap\n      name: argocd-cm\n    path: configmap.yaml\n  - target:\n      kind: Deployment\n      name: argocd-repo-server\n    path: deployment.yaml\n</code></pre> infra"},{"location":"architecture/kubernetes-infrastructure/#core-infrastructure-components","title":"Core Infrastructure Components","text":"<p>Purpose: Houses essential cluster services</p> <p>Components:</p> <ul> <li>Traefik (Ingress Controller)</li> <li>cert-manager (TLS Certificates)</li> <li>MetalLB (Load Balancer)</li> <li>local-path-provisioner (Storage)</li> <li>Prometheus Stack (Metrics)</li> <li>Grafana (Visualization)</li> <li>Loki (Log Aggregation)</li> <li>Jaeger (Distributed Tracing)</li> <li>Alloy (Log/Metrics Collection)</li> <li>Alertmanager (Alert Routing)</li> </ul> View Infrastructure Namespace Configuration YAML<pre><code>---\napiVersion: kustomize.config.k8s.io/v1beta1\nkind: Kustomization\n\nnamespace: infra\n\nresources:\n  - cert-manager\n  - metallb\n  - traefik\n  - local-path-provisioner\n  - monitoring\n  - ingress-route.yaml\n  - persistent-volume-claim.yaml\n</code></pre> utils"},{"location":"architecture/kubernetes-infrastructure/#utility-applications","title":"Utility Applications","text":"<p>Purpose: Supporting services and tools</p> <p>Components:</p> <ul> <li>Homepage (Dashboard)</li> <li>Nextcloud (File Sync &amp; Collaboration)</li> <li>Immich (Photo Management)</li> <li>Tandoor (Recipe Management)</li> <li>CloudNativePG Operator (PostgreSQL Management)</li> <li>Redis (Nextcloud cache)</li> <li>Valkey (Immich cache)</li> <li>PostgreSQL Clusters (Nextcloud, Immich, Tandoor)</li> </ul> View Utils Namespace Configuration YAML<pre><code>---\napiVersion: kustomize.config.k8s.io/v1beta1\nkind: Kustomization\n\nnamespace: utils\n\nresources:\n  - homepage\n  - nextcloud\n  - immich\n  - tandoor\n  - cnpg\n  - ingress-route.yaml\n  - persistent-volume-claim.yaml\n</code></pre> htpc"},{"location":"architecture/kubernetes-infrastructure/#home-theater-pc-services","title":"Home Theater PC Services","text":"<p>Purpose: Media management and streaming</p> <p>Components:</p> <ul> <li>Jellyfin (Media Server)</li> <li>Sonarr (TV Show Management)</li> <li>Radarr (Movie Management)</li> <li>Prowlarr (Indexer Manager)</li> <li>Transmission (BitTorrent Client)</li> <li>FlareSolverr (Cloudflare CAPTCHA Solver)</li> <li>Scraparr (Media Metrics Exporter)</li> </ul> View HTPC Namespace Configuration YAML<pre><code>---\napiVersion: kustomize.config.k8s.io/v1beta1\nkind: Kustomization\n\nnamespace: htpc\n\nresources:\n  - flaresolverr\n  - jellyfin\n  - prowlarr\n  - radarr\n  - sonarr\n  - transmission\n  - scraparr\n  - ingress-route.yaml\n  - persistent-volume-claim.yaml\n</code></pre>"},{"location":"architecture/kubernetes-infrastructure/#resource-management","title":"Resource Management","text":"<p>Resource allocation is managed at the pod level through resource requests and limits defined in deployment manifests.</p>"},{"location":"architecture/kubernetes-infrastructure/#pod-resource-patterns","title":"Pod Resource Patterns","text":"<p>Typical resource configurations by service tier:</p> <p>Infrastructure Services (Prometheus, Grafana, Loki):</p> <ul> <li>CPU: 100m-400m (requests-limits)</li> <li>Memory: 200Mi-768Mi (requests-limits)</li> </ul> <p>Database Services (PostgreSQL, Redis, Valkey):</p> <ul> <li>CPU: 100m-500m</li> <li>Memory: 256Mi-1Gi</li> </ul> <p>Application Services (Nextcloud, Immich, Media Stack):</p> <ul> <li>CPU: 100m-1000m</li> <li>Memory: 256Mi-2Gi</li> </ul> <p>Resource Quota Consideration</p> <p>ResourceQuota and LimitRange objects are not currently implemented but can be added to enforce namespace-level resource constraints if needed.</p>"},{"location":"architecture/kubernetes-infrastructure/#best-practices","title":"Best Practices","text":"<ul> <li>Set resource requests to ensure guaranteed resources</li> <li>Set resource limits to prevent resource exhaustion</li> <li>Monitor actual usage with <code>kubectl top pods -A</code></li> <li>Adjust based on observed patterns</li> </ul>"},{"location":"architecture/kubernetes-infrastructure/#kustomize-configuration","title":"Kustomize Configuration","text":"<p>The platform uses Kustomize for declarative configuration management.</p> <pre><code>graph TD\n    subgraph \"Base Layer\"\n        B1[base/infra]\n        B2[base/htpc]\n        B3[base/utils]\n    end\n\n    subgraph \"Overlay Layer\"\n        O1[overlays/infra]\n        O2[overlays/htpc]\n        O3[overlays/utils]\n    end\n\n    subgraph \"Environment Components\"\n        E1[production-infra]\n        E2[production-ingress]\n        E3[staging-infra]\n        E4[staging-ingress]\n    end\n\n    B1 --&gt; O1\n    B2 --&gt; O2\n    B3 --&gt; O3\n\n    O1 --&gt; E1\n    O1 --&gt; E2\n    O2 --&gt; E2\n    O3 --&gt; E2\n\n    style B1 fill:#4caf50\n    style B2 fill:#2196f3\n    style B3 fill:#ff9800\n    style E1 fill:#e91e63\n    style E2 fill:#9c27b0</code></pre>"},{"location":"architecture/kubernetes-infrastructure/#directory-structure","title":"Directory Structure","text":"Text Only<pre><code>.\n\u251c\u2500\u2500 base/\n\u2502   \u251c\u2500\u2500 htpc/\n\u2502   \u2502   \u251c\u2500\u2500 kustomization.yaml\n\u2502   \u2502   \u251c\u2500\u2500 jellyfin/\n\u2502   \u2502   \u251c\u2500\u2500 sonarr/\n\u2502   \u2502   \u2514\u2500\u2500 ...\n\u2502   \u251c\u2500\u2500 infra/\n\u2502   \u2502   \u251c\u2500\u2500 kustomization.yaml\n\u2502   \u2502   \u251c\u2500\u2500 traefik/\n\u2502   \u2502   \u251c\u2500\u2500 cert-manager/\n\u2502   \u2502   \u2514\u2500\u2500 ...\n\u2502   \u2514\u2500\u2500 utils/\n\u2502       \u251c\u2500\u2500 kustomization.yaml\n\u2502       \u251c\u2500\u2500 nextcloud/\n\u2502       \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 overlays/\n    \u251c\u2500\u2500 staging-infra/\n    \u251c\u2500\u2500 staging-ingress/\n    \u251c\u2500\u2500 production-infra/\n    \u2514\u2500\u2500 production-ingress/\n</code></pre>"},{"location":"architecture/kubernetes-infrastructure/#base-configurations","title":"Base Configurations","text":"<p>Base configurations contain common settings shared across all environments.</p> View Base HTPC Configuration YAML<pre><code>---\napiVersion: kustomize.config.k8s.io/v1beta1\nkind: Kustomization\n\nnamespace: htpc\n\nresources:\n  - flaresolverr\n  - jellyfin\n  - prowlarr\n  - radarr\n  - sonarr\n  - transmission\n  - scraparr\n  - ingress-route.yaml\n  - persistent-volume-claim.yaml\n</code></pre> View Base Infrastructure Configuration YAML<pre><code>---\napiVersion: kustomize.config.k8s.io/v1beta1\nkind: Kustomization\n\nnamespace: infra\n\nresources:\n  - cert-manager\n  - metallb\n  - traefik\n  - local-path-provisioner\n  - monitoring\n  - ingress-route.yaml\n  - persistent-volume-claim.yaml\n</code></pre> View Base Utils Configuration YAML<pre><code>---\napiVersion: kustomize.config.k8s.io/v1beta1\nkind: Kustomization\n\nnamespace: utils\n\nresources:\n  - homepage\n  - nextcloud\n  - immich\n  - tandoor\n  - cnpg\n  - ingress-route.yaml\n  - persistent-volume-claim.yaml\n</code></pre>"},{"location":"architecture/kubernetes-infrastructure/#environment-overlays","title":"Environment Overlays","text":"<p>Overlays customize base configurations for different environments using Kustomize components.</p> View Production Infrastructure Overlay YAML<pre><code>apiVersion: kustomize.config.k8s.io/v1beta1\nkind: Kustomization\n\nresources:\n  - ../../base/infra\n\ncomponents:\n  - ../environment/production-infra # Change to staging-infra for staging\n  - ../environment/production-ingress # Change to staging-ingress for staging\n</code></pre> View Production Environment Component YAML<pre><code>---\napiVersion: kustomize.config.k8s.io/v1alpha1\nkind: Component\npatches:\n  # Certificate patch\n  - target:\n      kind: Certificate\n      name: cluster-certificate\n      namespace: infra\n    patch: |-\n      apiVersion: cert-manager.io/v1\n      kind: Certificate\n      metadata:\n        name: cluster-certificate\n        namespace: infra\n      spec:\n        secretName: production-certificate-secret\n  # ClusterIssuer patch\n  - target:\n      kind: ClusterIssuer\n      name: letsencrypt-issuer\n    patch: |-\n      apiVersion: cert-manager.io/v1\n      kind: ClusterIssuer\n      metadata:\n        name: letsencrypt-issuer\n      spec:\n        acme:\n          server: https://acme-v02.api.letsencrypt.org/directory\n          privateKeySecretRef:\n            name: letsencrypt-production\n</code></pre> <p>The overlay system uses Kustomize components to:</p> <ul> <li>Patch certificate issuers (staging vs production Let's Encrypt)</li> <li>Customize ingress routes with environment-specific domains</li> <li>Apply environment-specific configurations</li> </ul>"},{"location":"architecture/kubernetes-infrastructure/#container-runtime","title":"Container Runtime","text":"<p>k3s uses containerd as its container runtime:</p>"},{"location":"architecture/kubernetes-infrastructure/#benefits","title":"Benefits","text":"<ul> <li>Lightweight: Smaller footprint than Docker</li> <li>Fast: Quick container startup</li> <li>Integrated: Built into k3s</li> <li>Standards: OCI compliant</li> </ul>"},{"location":"architecture/kubernetes-infrastructure/#cluster-operations","title":"Cluster Operations","text":""},{"location":"architecture/kubernetes-infrastructure/#health-monitoring","title":"Health Monitoring","text":"<p>Monitor cluster health:</p> Bash<pre><code># Node status\nkubectl get nodes\n\n# Component status\nkubectl get componentstatuses\n\n# System pods\nkubectl get pods -n kube-system\n\n# Resource usage\nkubectl top nodes\nkubectl top pods -A\n</code></pre>"},{"location":"architecture/kubernetes-infrastructure/#maintenance","title":"Maintenance","text":"<p>Common maintenance tasks:</p> Bash<pre><code># Drain node for maintenance\nkubectl drain &lt;node-name&gt; --ignore-daemonsets --delete-emptydir-data\n\n# Update k3s to latest stable version\ncurl -sfL https://get.k3s.io | sh -\n\n# Restart k3s service\nsudo systemctl restart k3s\n\n# Check k3s version\nkubectl version\n\n# Uncordon node after maintenance\nkubectl uncordon &lt;node-name&gt;\n</code></pre> <p>Update Considerations</p> <p>Always check the k3s release notes before upgrading. Test updates in a staging environment when possible.</p>"},{"location":"architecture/kubernetes-infrastructure/#troubleshooting","title":"Troubleshooting","text":""},{"location":"architecture/kubernetes-infrastructure/#common-issues","title":"Common Issues","text":"Pods stuck in Pending <p>Cause: Insufficient resources or scheduling constraints</p> <p>Solution:</p> Bash<pre><code>kubectl describe pod &lt;pod-name&gt; -n &lt;namespace&gt;\nkubectl get events -n &lt;namespace&gt;\nkubectl top nodes\n</code></pre> ImagePullBackOff errors <p>Cause: Cannot pull container image</p> <p>Solution:</p> Bash<pre><code>kubectl describe pod &lt;pod-name&gt; -n &lt;namespace&gt;\n# Check image name and registry access\n# Verify network connectivity\n</code></pre> CrashLoopBackOff <p>Cause: Application crashing on startup</p> <p>Solution:</p> Bash<pre><code>kubectl logs &lt;pod-name&gt; -n &lt;namespace&gt;\nkubectl logs &lt;pod-name&gt; -n &lt;namespace&gt; --previous\nkubectl describe pod &lt;pod-name&gt; -n &lt;namespace&gt;\n</code></pre>"},{"location":"architecture/kubernetes-infrastructure/#related-documentation","title":"Related Documentation","text":"<ul> <li>Configuration Management - Kustomize details</li> <li>Storage - Persistent storage</li> <li>Networking - Network configuration</li> </ul>"},{"location":"architecture/kubernetes-infrastructure/#abbreviations","title":"Abbreviations","text":""},{"location":"architecture/networking/","title":"Networking","text":"<p>The networking layer provides secure external access to services through ingress control, load balancing, and automated certificate management.</p>"},{"location":"architecture/networking/#overview","title":"Overview","text":"<p>The networking architecture consists of three main components:</p> <ul> <li>Traefik: Reverse proxy and ingress controller</li> <li>MetalLB: Load balancer for external IPs</li> <li>cert-manager: Automatic TLS certificate management</li> </ul> <pre><code>graph LR\n    A[Internet] --&gt; B[Cloudflare DNS]\n    B --&gt; C[MetalLB IP]\n    C --&gt; D[Traefik]\n    D --&gt; E[Service A]\n    D --&gt; F[Service B]\n    D --&gt; G[Service C]\n    H[cert-manager] -.-&gt; | TLS Certs | D</code></pre>"},{"location":"architecture/networking/#traefik-configuration","title":"Traefik Configuration","text":"<p>Traefik serves as the ingress controller and reverse proxy.</p>"},{"location":"architecture/networking/#features","title":"Features","text":"<p>\ud83d\udd00 LoadBalancer Integration</p> <ul> <li>Static IP: 192.168.1.245</li> <li>Assigned by MetalLB</li> <li>External service exposure</li> <li>Layer 4 and Layer 7 routing</li> </ul> <p>\ud83d\udd12 HTTPS Redirect</p> <ul> <li>Automatic HTTP to HTTPS redirection</li> <li>TLS termination at the edge</li> <li>Modern TLS versions (1.2+)</li> <li>Strong cipher suites</li> </ul> <p>\ud83d\udee1\ufe0f Security Headers</p> <ul> <li>HSTS (HTTP Strict Transport Security)</li> <li>XSS Protection</li> <li>Content Security Policy</li> <li>X-Frame-Options</li> <li>Referrer Policy</li> </ul> <p>\ud83d\udd11 Authentication</p> <ul> <li>Basic authentication support</li> <li>Forward authentication integration</li> <li>Custom middleware chains</li> <li>OAuth2 proxy ready</li> </ul> <p>Design Choice</p> <p>Traefik was chosen for its Kubernetes-native integration, dynamic configuration, and robust feature set that handles both simple and complex routing scenarios.</p>"},{"location":"architecture/networking/#deployment","title":"Deployment","text":"<p>Traefik is deployed as a LoadBalancer service type, receiving a static IP (192.168.1.245) from MetalLB for external access on ports 80 and 443.</p> View Traefik configuration <p>namespaceOverride: infra</p> <p>globalArguments:   - \"--global.sendanonymoususage=false\"   - \"--global.checknewversion=false\"</p> <p>additionalArguments:   - \"--serversTransport.insecureSkipVerify=true\"</p> <p>logs:   general:     level: \"INFO\"</p> <p>metrics:   addInternals: true   prometheus:     entryPoint: metrics     addEntryPointsLabels: true     addRoutersLabels: true     addServicesLabels: true     service:       enabled: true     disableAPICheck: true     serviceMonitor:       enabled: true       namespace: infra       additionalLabels:         release: kube-prometheus-stack</p> <p>tracing:   serviceName: \"traefik\"   addInternals: true   sampleRate: 1.0   otlp:     enabled: true     grpc:       enabled: true       endpoint: \"jaeger-collector.infra.svc.cluster.local:4317\"       insecure: true</p> <p>ingressClass:   enabled: true   isDefaultClass: true</p> <p>deployment:   enabled: true   kind: Deployment   replicas: 1</p> <p>ports:   web:     redirections:       entrypoint:         to: websecure         scheme: https         priority: 10   websecure:     http3:       enabled: true     advertisedPort: 443     tls:       enabled: true   metrics:     port: 8082     expose:       default: true     protocol: TCP     entryPoint: metrics</p> <p>providers:   kubernetesCRD:     enabled: true     ingressClass: traefik-external     allowExternalNameServices: true     allowCrossNamespace: true   kubernetesIngress:     enabled: false</p> <p>rbac:   enabled: true</p> <p>service:   enabled: true   type: LoadBalancer   spec:     loadBalancerIP: 192.168.1.245     externalTrafficPolicy: Local</p> <p>persistence:   enabled: true   existingClaim: traefik-data-pvc</p> <p>env:   - name: TZ     value: \"CET\"</p>"},{"location":"architecture/networking/#middleware","title":"Middleware","text":"<p>Common middleware configurations include:</p> <ul> <li>HTTPS redirect: Automatically redirect HTTP to HTTPS with permanent redirect</li> <li>Security headers: Add HSTS, SSL redirect, and other security headers with appropriate timeouts</li> </ul> View default security headers middleware <p>apiVersion: traefik.io/v1alpha1 kind: Middleware metadata:   name: default-headers spec:   headers:     browserXssFilter: true     contentTypeNosniff: true     forceSTSHeader: true     stsIncludeSubdomains: true     stsPreload: true     stsSeconds: 31536000     customFrameOptionsValue: DENY     referrerPolicy: no-referrer     contentSecurityPolicy: \"default-src 'none'; script-src 'self' 'unsafe-inline' 'unsafe-eval' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' https: data:; connect-src 'self' https:; frame-src 'self' https:; media-src 'self' https:; object-src 'none'; frame-ancestors 'self'; base-uri 'self'; form-action 'self';\"     customRequestHeaders:       X-Forwarded-Proto: https     customResponseHeaders:       Referrer-Policy: strict-origin-when-cross-origin       Permissions-Policy: geolocation=(), midi=(), sync-xhr=(), microphone=(), camera=(), magnetometer=(), gyroscope=(), fullscreen=(self), payment=()       X-Content-Type-Options: nosniff       X-Frame-Options: DENY       X-XSS-Protection: 1; mode=block     sslRedirect: true     sslForceHost: true     sslProxyHeaders:       X-Forwarded-Proto: https     accessControlAllowMethods:       - GET       - POST       - PUT       - DELETE       - OPTIONS     accessControlAllowHeaders:       - Content-Type       - Authorization     accessControlMaxAge: 3600     addVaryHeader: true</p>"},{"location":"architecture/networking/#ingressroute-example","title":"IngressRoute Example","text":"<p>IngressRoute CRDs define routing rules with:</p> <ul> <li>Entry points (websecure for HTTPS)</li> <li>Host-based matching</li> <li>Service references with ports</li> <li>Middleware chains for security</li> <li>TLS certificate secret references</li> </ul> View IngressRoute configuration <p>apiVersion: traefik.io/v1alpha1 kind: IngressRoute metadata:   name: ingressroute   namespace: infra   annotations:     kubernetes.io/ingress.class: traefik-external spec:   entryPoints:     - websecure   routes:     - match: Host(<code>traefik.my-homelab.party</code>)       kind: Rule       services:         - name: api@internal           kind: TraefikService     - match: Host(<code>grafana.my-homelab.party</code>)       kind: Rule       services:         - name: grafana           port: 80     - match: Host(<code>jaeger.my-homelab.party</code>)       kind: Rule       services:         - name: jaeger-query           port: 16686     - match: Host(<code>prometheus.my-homelab.party</code>)       kind: Rule       middlewares:         - name: homelab-auth       services:         - name: prometheus-prometheus           port: 9090     - match: Host(<code>alertmanager.my-homelab.party</code>)       kind: Rule       middlewares:         - name: homelab-auth       services:         - name: prometheus-alertmanager           port: 9093     - match: Host(<code>node-exporter.my-homelab.party</code>)       kind: Rule       middlewares:         - name: homelab-auth       services:         - name: node-exporter           port: 9100     - match: Host(<code>loki.my-homelab.party</code>)       kind: Rule       services:         - name: loki           port: 3100     - match: Host(<code>alloy.my-homelab.party</code>)       kind: Rule       services:         - name: alloy           port: 12345</p>"},{"location":"architecture/networking/#metallb-configuration","title":"MetalLB Configuration","text":"<p>MetalLB provides load balancer services in bare metal environments.</p>"},{"location":"architecture/networking/#ip-address-pool","title":"IP Address Pool","text":"<p>\ud83c\udf10 IP Range: 192.168.1.240/28</p> <ul> <li>16 assignable addresses (240-255)</li> <li>Reserved network segment</li> <li>No DHCP overlap</li> <li>Layer 2 mode (ARP)</li> </ul> <p>\u2696\ufe0f Load Balancing Features</p> <ul> <li>Address assignment</li> <li>Failover support</li> <li>Speaker daemonset</li> <li>BGP mode available (if needed)</li> </ul> <p>Network Design</p> <p>The IP range is carefully chosen to avoid conflicts with DHCP and other network services while providing enough addresses for all planned services.</p>"},{"location":"architecture/networking/#configuration","title":"Configuration","text":"<p>MetalLB is configured with an IPAddressPool defining available addresses and an L2Advertisement for Layer 2 mode.</p> View MetalLB configuration <p>apiVersion: metallb.io/v1beta1 kind: IPAddressPool metadata:   name: first-pool spec:   addresses:     - 192.168.1.240/28</p> <p>apiVersion: metallb.io/v1beta1 kind: L2Advertisement metadata:   name: empty</p>"},{"location":"architecture/networking/#cert-manager","title":"cert-manager","text":"<p>cert-manager automates TLS certificate management.</p>"},{"location":"architecture/networking/#cert-manager-features","title":"cert-manager Features","text":"<p>\ud83c\udfaf Let's Encrypt Integration</p> <ul> <li>Automated certificate issuance</li> <li>Automatic renewal</li> <li>ACME protocol support</li> <li>Production and staging environments</li> </ul> <p>\u2601\ufe0f Cloudflare DNS-01 Challenge</p> <ul> <li>Wildcard certificate support</li> <li>DNS-based validation</li> <li>No ingress required</li> <li>Private network compatible</li> </ul> <p>\ud83c\udf1f Wildcard Certificates</p> <ul> <li><code>*.my-homelab.party</code></li> <li>Single cert for all subdomains</li> <li>Reduced renewal frequency</li> <li>Simplified management</li> </ul> <p>\ud83d\udcca Monitoring</p> <ul> <li>Prometheus metrics</li> <li>Certificate expiry alerts</li> <li>Renewal status tracking</li> <li>Error notifications</li> </ul>"},{"location":"architecture/networking/#clusterissuer-configuration","title":"ClusterIssuer Configuration","text":"<p>The ClusterIssuer configures Let's Encrypt integration with Cloudflare DNS-01 challenge solver using an API token secret.</p> View ClusterIssuer configuration <p>apiVersion: cert-manager.io/v1 kind: ClusterIssuer metadata:   name: letsencrypt-issuer spec:   acme:     server: placeholder-server     email: chaitanya2692@gmail.com     privateKeySecretRef:       name: placeholder-name     solvers:       - dns01:           cloudflare:             email: chaitanya2692@gmail.com             apiTokenSecretRef:               name: cloudflare-token-secret               key: cloudflare-token         selector:           dnsZones:             - \"my-homelab.party\"</p>"},{"location":"architecture/networking/#certificate-request","title":"Certificate Request","text":"<p>Certificate resources request TLS certificates from the ClusterIssuer, specifying DNS names (including wildcards) and the target secret name.</p> View Certificate configuration <p>apiVersion: cert-manager.io/v1 kind: Certificate metadata:   name: cluster-certificate   namespace: infra spec:   secretName: placeholder-secret-name   secretTemplate:     annotations:       reflector.v1.k8s.emberstack.com/reflection-allowed: \"true\"       reflector.v1.k8s.emberstack.com/reflection-allowed-namespaces: \"argocd,htpc,infra,utils\"       reflector.v1.k8s.emberstack.com/reflection-auto-enabled: \"true\"       reflector.v1.k8s.emberstack.com/reflection-auto-namespaces: \"argocd,htpc,infra,utils\"   issuerRef:     kind: ClusterIssuer     name: letsencrypt-issuer   commonName: \".my-homelab.party\"   dnsNames:     - \".my-homelab.party\"</p>"},{"location":"architecture/networking/#dns-configuration","title":"DNS Configuration","text":""},{"location":"architecture/networking/#cloudflare-setup","title":"Cloudflare Setup","text":""},{"location":"architecture/networking/#dns-security-and-management","title":"DNS Security and Management","text":"<ul> <li>DDoS protection</li> <li>WAF capabilities</li> <li>Proxy protection (orange cloud)</li> <li>Analytics and insights</li> </ul>"},{"location":"architecture/networking/#dns-records","title":"DNS Records","text":"<p>Configure an A record for the root domain pointing to your external IP and a CNAME wildcard record pointing to the root, both with Cloudflare proxy enabled.</p>"},{"location":"architecture/networking/#local-dns","title":"Local DNS","text":"<p>For internal-only access, add entries to <code>/etc/hosts</code> or your local DNS server mapping service hostnames to the MetalLB IP (192.168.1.245).</p>"},{"location":"architecture/networking/#traffic-flow","title":"Traffic Flow","text":"<pre><code>sequenceDiagram\n    participant User\n    participant Cloudflare\n    participant MetalLB\n    participant Traefik\n    participant Service\n    participant certmanager as cert-manager\n\n    Note over certmanager: Certificate Issuance (Background)\n    certmanager-&gt;&gt;Cloudflare: DNS-01 Challenge\n    Cloudflare-&gt;&gt;certmanager: Challenge Response\n    certmanager-&gt;&gt;certmanager: Store Certificate in Secret\n\n    Note over User,Service: Request Flow\n    User-&gt;&gt;Cloudflare: HTTPS Request (service.my-homelab.party)\n    Cloudflare-&gt;&gt;MetalLB: Forward to 192.168.1.245\n    MetalLB-&gt;&gt;Traefik: Route to LoadBalancer (Port 443)\n    Traefik-&gt;&gt;Traefik: TLS Termination\n    Traefik-&gt;&gt;Traefik: Apply Middleware (Headers, Auth)\n    Traefik-&gt;&gt;Traefik: Match IngressRoute Rule\n    Traefik-&gt;&gt;Service: Forward to Backend Service\n    Service-&gt;&gt;Traefik: Response\n    Traefik-&gt;&gt;MetalLB: Return Response\n    MetalLB-&gt;&gt;Cloudflare: Forward Response\n    Cloudflare-&gt;&gt;User: HTTPS Response</code></pre>"},{"location":"architecture/networking/#network-policies","title":"Network Policies","text":"<p>Kubernetes NetworkPolicies control traffic between pods.</p> <p>Current Implementation</p> <p>NetworkPolicies are currently implemented for the ArgoCD namespace to secure GitOps operations. Application namespaces (htpc, utils, infra) rely on namespace isolation and do not have explicit NetworkPolicy resources defined.</p>"},{"location":"architecture/networking/#argocd-network-policies","title":"ArgoCD Network Policies","text":"<p>ArgoCD uses NetworkPolicies to:</p> <ul> <li>Control ingress traffic to ArgoCD components</li> <li>Restrict inter-component communication</li> <li>Allow specific access from Traefik ingress</li> <li>Implement least-privilege network access</li> </ul>"},{"location":"architecture/networking/#future-considerations","title":"Future Considerations","text":"<p>Additional NetworkPolicies can be implemented for:</p> <ul> <li>Default deny policies per namespace</li> <li>Explicit allow rules for service-to-service communication</li> <li>Egress filtering for external API access</li> </ul>"},{"location":"architecture/networking/#troubleshooting","title":"Troubleshooting","text":""},{"location":"architecture/networking/#traefik-issues","title":"Traefik Issues","text":"Bash<pre><code># Check Traefik pods\nkubectl get pods -n infra -l app.kubernetes.io/name=traefik\n\n# View Traefik logs\nkubectl logs -n infra -l app.kubernetes.io/name=traefik\n\n# Check IngressRoutes\nkubectl get ingressroute -A\n\n# Describe specific route\nkubectl describe ingressroute &lt;name&gt; -n &lt;namespace&gt;\n</code></pre>"},{"location":"architecture/networking/#metallb-issues","title":"MetalLB Issues","text":"Bash<pre><code># Check speaker pods\nkubectl get pods -n infra -l app=metallb\n\n# View speaker logs\nkubectl logs -n infra -l component=speaker\n\n# Check IP address pools\nkubectl get ipaddresspool -n infra\n\n# Check L2 advertisements\nkubectl get l2advertisement -n infra\n</code></pre>"},{"location":"architecture/networking/#cert-manager-issues","title":"cert-manager Issues","text":"Bash<pre><code># Check cert-manager pods\nkubectl get pods -n infra -l app=cert-manager\n\n# View cert-manager logs\nkubectl logs -n infra -l app=cert-manager\n\n# Check certificates\nkubectl get certificate -A\n\n# Check certificate requests\nkubectl get certificaterequest -A\n\n# Describe certificate\nkubectl describe certificate &lt;name&gt; -n &lt;namespace&gt;\n</code></pre>"},{"location":"architecture/networking/#related-documentation","title":"Related Documentation","text":"<ul> <li>Security - Security architecture</li> <li>Kubernetes Infrastructure - Cluster details</li> <li>Observability - Monitoring networking</li> </ul>"},{"location":"architecture/networking/#abbreviations","title":"Abbreviations","text":""},{"location":"architecture/observability/","title":"Observability Architecture","text":"<p>The observability system provides comprehensive visibility into system behavior through metrics, logs, and distributed tracing.</p>"},{"location":"architecture/observability/#three-pillars-of-observability","title":"Three Pillars of Observability","text":"<p>The monitoring system is built on three foundational pillars:</p> <pre><code>graph TB\n    subgraph \"Observability Stack\"\n        M[Metrics&lt;br/&gt;Prometheus]\n        L[Logs&lt;br/&gt;Loki]\n        T[Traces&lt;br/&gt;Jaeger]\n    end\n\n    subgraph \"Data Sources\"\n        A[Applications]\n        K[Kubernetes]\n        N[Nodes]\n    end\n\n    subgraph \"Visualization\"\n        G[Grafana&lt;br/&gt;Dashboards]\n    end\n\n    A --&gt; M\n    A --&gt; L\n    A --&gt; T\n    K --&gt; M\n    K --&gt; L\n    N --&gt; M\n\n    M --&gt; G\n    L --&gt; G\n    T --&gt; G\n\n    style M fill:#e85d75\n    style L fill:#f4a742\n    style T fill:#60d0e4\n    style G fill:#f05a28</code></pre>"},{"location":"architecture/observability/#1-metrics-prometheus","title":"1. Metrics (Prometheus)","text":"<p>Time-series data for performance and health monitoring</p>"},{"location":"architecture/observability/#2-logs-loki","title":"2. Logs (Loki)","text":"<p>Centralized logging for debugging and audit trails</p>"},{"location":"architecture/observability/#3-traces-jaeger","title":"3. Traces (Jaeger)","text":"<p>Distributed request tracing for performance analysis</p> <p>Observability Philosophy</p> <p>Complete system visibility with correlation across metrics, logs, and traces enables rapid problem identification and resolution.</p>"},{"location":"architecture/observability/#metrics-collection","title":"Metrics Collection","text":""},{"location":"architecture/observability/#prometheus-stack","title":"Prometheus Stack","text":"<p>Prometheus collects and stores time-series metrics.</p> <pre><code>flowchart LR\n    subgraph \"Metric Sources\"\n        SM[ServiceMonitors]\n        NE[Node Exporter]\n        KSM[Kube State Metrics]\n        Pods[Annotated Pods]\n    end\n\n    subgraph \"Collection\"\n        Alloy[Alloy]\n        Prom[Prometheus]\n    end\n\n    subgraph \"Storage &amp; Query\"\n        TSDB[Time Series DB&lt;br/&gt;10Gi PVC&lt;br/&gt;7d retention]\n    end\n\n    subgraph \"Visualization\"\n        Grafana[Grafana&lt;br/&gt;Dashboards]\n    end\n\n    SM --&gt; Prom\n    NE --&gt; Prom\n    KSM --&gt; Prom\n    Pods --&gt; Alloy\n    Alloy --&gt; Prom\n    Prom --&gt; TSDB\n    TSDB --&gt; Grafana\n\n    style Prom fill:#e85d75\n    style Grafana fill:#f05a28</code></pre> View kube-prometheus-stack Configuration YAML<pre><code>---\nnamespaceOverride: \"infra\"\nfullnameOverride: prometheus\n\ngrafana:\n  enabled: true\n  fullnameOverride: grafana\n  defaultDashboardsTimezone: cet\n  grafana.ini:\n    analytics:\n      check_for_updates: false\n      reporting_enabled: false\n      check_for_plugin_updates: false\n  persistence:\n    enabled: true\n    existingClaim: grafana-data-pvc\n  initChownData:\n    enabled: false\n  sidecar:\n    dashboards:\n      enabled: true\n      skipTlsVerify: true\n    datasources:\n      enabled: true\n      skipTlsVerify: true\n  additionalDataSources:\n    - name: Loki\n      type: loki\n      uid: loki\n      url: http://loki.infra.svc.cluster.local:3100\n\nprometheus:\n  enabled: true\n  serviceAccount:\n    create: true\n    name: kube-prometheus-stack-prometheus\n  prometheusSpec:\n    replicas: 1\n    replicaExternalLabelName: \"replica\"\n    ruleSelectorNilUsesHelmValues: false\n    serviceMonitorSelectorNilUsesHelmValues: false\n    podMonitorSelectorNilUsesHelmValues: false\n    probeSelectorNilUsesHelmValues: false\n    retention: 7d\n    enableAdminAPI: true\n    walCompression: true\n    enableFeatures:\n      - remote-write-receiver\n    resources:\n      requests:\n        cpu: \"150m\"\n        memory: \"256Mi\"\n      limits:\n        cpu: \"400m\"\n        memory: \"768Mi\"\n    storageSpec:\n      volumeClaimTemplate:\n        spec:\n          storageClassName: local-path-infra\n          accessModes: [\"ReadWriteOnce\"]\n          resources:\n            requests:\n              storage: 10Gi\n\nnodeExporter:\n  enabled: true\n  serviceMonitor:\n    relabelings:\n      - action: replace\n        regex: (.*)\n        replacement: $1\n        sourceLabels:\n          - __meta_kubernetes_pod_node_name\n        targetLabel: kubernetes_node\n\nprometheus-node-exporter:\n  enabled: true\n  fullnameOverride: node-exporter\n  prometheus:\n    monitor:\n      enabled: true\n      relabelings:\n        - action: replace\n          regex: (.*)\n          replacement: $1\n          sourceLabels:\n            - __meta_kubernetes_pod_node_name\n          targetLabel: kubernetes_node\n  resources:\n    requests:\n      memory: \"64Mi\"\n      cpu: \"100m\"\n    limits:\n      memory: \"128Mi\"\n      cpu: \"200m\"\n\nkubeStateMetrics:\n  enabled: true\n\nkube-state-metrics:\n  enabled: true\n  fullnameOverride: kube-state-metrics\n  selfMonitor:\n    enabled: true\n  prometheus:\n    monitor:\n      enabled: true\n      relabelings:\n        - action: replace\n          regex: (.*)\n          replacement: $1\n          sourceLabels:\n            - __meta_kubernetes_pod_node_name\n          targetLabel: kubernetes_node\n  resources:\n    requests:\n      memory: \"64Mi\"\n      cpu: \"100m\"\n    limits:\n      memory: \"128Mi\"\n      cpu: \"200m\"\n\nalertmanager:\n  enabled: true\n  fullnameOverride: alertmanager\n  serviceAccount:\n    create: true\n    name: kube-prometheus-stack-alertmanager\n  alertmanagerSpec:\n    resources:\n      requests:\n        memory: \"64Mi\"\n        cpu: \"50m\"\n      limits:\n        memory: \"128Mi\"\n        cpu: \"100m\"\n\nkubeApiServer:\n  enabled: true\n\nkubelet:\n  enabled: true\n  serviceMonitor:\n    metricRelabelings:\n      - action: replace\n        sourceLabels:\n          - node\n        targetLabel: instance\n\nkubeControllerManager:\n  enabled: true\n  endpoints:\n    - 192.168.1.75\n\ncoreDns:\n  enabled: true\n\nkubeDns:\n  enabled: false\n\nkubeEtcd:\n  enabled: true\n  endpoints:\n    - 192.168.1.75\n  service:\n    enabled: true\n    port: 2381\n    targetPort: 2381\n\nkubeScheduler:\n  enabled: true\n  endpoints: # ips of servers\n    - 192.168.1.75\n\nkubeProxy:\n  enabled: true\n  endpoints: # ips of servers\n    - 192.168.1.75\n</code></pre>"},{"location":"architecture/observability/#components","title":"Components","text":"Component Purpose Key Metrics Prometheus Time-series DB - Resource utilization- Application metrics- Service health Scraparr Media Stats - Download status- Queue metrics- Quality stats- Arr service metrics Node Exporter System Metrics - Hardware stats- System load- Network usage ServiceMonitor Service Discovery - ArgoCD- Scraparr- cert-manager- CNPG operator- Alloy"},{"location":"architecture/observability/#configuration","title":"Configuration","text":"<p>ServiceMonitor CRDs enable automatic Prometheus scraping of services matching label selectors, specifying scrape intervals and metric endpoints.</p> View ServiceMonitor Example - ArgoCD YAML<pre><code>---\napiVersion: monitoring.coreos.com/v1\nkind: ServiceMonitor\nmetadata:\n  name: argocd-metrics\n  labels:\n    release: kube-prometheus-stack\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-metrics\n  endpoints:\n    - port: metrics\n---\napiVersion: monitoring.coreos.com/v1\nkind: ServiceMonitor\nmetadata:\n  name: argocd-server-metrics\n  labels:\n    release: kube-prometheus-stack\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-server-metrics\n  endpoints:\n    - port: metrics\n---\napiVersion: monitoring.coreos.com/v1\nkind: ServiceMonitor\nmetadata:\n  name: argocd-repo-server-metrics\n  labels:\n    release: kube-prometheus-stack\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-repo-server\n  endpoints:\n    - port: metrics\n</code></pre> View ServiceMonitor Example - Scraparr YAML<pre><code>---\napiVersion: monitoring.coreos.com/v1\nkind: ServiceMonitor\nmetadata:\n  name: scraparr\n  namespace: htpc\n  labels:\n    app: scraparr\n    release: kube-prometheus-stack\nspec:\n  selector:\n    matchLabels:\n      app: scraparr\n  endpoints:\n    - port: http # This should match your service's port name\n      path: /metrics\n      interval: 30s\n</code></pre>"},{"location":"architecture/observability/#key-metrics","title":"Key Metrics","text":""},{"location":"architecture/observability/#resource-utilization","title":"Resource Utilization","text":"<ul> <li><code>container_cpu_usage_seconds_total</code></li> <li><code>container_memory_working_set_bytes</code></li> <li><code>kubelet_volume_stats_used_bytes</code></li> </ul>"},{"location":"architecture/observability/#application-metrics","title":"Application Metrics","text":"<ul> <li><code>http_requests_total</code></li> <li><code>http_request_duration_seconds</code></li> <li><code>http_errors_total</code></li> </ul>"},{"location":"architecture/observability/#service-health","title":"Service Health","text":"<ul> <li><code>up</code> - Service availability</li> <li><code>probe_success</code> - Health check status</li> <li><code>kube_pod_status_phase</code></li> </ul>"},{"location":"architecture/observability/#log-management","title":"Log Management","text":""},{"location":"architecture/observability/#loki-stack","title":"Loki Stack","text":"<p>Loki provides efficient log aggregation.</p> <pre><code>sequenceDiagram\n    participant Pod as Kubernetes Pods\n    participant Alloy as Alloy Collector\n    participant Loki as Loki\n    participant Grafana as Grafana\n\n    Pod-&gt;&gt;Alloy: Container logs\n    Alloy-&gt;&gt;Alloy: Extract labels&lt;br/&gt;(namespace, pod, container)\n    Alloy-&gt;&gt;Loki: Push logs with labels\n    Loki-&gt;&gt;Loki: Store in filesystem&lt;br/&gt;(tsdb/v13)\n    Grafana-&gt;&gt;Loki: LogQL query\n    Loki-&gt;&gt;Grafana: Return results</code></pre> View Loki Configuration YAML<pre><code>---\nnamespaceOverride: \"infra\"\n\ndeploymentMode: SingleBinary\n\nsingleBinary:\n  replicas: 1\n  persistence:\n    size: 4Gi\n    storageClass: local-path-infra\n  resources:\n    requests:\n      cpu: \"100m\"\n      memory: \"200Mi\"\n    limits:\n      cpu: \"300m\"\n      memory: \"700Mi\"\n\ngateway:\n  enabled: false\n\n# Explicitly disable SimpleScalable components when in SingleBinary mode\nwrite:\n  replicas: 0\nread:\n  replicas: 0\nbackend:\n  replicas: 0\n\ningester:\n  replicas: 0\nquerier:\n  replicas: 0\nqueryFrontend:\n  replicas: 0\nqueryScheduler:\n  replicas: 0\ndistributor:\n  replicas: 0\ncompactor:\n  replicas: 0\nindexGateway:\n  replicas: 0\nbloomCompactor:\n  replicas: 0\nbloomGateway:\n  replicas: 0\n\nloki:\n  readinessProbe:\n    httpGet:\n      path: /ready\n      port: http-metrics\n    initialDelaySeconds: 60\n    timeoutSeconds: 1\n  image:\n    repository: grafana/loki\n    tag: \"3.6.2\"\n  sidecar:\n    skipTlsVerify: true\n  auth_enabled: false\n  analytics:\n    reporting_enabled: false\n  storage:\n    type: filesystem\n  commonConfig:\n    replication_factor: 1\n  pattern_ingester:\n    enabled: true\n  limits_config:\n    allow_structured_metadata: true\n    volume_enabled: true\n  ruler:\n    enable_api: true\n  schemaConfig:\n    configs:\n      - from: \"2024-04-01\"\n        store: tsdb\n        object_store: filesystem\n        schema: v13\n        index:\n          prefix: loki_index_\n          period: 24h\n\ntest:\n  enabled: false\n\nlokiCanary:\n  enabled: false\n\nmemberlist:\n  service:\n    publishNotReadyAddresses: true\n\nchunksCache:\n  resources:\n    requests:\n      cpu: \"100m\"\n      memory: \"200Mi\"\n    limits:\n      cpu: \"300m\"\n      memory: \"500Mi\"\n\nresultsCache:\n  resources:\n    requests:\n      cpu: \"100m\"\n      memory: \"200Mi\"\n    limits:\n      cpu: \"300m\"\n      memory: \"500Mi\"\n</code></pre> View Alloy Configuration YAML<pre><code>namespaceOverride: \"infra\" # Ensures Alloy is deployed in the 'infra' namespace.\n\nalloy:\n  # Storage path for persistence\n  storagePath: /data/alloy\n\n  # Add mounts for persistent storage\n  mounts:\n    varlog: true\n    dockercontainers: true\n    extra:\n      - name: storage\n        mountPath: /data/alloy\n\n  # Disable anonymous usage reporting\n  enableReporting: false\n\n  configMap:\n    content: |\n      logging {\n        level  = \"info\"\n        format = \"logfmt\"\n      }\n\n      loki.source.kubernetes \"pods\" {\n        targets    = discovery.kubernetes.pods_discovered.targets\n        forward_to = [loki.write.default.receiver]\n      }\n\n      loki.source.kubernetes_events \"example\" {\n        // Only watch for events in the kube-system namespace.\n        namespaces = [\"kube-system\", \"default\", \"infra\", \"htpc\", \"utils\"]\n        forward_to = [loki.write.default.receiver]\n      }\n\n      loki.write \"default\" {\n        endpoint {\n          url = \"http://loki.infra.svc.cluster.local:3100/loki/api/v1/push\"\n        }\n      }\n\n      // Step 1: Discover Kubernetes pods\n      discovery.kubernetes \"pods_discovered\" {\n        role = \"pod\"\n      }\n\n      // Step 2: Relabel the discovered targets using discovery.relabel\n      discovery.relabel \"pods_relabeled\" {\n        targets = discovery.kubernetes.pods_discovered.targets // Input from the discovery step\n\n        // Keep only pods with prometheus.io/scrape: true annotation\n        rule {\n          source_labels = [\"__meta_kubernetes_pod_annotation_prometheus_io_scrape\"]\n          action        = \"keep\"\n          regex         = \"true\"\n        }\n\n        // Relabeling rules to prepare targets for scraping\n        // Set metrics path from annotation, default to /metrics if not set\n        rule {\n          source_labels = [\"__meta_kubernetes_pod_annotation_prometheus_io_path\"]\n          target_label  = \"__metrics_path__\"\n          regex         = \"(.+)\"\n          replacement   = \"$1\"\n          action        = \"replace\"\n        }\n        // If the metrics path is empty, default to /metrics\n        rule {\n          source_labels = [\"__meta_kubernetes_pod_annotation_prometheus_io_path\"]\n          target_label  = \"__metrics_path__\"\n          regex         = \"^$\"\n          replacement   = \"/metrics\"\n          action        = \"replace\"\n        }\n        rule {\n          source_labels = [\"__address__\", \"__meta_kubernetes_pod_annotation_prometheus_io_port\"]\n          target_label  = \"__address__\"\n          regex         = \"([^:]+)(?::\\\\d+)?;(\\\\d+)\" // Ensure this regex correctly captures your intent\n          replacement   = \"$1:$2\"\n          action        = \"replace\"\n        }\n        rule {\n          source_labels = [\"__meta_kubernetes_namespace\"]\n          target_label  = \"kubernetes_namespace\"\n          action        = \"replace\"\n        }\n        rule {\n          source_labels = [\"__meta_kubernetes_pod_name\"]\n          target_label  = \"kubernetes_pod_name\"\n          action        = \"replace\"\n        }\n        rule {\n          source_labels = [\"__meta_kubernetes_pod_container_name\"]\n          target_label  = \"container_name\"\n          action        = \"replace\"\n        }\n        rule {\n          source_labels = [\"__meta_kubernetes_pod_label_app\"]\n          target_label  = \"app\"\n          action        = \"replace\"\n        }\n        rule {\n          source_labels = [\"__meta_kubernetes_pod_label_app_kubernetes_io_name\"]\n          target_label  = \"app_kubernetes_io_name\"\n          action        = \"replace\"\n        }\n        rule {\n          source_labels = [\"__meta_kubernetes_pod_label_app_kubernetes_io_instance\"]\n          target_label  = \"app_kubernetes_io_instance\"\n          action        = \"replace\"\n        }\n        rule {\n          source_labels = [\"__meta_kubernetes_pod_label_run\"]\n          target_label  = \"run\"\n          action        = \"replace\"\n        }\n      }\n\n      // Step 3: Scrape the (now relabeled) targets\n      prometheus.scrape \"kubernetes_pods\" {\n        targets    = discovery.relabel.pods_relabeled.output // Targets come from the discovery.relabel component\n        forward_to = [prometheus.remote_write.main.receiver]\n        job_name   = \"kubernetes-pods\"\n        // No relabel_config blocks are needed here as targets are pre-relabeled\n      }\n\n      prometheus.remote_write \"main\" {\n        endpoint {\n          url = \"http://kube-prometheus-stack-prometheus.infra.svc.cluster.local:9090/api/v1/write\"\n        }\n      }\n\n# Controller configuration - using StatefulSet for persistence\ncontroller:\n  type: \"statefulset\"\n  replicas: 1\n\n  # Using existing PVC instead of volumeClaimTemplates\n  volumes:\n    extra:\n      - name: storage\n        persistentVolumeClaim:\n          claimName: alloy-data-pvc\n\nservice:\n  annotations:\n    prometheus.io/scrape: \"true\"\n    prometheus.io/port: \"12345\"\n\n# We don't need ingress here as we're using IngressRoute CRD\ningress:\n  enabled: false\n\nserviceMonitor:\n  enabled: true\n  additionalLabels:\n    release: kube-prometheus-stack\n</code></pre>"},{"location":"architecture/observability/#loki-components","title":"Loki Components","text":"Component Role Features Loki Log Aggregation - Label-based queries- Log correlation- Real-time tailing Alloy Log Collection - Service discovery- Label extraction- Pipeline processing"},{"location":"architecture/observability/#log-collection","title":"Log Collection","text":"<p>Alloy (formerly Promtail) collects logs using Kubernetes service discovery, extracting pod metadata as labels for efficient querying in Loki.</p>"},{"location":"architecture/observability/#log-queries","title":"Log Queries","text":"<p>Loki uses LogQL for querying:</p> <ul> <li>Filter logs by namespace, pod, or other labels</li> <li>Search for specific text patterns (errors, warnings)</li> <li>Aggregate log counts over time windows</li> </ul>"},{"location":"architecture/observability/#distributed-tracing","title":"Distributed Tracing","text":""},{"location":"architecture/observability/#jaeger","title":"Jaeger","text":"<p>Jaeger provides distributed request tracing.</p> View Jaeger Configuration YAML<pre><code>namespaceOverride: \"infra\"\n\nprovisionDataStore:\n  cassandra: false\n  elasticsearch: false\n\nstorage:\n  type: badger\n  badger:\n    ephemeral: false\n    persistence:\n      enabled: true\n      useExistingPvcName: \"jaeger-data-pvc\"\n      storageClassName: local-path-infra\n      size: 10Gi\n\ncollector:\n  enabled: false\nquery:\n  enabled: false\nagent:\n  enabled: false\ningester:\n  enabled: false\nschema:\n  enabled: false\nspark:\n  enabled: false\nesIndexCleaner:\n  enabled: false\nesRollover:\n  enabled: false\n\nallInOne:\n  enabled: true\n  resources:\n    requests:\n      cpu: \"100m\"\n      memory: \"256Mi\"\n    limits:\n      cpu: \"300m\"\n      memory: \"768Mi\"\n</code></pre>"},{"location":"architecture/observability/#capabilities","title":"Capabilities","text":"Component Purpose Capabilities Jaeger Request Tracing - Latency analysis- Error tracking- Dependency mapping"},{"location":"architecture/observability/#trace-data","title":"Trace Data","text":"<p>Captured information:</p> <ul> <li>Request flow across services</li> <li>Latency at each step</li> <li>Error locations</li> <li>Service dependencies</li> </ul>"},{"location":"architecture/observability/#integration","title":"Integration","text":"<p>Instrument applications using OpenTelemetry SDK, configuring the OTLP endpoint to send traces to Jaeger collector.</p>"},{"location":"architecture/observability/#visualization--alerting","title":"Visualization &amp; Alerting","text":""},{"location":"architecture/observability/#grafana-dashboards","title":"Grafana Dashboards","text":"<p>Pre-configured dashboards for comprehensive monitoring:</p> Dashboard Focus Features ArgoCD GitOps Operations - Application sync status- Deployment health- API activity cert-manager Certificate Management - Certificate expiry- Renewal status- Issuer health Kubernetes Cluster Health - Resource usage- Node status- Pod metrics Loki Log Aggregation - Log volume- Error rates- Query performance Scraparr Media Automation - Service health- Request metrics- Error tracking HTPC Media Services - Arr stack metrics- Download progress- Resource usage <p>Dashboard Sources</p> <p>Dashboard definitions are stored as ConfigMaps in <code>base/infra/monitoring/*-dashboard-cm.yaml</code> files and are automatically provisioned into Grafana via sidecar containers.</p>"},{"location":"architecture/observability/#dashboard-access","title":"Dashboard Access","text":"<p>Access Grafana via port-forward:</p> Bash<pre><code>kubectl port-forward -n infra svc/grafana 3000:80\n</code></pre> <p>Then visit <code>http://localhost:3000</code> with default credentials <code>admin</code>/<code>admin</code> (change on first login).</p>"},{"location":"architecture/observability/#custom-dashboards","title":"Custom Dashboards","text":"<p>Create custom dashboards using:</p> <ul> <li>PromQL for metrics</li> <li>LogQL for logs</li> <li>Template variables</li> <li>Panel plugins</li> </ul>"},{"location":"architecture/observability/#alerting","title":"Alerting","text":""},{"location":"architecture/observability/#alert-rules","title":"Alert Rules","text":"<p>PrometheusRule Template</p> <p>Alert rules can be defined using PrometheusRule CRDs. Below is a template example:</p> YAML<pre><code>apiVersion: monitoring.coreos.com/v1\nkind: PrometheusRule\nmetadata:\nname: app-alerts\nnamespace: infra\nspec:\ngroups:\n    - name: app\n    interval: 30s\n    rules:\n        - alert: HighErrorRate\n        expr: |\n            rate(http_errors_total[5m]) &gt; 0.05\n        for: 5m\n        labels:\n            severity: warning\n        annotations:\n            summary: \"High error rate detected\"\n            description: \"Error rate is {{ $value }} errors/sec\"\n</code></pre> <p>Current Alert Configuration</p> <p>Alert rules are currently managed through the kube-prometheus-stack default rules. Custom PrometheusRule resources can be added as needed following the template above.</p>"},{"location":"architecture/observability/#alert-configuration","title":"Alert Configuration","text":"<p>Alertmanager Setup</p> <p>Alertmanager is deployed and ready for configuration. Alert routing and notification channels can be configured by updating the Alertmanager configuration.</p> <p>Supported notification channels include:</p> <ul> <li>Slack: Real-time notifications</li> <li>Email: Detailed alert information</li> <li>PagerDuty: On-call escalation</li> <li>Webhook: Custom integrations</li> </ul>"},{"location":"architecture/observability/#alert-severity-levels","title":"Alert Severity Levels","text":"<ul> <li>Critical: Immediate action required</li> <li>Warning: Attention needed soon</li> <li>Info: Informational only</li> </ul>"},{"location":"architecture/observability/#monitoring-best-practices","title":"Monitoring Best Practices","text":""},{"location":"architecture/observability/#metrics","title":"Metrics","text":"<ul> <li>Use labels wisely: Avoid high cardinality</li> <li>Set appropriate intervals: Balance accuracy and load</li> <li>Monitor what matters: Focus on business metrics</li> <li>Set SLOs: Define service level objectives</li> </ul>"},{"location":"architecture/observability/#logs","title":"Logs","text":"<ul> <li>Structured logging: Use JSON format</li> <li>Consistent labels: Standardize label names</li> <li>Appropriate levels: Use correct log levels</li> <li>Sampling: Sample high-volume logs</li> </ul>"},{"location":"architecture/observability/#traces","title":"Traces","text":"<ul> <li>Sample strategically: 100% for errors, sample successes</li> <li>Tag appropriately: Add meaningful tags</li> <li>Monitor overhead: Keep instrumentation lightweight</li> <li>Correlate with logs: Link traces to log entries</li> </ul>"},{"location":"architecture/observability/#performance-optimization","title":"Performance Optimization","text":""},{"location":"architecture/observability/#prometheus","title":"Prometheus","text":"<p>Key configuration parameters:</p> <ul> <li>Retention: 7 days time-based</li> <li>Storage: 10Gi persistent volume</li> <li>Resources: 256Mi-768Mi memory, 150m-400m CPU</li> <li>Configuration can be adjusted based on metric cardinality and query load</li> </ul>"},{"location":"architecture/observability/#loki","title":"Loki","text":"<p>Optimize log ingestion and storage:</p> <ul> <li>Deployment mode: SingleBinary</li> <li>Storage: 4Gi persistent volume with local-path-infra storage class</li> <li>Resources: 200Mi-700Mi memory, 100m-300m CPU</li> <li>Storage backend: Filesystem (tsdb with v13 schema)</li> <li>Retention policies can be configured based on storage capacity</li> </ul>"},{"location":"architecture/observability/#jaeger-configuration","title":"Jaeger Configuration","text":"<p>Jaeger deployment configuration:</p> <ul> <li>Deployment mode: All-in-One</li> <li>Storage backend: Badger (embedded database)</li> <li>Storage: 10Gi persistent volume</li> <li>Resources: 256Mi-768Mi memory, 100m-300m CPU</li> <li>Sampling configuration can be adjusted at the application level using OpenTelemetry SDK</li> </ul>"},{"location":"architecture/observability/#data-retention","title":"Data Retention","text":"Component Current Retention Storage Configurable Prometheus 7 days 10Gi PVC Yes Loki Volume-based 4Gi PVC Yes Jaeger Storage-based 10Gi PVC Yes Grafana Unlimited Existing PVC N/A"},{"location":"architecture/observability/#troubleshooting","title":"Troubleshooting","text":""},{"location":"architecture/observability/#prometheus-issues","title":"Prometheus Issues","text":"Bash<pre><code># Check Prometheus pods\nkubectl get pods -n infra -l app.kubernetes.io/name=prometheus\n\n# View Prometheus logs\nkubectl logs -n infra -l app.kubernetes.io/name=prometheus\n\n# Check targets\nkubectl port-forward -n infra svc/kube-prometheus-stack-prometheus 9090:9090\n# Visit http://localhost:9090/targets\n\n# Check service monitors\nkubectl get servicemonitor -A\n</code></pre>"},{"location":"architecture/observability/#loki-issues","title":"Loki Issues","text":"Bash<pre><code># Check Loki pods\nkubectl get pods -n infra -l app.kubernetes.io/name=loki\n\n# View Loki logs\nkubectl logs -n infra -l app.kubernetes.io/name=loki\n\n# Test log query\nkubectl port-forward -n infra svc/loki 3100:3100\ncurl -G -s \"http://localhost:3100/loki/api/v1/query\" \\\n  --data-urlencode 'query={namespace=\"utils\"}'\n</code></pre>"},{"location":"architecture/observability/#grafana-issues","title":"Grafana Issues","text":"Bash<pre><code># Check Grafana pods\nkubectl get pods -n infra -l app.kubernetes.io/name=grafana\n\n# View Grafana logs\nkubectl logs -n infra -l app.kubernetes.io/name=grafana\n\n# Reset admin password\nkubectl exec -n infra $(kubectl get pod -n infra -l app.kubernetes.io/name=grafana \\\n  -o jsonpath='{.items[0].metadata.name}') -- grafana-cli admin reset-admin-password newpassword\n</code></pre>"},{"location":"architecture/observability/#jaeger-issues","title":"Jaeger Issues","text":"Bash<pre><code># Check Jaeger pods (all-in-one deployment)\nkubectl get pods -n infra -l app.kubernetes.io/name=jaeger\n\n# View Jaeger logs\nkubectl logs -n infra -l app.kubernetes.io/name=jaeger\n\n# Access Jaeger UI\nkubectl port-forward -n infra svc/jaeger-query 16686:16686\n# Visit http://localhost:16686\n</code></pre>"},{"location":"architecture/observability/#monitoring-checklist","title":"Monitoring Checklist","text":"<p>Regular monitoring health checks:</p> <ul> <li> All monitoring pods are running</li> <li> Prometheus targets are up</li> <li> Logs are being ingested</li> <li> Dashboards are loading</li> <li> Alerts are configured</li> <li> Alert channels are working</li> <li> Retention policies are set</li> <li> Storage is not full</li> <li> Performance is acceptable</li> </ul>"},{"location":"architecture/observability/#related-documentation","title":"Related Documentation","text":"<ul> <li>Kubernetes Infrastructure - Cluster monitoring</li> <li>Networking - Network metrics</li> <li>Services - Observability services</li> </ul>"},{"location":"architecture/observability/#abbreviations","title":"Abbreviations","text":""},{"location":"architecture/overview/","title":"Architecture Overview","text":"<p>The homelab platform employs a modern microservices architecture, with each component running as a Kubernetes service. This design provides flexibility, scalability, and maintainability while following cloud-native best practices.</p>"},{"location":"architecture/overview/#system-design","title":"System Design","text":""},{"location":"architecture/overview/#design-philosophy","title":"Design Philosophy","text":"<p>Architecture Principles</p> <p>This setup embraces the Infrastructure as Code (IaC) paradigm, using declarative configurations to ensure reproducibility and maintainability. The architecture follows cloud-native principles while being optimized for home deployment.</p>"},{"location":"architecture/overview/#core-principles","title":"Core Principles","text":""},{"location":"architecture/overview/#microservices-architecture","title":"Microservices Architecture","text":"<p>Each service is independently deployable and scalable, with clear boundaries and responsibilities.</p>"},{"location":"architecture/overview/#declarative-configuration","title":"Declarative Configuration","text":"<p>All infrastructure is defined in version-controlled YAML files, ensuring consistency and reproducibility.</p>"},{"location":"architecture/overview/#gitops-workflow","title":"GitOps Workflow","text":"<p>Changes flow through Git, with automated synchronization to maintain desired state.</p>"},{"location":"architecture/overview/#defense-in-depth","title":"Defense in Depth","text":"<p>Multiple security layers protect services and data at every level.</p>"},{"location":"architecture/overview/#high-level-architecture","title":"High-Level Architecture","text":""},{"location":"architecture/overview/#layer-breakdown","title":"Layer Breakdown","text":"<p>The platform consists of several distinct layers, each serving a specific purpose:</p>"},{"location":"architecture/overview/#1-external-access-layer","title":"1. External Access Layer","text":"<ul> <li>DNS Management: Cloudflare provides DNS resolution and DDoS protection</li> <li>Certificate Authority: Let's Encrypt issues TLS certificates</li> <li>Edge Security: Cloudflare WAF and proxy protection</li> </ul>"},{"location":"architecture/overview/#2-ingress-layer","title":"2. Ingress Layer","text":"<ul> <li>Load Balancing: MetalLB assigns external IPs to services</li> <li>Reverse Proxy: Traefik routes traffic to appropriate services</li> <li>TLS Termination: Automatic HTTPS with cert-manager</li> <li>Authentication: Middleware for access control</li> </ul>"},{"location":"architecture/overview/#3-application-layer","title":"3. Application Layer","text":"<ul> <li>Core Infrastructure: ArgoCD, monitoring, storage provisioners</li> <li>Personal Cloud: Nextcloud, Immich, Tandoor</li> <li>Media Services: Complete media automation stack</li> <li>Utility Services: Homepage dashboard, databases</li> </ul>"},{"location":"architecture/overview/#4-data-layer","title":"4. Data Layer","text":"<ul> <li>Relational Database: CloudNativePG for PostgreSQL</li> <li>Caching: Redis for Nextcloud caching, Valkey for Immich caching</li> <li>Persistent Storage: Local-path-provisioner for volumes</li> </ul>"},{"location":"architecture/overview/#5-observability-layer","title":"5. Observability Layer","text":"<ul> <li>Metrics: Prometheus collects and stores time-series data</li> <li>Visualization: Grafana displays dashboards and alerts</li> <li>Logging: Loki aggregates logs from all services</li> <li>Tracing: Jaeger tracks distributed requests</li> </ul>"},{"location":"architecture/overview/#architecture-characteristics","title":"Architecture Characteristics","text":""},{"location":"architecture/overview/#scalability","title":"Scalability","text":"<p>The architecture supports both vertical and horizontal scaling:</p> <ul> <li>Vertical: Increase resource allocations per service</li> <li>Horizontal: Add more replicas for high-availability</li> </ul>"},{"location":"architecture/overview/#reliability","title":"Reliability","text":"<p>Multiple mechanisms ensure system reliability:</p> <ul> <li>Health Checks: Kubernetes liveness and readiness probes</li> <li>Self-Healing: Automatic restart of failed containers</li> <li>Rolling Updates: Zero-downtime deployments</li> <li>Rollback Capability: Quick reversion to previous versions</li> </ul>"},{"location":"architecture/overview/#maintainability","title":"Maintainability","text":"<p>The system is designed for easy maintenance:</p> <ul> <li>Modular Design: Independent service updates</li> <li>Clear Separation: Namespace isolation</li> <li>Automated Updates: Renovate Bot for dependencies</li> <li>Documentation: Inline comments and external docs</li> </ul>"},{"location":"architecture/overview/#security","title":"Security","text":"<p>Security is embedded at every layer:</p> <ul> <li>Network Policies: Control traffic between services</li> <li>Secret Management: Encrypted storage of sensitive data</li> <li>TLS Everywhere: End-to-end encryption</li> <li>RBAC: Role-based access control</li> </ul>"},{"location":"architecture/overview/#component-interaction","title":"Component Interaction","text":""},{"location":"architecture/overview/#service-communication","title":"Service Communication","text":"<p>Services communicate through well-defined interfaces:</p> <pre><code>graph LR\n    A[Client] --&gt; | HTTPS | B[Traefik]\n    B --&gt; | HTTP | C[Service]\n    C --&gt; | SQL | D[PostgreSQL]\n    C --&gt; | Cache | E[Redis]\n    C --&gt; | Storage | F[PVC]</code></pre>"},{"location":"architecture/overview/#data-flow","title":"Data Flow","text":"<p>Data flows through the system in a controlled manner:</p> <pre><code>graph TD\n    A[User Request] --&gt; B[DNS Resolution]\n    B --&gt; C[Load Balancer]\n    C --&gt; D[Traefik]\n    D --&gt; E{Authentication}\n    E --&gt; | Authorized | F[Application]\n    E --&gt; | Denied | G[403 Response]\n    F --&gt; H[Database]\n    F --&gt; I[Cache]\n    F --&gt; J[Storage]</code></pre>"},{"location":"architecture/overview/#deployment-model","title":"Deployment Model","text":""},{"location":"architecture/overview/#environment-separation","title":"Environment Separation","text":"<p>The platform supports multiple environments:</p> <ul> <li>Staging: Testing and development</li> <li>Production: Live services</li> </ul> <p>Each environment has:</p> <ul> <li>Separate namespaces</li> <li>Independent configurations</li> <li>Isolated resources</li> </ul>"},{"location":"architecture/overview/#configuration-management","title":"Configuration Management","text":"<p>Configurations are managed through Kustomize:</p> Text Only<pre><code>base/\n\u251c\u2500\u2500 htpc/\n\u251c\u2500\u2500 infra/\n\u2514\u2500\u2500 utils/\n\noverlays/\n\u251c\u2500\u2500 staging-infra/\n\u251c\u2500\u2500 staging-ingress/\n\u251c\u2500\u2500 production-infra/\n\u2514\u2500\u2500 production-ingress/\n</code></pre>"},{"location":"architecture/overview/#architectural-decisions","title":"Architectural Decisions","text":""},{"location":"architecture/overview/#why-k3s","title":"Why k3s?","text":"<p>k3s was chosen for its:</p> <ul> <li>Lightweight footprint: Minimal resource overhead</li> <li>Single binary: Easy installation and updates</li> <li>Built-in components: Traefik, local-path-provisioner included</li> <li>Production-ready: CNCF certified Kubernetes</li> </ul>"},{"location":"architecture/overview/#why-argocd","title":"Why ArgoCD?","text":"<p>ArgoCD provides:</p> <ul> <li>GitOps workflow: Git as single source of truth</li> <li>Automated sync: Continuous deployment</li> <li>Drift detection: Alerts when cluster state diverges</li> <li>Rollback capability: Easy reversion to previous states</li> </ul>"},{"location":"architecture/overview/#why-kustomize","title":"Why Kustomize?","text":"<p>Kustomize offers:</p> <ul> <li>Native Kubernetes: Built into kubectl</li> <li>No templating: Pure YAML with overlays</li> <li>Composability: Layer configurations easily</li> <li>Simplicity: Easy to understand and maintain</li> </ul>"},{"location":"architecture/overview/#design-patterns","title":"Design Patterns","text":""},{"location":"architecture/overview/#12-factor-app-principles","title":"12-Factor App Principles","text":"<p>The platform follows the 12-Factor App methodology:</p> <ol> <li>Codebase: One codebase in version control</li> <li>Dependencies: Explicitly declared</li> <li>Config: Stored in environment</li> <li>Backing services: Attached resources</li> <li>Build, release, run: Strict separation</li> <li>Processes: Stateless execution</li> <li>Port binding: Self-contained services</li> <li>Concurrency: Scale out via process model</li> <li>Disposability: Fast startup and graceful shutdown</li> <li>Dev/prod parity: Keep environments similar</li> <li>Logs: Treat logs as event streams</li> <li>Admin processes: Run as one-off processes</li> </ol>"},{"location":"architecture/overview/#service-mesh-ready","title":"Service Mesh Ready","text":"<p>The architecture can be extended with a service mesh:</p> <ul> <li>Istio: For advanced traffic management</li> <li>Linkerd: For simplicity and performance</li> <li>Consul: For service discovery</li> </ul> <p>Currently, basic service-to-service communication is sufficient, but the design allows for future mesh integration.</p>"},{"location":"architecture/overview/#operational-considerations","title":"Operational Considerations","text":""},{"location":"architecture/overview/#resource-management","title":"Resource Management","text":"<p>Resources are allocated per namespace:</p> <ul> <li>Resource Quotas: Limit total resource consumption</li> <li>Limit Ranges: Set default and max limits</li> <li>Priority Classes: Ensure critical services get resources</li> </ul>"},{"location":"architecture/overview/#backup-strategy","title":"Backup Strategy","text":"<p>Data protection through:</p> <ul> <li>Git repository: Configuration backups</li> <li>Persistent volume snapshots: Data backups</li> <li>Database dumps: Regular SQL exports</li> </ul>"},{"location":"architecture/overview/#disaster-recovery","title":"Disaster Recovery","text":"<p>Recovery procedures:</p> <ol> <li>Configuration: Restore from Git</li> <li>Data: Restore from volume snapshots</li> <li>Redeploy: Run kickstart script</li> <li>Verify: Check application health</li> </ol>"},{"location":"architecture/overview/#future-enhancements","title":"Future Enhancements","text":"<p>Potential architectural improvements:</p> <ul> <li>Multi-cluster: Expand to multiple clusters</li> <li>Service mesh: Advanced traffic management</li> <li>External secrets: HashiCorp Vault integration</li> <li>Automated backups: Velero for disaster recovery</li> <li>Edge computing: Deploy edge nodes for local processing</li> </ul>"},{"location":"architecture/overview/#related-documentation","title":"Related Documentation","text":"<ul> <li>Kubernetes Infrastructure - Cluster details</li> <li>Networking - Ingress and routing</li> <li>Storage - Persistent storage</li> <li>Security - Security architecture</li> </ul>"},{"location":"architecture/overview/#abbreviations","title":"Abbreviations","text":""},{"location":"architecture/security/","title":"Security Architecture","text":"<p>The security framework is built on multiple layers of protection, implementing defense-in-depth principles to protect services and data.</p>"},{"location":"architecture/security/#security-philosophy","title":"Security Philosophy","text":"<p>Defense in Depth</p> <p>Security is implemented at every layer of the stack, with multiple overlapping controls working together to protect services and data. No single point of failure compromises the entire system.</p>"},{"location":"architecture/security/#security-architecture-overview","title":"Security Architecture Overview","text":"<pre><code>graph TB\n    subgraph \"Layer 5: DNS Security\"\n        CF[Cloudflare]\n        CF --&gt; |DDoS Protection| CF\n        CF --&gt; |WAF| CF\n        CF --&gt; |Proxy| CF\n    end\n\n    subgraph \"Layer 4: Secrets Management\"\n        SOPS[SOPS + AGE]\n        KSOPS[KSOPS]\n        K8S_SEC[Kubernetes Secrets]\n        SOPS --&gt; KSOPS\n        KSOPS --&gt; K8S_SEC\n    end\n\n    subgraph \"Layer 3: Network Security\"\n        NP[Network Policies]\n        NS[Namespace Isolation]\n        IG[Ingress Control]\n    end\n\n    subgraph \"Layer 2: Access Control\"\n        RBAC[RBAC]\n        SA[Service Accounts]\n        AUTH[Authentication]\n    end\n\n    subgraph \"Layer 1: Transport Security\"\n        TLS[TLS 1.2/1.3]\n        CERT[cert-manager]\n        LE[Let's Encrypt]\n        CERT --&gt; LE\n    end\n\n    CF --&gt; TLS\n    TLS --&gt; IG\n    IG --&gt; NS\n    NS --&gt; NP\n    RBAC --&gt; K8S_SEC\n    AUTH --&gt; RBAC</code></pre>"},{"location":"architecture/security/#security-layers","title":"Security Layers","text":"<p>The platform implements security at five distinct layers:</p>"},{"location":"architecture/security/#1-transport-security","title":"1. Transport Security","text":""},{"location":"architecture/security/#ssltls-implementation","title":"SSL/TLS Implementation","text":"<p>\ud83d\udee1\ufe0f Automated Certificate Management</p> <ul> <li>Let's Encrypt integration via cert-manager</li> <li>Automatic certificate renewal</li> <li>Wildcard certificates for all subdomains</li> <li>DNS-01 challenge for validation</li> </ul> <p>\ud83d\udd12 Modern TLS Configuration</p> <ul> <li>TLS 1.2 and 1.3 only</li> <li>Strong cipher suites</li> <li>Perfect Forward Secrecy (PFS)</li> <li>OCSP stapling</li> </ul>"},{"location":"architecture/security/#configuration-example","title":"Configuration Example","text":"<p>TLS options are configured via Traefik TLSOption CRDs specifying minimum TLS version, allowed cipher suites, and curve preferences. Security headers are enforced through Traefik middleware.</p> View security headers configuration <p>apiVersion: traefik.io/v1alpha1 kind: Middleware metadata:   name: default-headers spec:   headers:     browserXssFilter: true     contentTypeNosniff: true     forceSTSHeader: true     stsIncludeSubdomains: true     stsPreload: true     stsSeconds: 31536000     customFrameOptionsValue: DENY     referrerPolicy: no-referrer     contentSecurityPolicy: \"default-src 'none'; script-src 'self' 'unsafe-inline' 'unsafe-eval' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' https: data:; connect-src 'self' https:; frame-src 'self' https:; media-src 'self' https:; object-src 'none'; frame-ancestors 'self'; base-uri 'self'; form-action 'self';\"     customRequestHeaders:       X-Forwarded-Proto: https     customResponseHeaders:       Referrer-Policy: strict-origin-when-cross-origin       Permissions-Policy: geolocation=(), midi=(), sync-xhr=(), microphone=(), camera=(), magnetometer=(), gyroscope=(), fullscreen=(self), payment=()       X-Content-Type-Options: nosniff       X-Frame-Options: DENY       X-XSS-Protection: 1; mode=block     sslRedirect: true     sslForceHost: true     sslProxyHeaders:       X-Forwarded-Proto: https     accessControlAllowMethods:       - GET       - POST       - PUT       - DELETE       - OPTIONS     accessControlAllowHeaders:       - Content-Type       - Authorization     accessControlMaxAge: 3600     addVaryHeader: true</p>"},{"location":"architecture/security/#2-access-control","title":"2. Access Control","text":""},{"location":"architecture/security/#authentication-strategy","title":"Authentication Strategy","text":"<p>\ud83d\udd11 Multi-Factor Capability</p> <ul> <li>Support for 2FA/MFA where available</li> <li>OAuth2 integration ready</li> <li>LDAP/SSO integration possible</li> </ul> <p>\ud83d\udc64 Role-Based Access Control (RBAC)</p> <ul> <li>Kubernetes RBAC for cluster access</li> <li>Application-level permissions</li> <li>Least privilege principle</li> <li>Service accounts with limited scope</li> </ul> <p>RBAC Implementation</p> <p>RBAC is implemented for specific services like cert-manager, ArgoCD, and homepage that require cluster API access. See <code>base/infra/cert-manager/role.yaml</code> and related RBAC files.</p> <p>\ud83d\udee1\ufe0f Session Management</p> <ul> <li>Secure session cookies</li> <li>Session timeout policies</li> <li>Session invalidation on logout</li> </ul> <p>\ud83d\udeab Brute Force Protection</p> <ul> <li>Rate limiting middleware</li> <li>Account lockout policies</li> <li>IP-based blocking</li> </ul>"},{"location":"architecture/security/#3-network-security","title":"3. Network Security","text":""},{"location":"architecture/security/#network-policies","title":"Network Policies","text":"<p>\ud83c\udf10 Namespace Isolation</p> <p>Namespace-level isolation provides the primary network boundary. NetworkPolicies are implemented for ArgoCD to control inter-component communication.</p> <p>\ud83d\udd17 Inter-Service Communication Control</p> <p>Services communicate within namespaces using Kubernetes DNS. Cross-namespace communication is controlled through service exposure and ingress rules.</p> <p>\ud83d\udd12 Egress Traffic Filtering</p> <ul> <li>Services access external APIs as needed</li> <li>Cloudflare provides edge-level filtering</li> <li>Future: Implement explicit egress policies</li> </ul>"},{"location":"architecture/security/#pod-security-standards","title":"Pod Security Standards","text":"<p>Implementation Status</p> <p>Pod Security Standards can be enforced at the namespace level using labels. Current implementation focuses on container-level security contexts (fsGroup, supplementalGroups) for file access control, particularly for media services and databases.</p>"},{"location":"architecture/security/#4-secrets-management","title":"4. Secrets Management","text":""},{"location":"architecture/security/#secure-configuration","title":"Secure Configuration","text":"<p>\ud83e\udd2b Encrypted Secrets Storage</p> <ul> <li>SOPS with AGE encryption: Secrets encrypted in Git</li> <li>KSOPS: Kustomize integration for automatic decryption</li> <li>Kubernetes Secrets: Runtime secrets in cluster</li> <li>Encryption at rest: etcd encryption for cluster secrets</li> </ul> <p>\ud83d\udd10 Runtime Injection</p> <ul> <li>Secrets mounted as volumes or environment variables</li> <li>SOPS decryption during kustomize build</li> <li>No plaintext secrets in Git repository</li> </ul> <p>\u267b\ufe0f Rotation Policies</p> <ul> <li>Cloudflare API token for cert-manager</li> <li>AGE encryption keys for SOPS</li> <li>Manual rotation process with secret updates</li> </ul> <p>\ud83d\udd11 Least Privilege Principle</p> <ul> <li>Secrets scoped to namespaces</li> <li>ServiceAccount token projection</li> <li>Minimal secret exposure through RBAC</li> </ul>"},{"location":"architecture/security/#secret-example","title":"Secret Example","text":"<p>Secrets are encrypted using SOPS before committing to Git. The CI/CD pipeline uses AGE keys to decrypt secrets during validation and deployment.</p> View SOPS configuration <p>See <code>.sops.yaml</code> in repository root for encryption rules.</p>"},{"location":"architecture/security/#5-dns-security","title":"5. DNS Security","text":""},{"location":"architecture/security/#cloudflare-integration","title":"Cloudflare Integration","text":"<p>\u2601\ufe0f DDoS Protection</p> <ul> <li>Automatic DDoS mitigation</li> <li>Rate limiting at edge</li> <li>Traffic filtering</li> </ul> <p>\ud83d\udee1\ufe0f WAF Capabilities</p> <ul> <li>Web Application Firewall rules</li> <li>OWASP top 10 protection</li> <li>Custom rule creation</li> </ul> <p>\ud83d\udd12 DNS-Based Authentication</p> <ul> <li>DNS-01 ACME challenges</li> <li>Secure certificate issuance</li> <li>Private network compatible</li> </ul> <p>\ud83c\udf10 Proxy Protection</p> <ul> <li>Hide origin IP address</li> <li>SSL/TLS termination at edge</li> <li>Bot protection</li> </ul>"},{"location":"architecture/security/#security-monitoring","title":"Security Monitoring","text":""},{"location":"architecture/security/#audit-logging","title":"Audit Logging","text":"<p>Kubernetes audit logs track all API server access, recording who did what and when. Configure audit policies to capture metadata-level information for sensitive resources like secrets while minimizing storage overhead.</p>"},{"location":"architecture/security/#intrusion-detection","title":"Intrusion Detection","text":"<p>Monitor for suspicious activity:</p> <ul> <li>Failed authentication attempts</li> <li>Unusual API access patterns</li> <li>Privilege escalation attempts</li> <li>Resource abuse</li> </ul>"},{"location":"architecture/security/#vulnerability-scanning","title":"Vulnerability Scanning","text":"<p>Approaches for vulnerability management:</p> <ul> <li>Dependencies: Renovate Bot for automated updates</li> <li>Secret detection: TruffleHog in CI pipeline</li> </ul>"},{"location":"architecture/security/#security-best-practices","title":"Security Best Practices","text":""},{"location":"architecture/security/#container-security","title":"Container Security","text":"<ul> <li>Security contexts: Used for filesystem permissions (fsGroup, supplementalGroups)</li> <li>Minimal base images: Use official images from trusted sources</li> <li>Resource limits: CPU and memory limits defined per container</li> <li>Image updates: Automated via Renovate Bot</li> </ul> <p>Actual Implementation</p> <p>Most services use <code>securityContext</code> with <code>fsGroup</code> (typically 1000) for volume access:     YAML<pre><code>securityContext:\nfsGroup: 1000\n</code></pre></p> <p>Some services like Jellyfin require privileged mode for hardware access (GPU transcoding):     YAML<pre><code>securityContext:\nprivileged: true\n</code></pre></p>"},{"location":"architecture/security/#network-security","title":"Network Security","text":"<ul> <li>TLS everywhere: All external and internal traffic</li> <li>Network segmentation: Use NetworkPolicies</li> <li>Ingress filtering: Only expose necessary services</li> <li>Egress control: Limit outbound connections</li> </ul>"},{"location":"architecture/security/#access-control","title":"Access Control","text":"<ul> <li>Principle of least privilege: Minimal permissions</li> <li>Regular audits: Review access permissions</li> <li>MFA enforcement: Enable where supported</li> <li>Password policies: Strong passwords, rotation</li> </ul>"},{"location":"architecture/security/#data-protection","title":"Data Protection","text":"<ul> <li>Encryption at rest: Disk encryption (LUKS)</li> <li>Encryption in transit: TLS for all communication</li> <li>Backup encryption: Encrypted backups</li> <li>Data minimization: Only store necessary data</li> </ul>"},{"location":"architecture/security/#compliance-considerations","title":"Compliance Considerations","text":""},{"location":"architecture/security/#data-privacy","title":"Data Privacy","text":"<ul> <li>GDPR considerations: Data subject rights</li> <li>Data location: Know where data is stored</li> <li>Data retention: Implement retention policies</li> <li>Audit trails: Track data access</li> </ul>"},{"location":"architecture/security/#security-standards","title":"Security Standards","text":"<ul> <li>CIS Kubernetes Benchmark: Follow hardening guidelines</li> <li>NIST Framework: Align with cybersecurity framework</li> <li>ISO 27001: Information security management</li> </ul>"},{"location":"architecture/security/#incident-response","title":"Incident Response","text":""},{"location":"architecture/security/#detection","title":"Detection","text":"<ul> <li>Automated alerting on security events</li> <li>Log aggregation and analysis</li> <li>Anomaly detection</li> </ul>"},{"location":"architecture/security/#response","title":"Response","text":"<ol> <li>Identify: Determine scope and impact</li> <li>Contain: Isolate affected systems</li> <li>Eradicate: Remove threat</li> <li>Recover: Restore to normal operations</li> <li>Learn: Post-incident analysis</li> </ol>"},{"location":"architecture/security/#recovery","title":"Recovery","text":"<ul> <li>Backup restoration procedures</li> <li>Service priority matrix</li> <li>Communication plans</li> </ul>"},{"location":"architecture/security/#security-checklist","title":"Security Checklist","text":"<p>Regular security review checklist:</p> <ul> <li> All services use TLS</li> <li> Certificates are valid and not expiring</li> <li> NetworkPolicies are in place</li> <li> RBAC is properly configured</li> <li> Secrets are encrypted and rotated</li> <li> Container images are up-to-date</li> <li> Vulnerability scans are clean</li> <li> Audit logs are being collected</li> <li> Backups are encrypted and tested</li> <li> Access controls are reviewed</li> </ul>"},{"location":"architecture/security/#troubleshooting","title":"Troubleshooting","text":""},{"location":"architecture/security/#certificate-issues","title":"Certificate Issues","text":"Bash<pre><code># Check certificate status\nkubectl get certificate -A\n\n# Describe certificate\nkubectl describe certificate &lt;name&gt; -n &lt;namespace&gt;\n\n# Check cert-manager logs\nkubectl logs -n infra -l app=cert-manager\n</code></pre>"},{"location":"architecture/security/#authentication-problems","title":"Authentication Problems","text":"Bash<pre><code># Check RBAC permissions\nkubectl auth can-i &lt;verb&gt; &lt;resource&gt; --as=&lt;user&gt;\n\n# List roles and rolebindings\nkubectl get roles,rolebindings -n &lt;namespace&gt;\n\n# Describe specific role\nkubectl describe role &lt;name&gt; -n &lt;namespace&gt;\n</code></pre>"},{"location":"architecture/security/#network-policy-issues","title":"Network Policy Issues","text":"Bash<pre><code># Test connectivity\nkubectl exec -it &lt;pod&gt; -n &lt;namespace&gt; -- curl &lt;service&gt;\n\n# Check network policies\nkubectl get networkpolicy -n &lt;namespace&gt;\n\n# Describe policy\nkubectl describe networkpolicy &lt;name&gt; -n &lt;namespace&gt;\n</code></pre>"},{"location":"architecture/security/#related-documentation","title":"Related Documentation","text":"<ul> <li>Networking - Network architecture</li> <li>Configuration: Secrets - Secret management</li> <li>Observability - Security monitoring</li> </ul>"},{"location":"architecture/security/#abbreviations","title":"Abbreviations","text":""},{"location":"architecture/storage/","title":"Storage Architecture","text":"<p>The storage architecture provides persistent data storage for applications with dynamic provisioning, namespace isolation, and performance optimization.</p>"},{"location":"architecture/storage/#storage-principles","title":"Storage Principles","text":"<p>The storage design follows these core principles:</p>"},{"location":"architecture/storage/#dynamic-provisioning","title":"Dynamic Provisioning","text":"<ul> <li>Automated volume management</li> <li>Just-in-time resource allocation</li> <li>Flexible capacity planning</li> <li>No manual PV creation</li> </ul>"},{"location":"architecture/storage/#namespace-isolation","title":"Namespace Isolation","text":"<ul> <li>Dedicated StorageClasses per namespace</li> <li>Independent scaling capabilities</li> <li>Granular access control</li> <li>Resource quota enforcement</li> </ul>"},{"location":"architecture/storage/#performance-optimization","title":"Performance Optimization","text":"<ul> <li>Local path provisioning for low latency</li> <li>Direct volume access</li> <li>Optimized for media streaming</li> <li>Fast random access for databases</li> </ul> <p>Storage Design</p> <p>The storage architecture prioritizes performance and reliability while maintaining flexibility for future growth.</p>"},{"location":"architecture/storage/#local-path-provisioner","title":"Local Path Provisioner","text":"<p>The platform uses local-path-provisioner for dynamic storage.</p>"},{"location":"architecture/storage/#features","title":"Features","text":"<ul> <li>Dynamic PV creation: Automatic volume provisioning</li> <li>Local storage: Uses host filesystem</li> <li>Low latency: Direct disk access</li> <li>Simple configuration: No external dependencies</li> </ul>"},{"location":"architecture/storage/#configuration","title":"Configuration","text":"<p>The platform uses namespace-specific StorageClasses, each provisioning volumes to dedicated directories.</p> View StorageClass configuration <p>apiVersion: storage.k8s.io/v1 kind: StorageClass metadata:   name: local-path-infra   annotations:     storageclass.kubernetes.io/is-default-class: \"false\" provisioner: rancher.io/local-path reclaimPolicy: Retain volumeBindingMode: WaitForFirstConsumer parameters:   nodePath: /opt/cluster/infra</p> <p>apiVersion: storage.k8s.io/v1 kind: StorageClass metadata:   name: local-path-htpc   annotations:     storageclass.kubernetes.io/is-default-class: \"false\" provisioner: rancher.io/local-path reclaimPolicy: Retain volumeBindingMode: WaitForFirstConsumer parameters:   nodePath: /opt/cluster/htpc</p> <p>apiVersion: storage.k8s.io/v1 kind: StorageClass metadata:   name: local-path-utils   annotations:     storageclass.kubernetes.io/is-default-class: \"false\" provisioner: rancher.io/local-path reclaimPolicy: Retain volumeBindingMode: WaitForFirstConsumer parameters:   nodePath: /opt/cluster/utils</p> <p>Reclaim Policy</p> <p>StorageClasses use <code>Retain</code> reclaim policy to prevent accidental data loss. Volumes must be manually deleted from the host filesystem after PVC deletion.</p>"},{"location":"architecture/storage/#storage-location","title":"Storage Location","text":"<p>Storage is organized by namespace:</p> <ul> <li>Infrastructure: <code>/opt/cluster/infra</code></li> <li>Media (HTPC): <code>/opt/cluster/htpc</code></li> <li>Utilities: <code>/opt/cluster/utils</code></li> </ul> Bash<pre><code># Create storage directories\nsudo mkdir -p /opt/cluster/{infra,htpc,utils}\nsudo chmod 755 /opt/cluster\n\n# Check storage usage by namespace\ndu -sh /opt/cluster/*\n</code></pre>"},{"location":"architecture/storage/#persistent-volume-claims","title":"Persistent Volume Claims","text":""},{"location":"architecture/storage/#infrastructure-namespace-infra","title":"Infrastructure Namespace (infra)","text":"PVC Size Purpose Design Considerations grafana-data-pvc 5Gi Dashboard storage Fast random access, low latency jaeger-data-pvc 10Gi Trace storage High write frequency, sequential access traefik-data-pvc 1Gi Traefik storage Configuration and cache alloy-data-pvc 5Gi Alloy storage Metrics and logs buffering View infrastructure PVCs"},{"location":"architecture/storage/#pvc-for-grafana-data","title":"PVC for Grafana Data","text":"<p>apiVersion: v1 kind: PersistentVolumeClaim metadata:   name: grafana-data-pvc   namespace: infra spec:   storageClassName: local-path-infra   accessModes:     - ReadWriteOnce   resources:     requests:       storage: 5Gi # For dashboards, plugins, internal DB</p>"},{"location":"architecture/storage/#pvc-for-jaeger-storage-only-if-using-persistent-storage-like-badger","title":"PVC for Jaeger Storage (Only if using persistent storage like Badger)","text":"<p>apiVersion: v1 kind: PersistentVolumeClaim metadata:   name: jaeger-data-pvc # Adjust if needed based on Jaeger chart values   namespace: infra spec:   storageClassName: local-path-infra   accessModes:     - ReadWriteOnce   resources:     requests:       storage: 10Gi</p>"},{"location":"architecture/storage/#pvc-for-traefik-storage","title":"PVC for Traefik Storage","text":"<p>apiVersion: v1 kind: PersistentVolumeClaim metadata:   name: traefik-data-pvc   namespace: infra spec:   storageClassName: local-path-infra   accessModes:     - ReadWriteOnce   resources:     requests:       storage: 1Gi</p>"},{"location":"architecture/storage/#pvc-for-alloy-storage","title":"PVC for Alloy Storage","text":"<p>apiVersion: v1 kind: PersistentVolumeClaim metadata:   name: alloy-data-pvc   namespace: infra spec:   storageClassName: local-path-infra   accessModes:     - ReadWriteOnce   resources:     requests:       storage: 10Gi</p>"},{"location":"architecture/storage/#utilities-namespace-utils","title":"Utilities Namespace (utils)","text":"PVC Size Purpose Design Considerations immich-library-pvc 20Gi Photos/Videos Mixed IO patterns, large files immich-valkey-pvc 5Gi Cache data In-memory performance, persistence immich-ml-cache-pvc 10Gi ML Models Read-optimized, infrequent writes nextcloud-pvc 31Gi File storage Mixed workload, many small files nextcloud-redis-pvc 1Gi Redis cache Fast access, persistence tandoor-data-pvc 20Gi Recipe data Small files, frequent access View utilities PVCs"},{"location":"architecture/storage/#pvc-for-immich-media-library","title":"PVC for Immich Media Library","text":"<p>apiVersion: v1 kind: PersistentVolumeClaim metadata:   name: immich-library-pvc   namespace: utils spec:   storageClassName: local-path-utils   accessModes:     - ReadWriteOnce   resources:     requests:       storage: 20Gi</p>"},{"location":"architecture/storage/#pvc-for-immich-redis-persistence","title":"PVC for Immich Redis persistence","text":"<p>apiVersion: v1 kind: PersistentVolumeClaim metadata:   name: immich-valkey-pvc   namespace: utils spec:   storageClassName: local-path-utils   accessModes:     - ReadWriteOnce   resources:     requests:       storage: 5Gi</p>"},{"location":"architecture/storage/#pvc-for-immich-machine-learning-cache","title":"PVC for Immich Machine Learning cache","text":"<p>apiVersion: v1 kind: PersistentVolumeClaim metadata:   name: immich-ml-cache-pvc   namespace: utils spec:   storageClassName: local-path-utils   accessModes:     - ReadWriteOnce   resources:     requests:       storage: 10Gi</p>"},{"location":"architecture/storage/#pvc-for-tandoor-application-data-media-static-files","title":"PVC for Tandoor application data (media, static files)","text":"<p>apiVersion: v1 kind: PersistentVolumeClaim metadata:   name: tandoor-data-pvc   namespace: utils spec:   storageClassName: local-path-utils   accessModes:     - ReadWriteOnce   resources:     requests:       storage: 20Gi</p>"},{"location":"architecture/storage/#pvc-for-all-nextcloud-data-app-database-redis-backups","title":"PVC for all Nextcloud data (app, database, redis, backups)","text":"<p>apiVersion: v1 kind: PersistentVolumeClaim metadata:   name: nextcloud-pvc   namespace: utils spec:   storageClassName: local-path-utils   accessModes:     - ReadWriteOnce   resources:     requests:       storage: 31Gi</p>"},{"location":"architecture/storage/#pvc-for-nextcloud-redis-data","title":"PVC for Nextcloud redis data","text":"<p>apiVersion: v1 kind: PersistentVolumeClaim metadata:   name: nextcloud-redis-pvc   namespace: utils spec:   storageClassName: local-path-utils   accessModes:     - ReadWriteOnce   resources:     requests:       storage: 1Gi</p>"},{"location":"architecture/storage/#media-namespace-htpc","title":"Media Namespace (htpc)","text":"PVC Size Purpose Design Considerations htpc-pvc 500Gi Media &amp; App Data High throughput, large sequential files View HTPC PVC <p>apiVersion: v1 kind: PersistentVolumeClaim metadata:   name: htpc-pvc spec:   storageClassName: local-path-htpc   accessModes:     - ReadWriteOnce   resources:     requests:       storage: 500Gi</p> <p>Dynamic Provisioning</p> <p>All storage is dynamically provisioned by local-path-provisioner. No manual PV creation required.</p>"},{"location":"architecture/storage/#storage-provisioning-flow","title":"Storage Provisioning Flow","text":"<pre><code>sequenceDiagram\n    participant Pod\n    participant PVC\n    participant SC as StorageClass\n    participant LPP as local-path-provisioner\n    participant Node\n    participant PV\n\n    Pod-&gt;&gt;PVC: Request Storage\n    PVC-&gt;&gt;SC: Claim with StorageClass\n    Note over SC: WaitForFirstConsumer\n    Pod-&gt;&gt;Node: Pod Scheduled to Node\n    SC-&gt;&gt;LPP: Trigger Provisioning\n    LPP-&gt;&gt;Node: Create Directory&lt;br&gt;/opt/cluster/{namespace}/pvc-xxx\n    LPP-&gt;&gt;PV: Create PersistentVolume\n    PV-&gt;&gt;PVC: Bind to Claim\n    PVC-&gt;&gt;Pod: Mount Volume\n    Note over Pod,Node: Volume Ready for Use</code></pre>"},{"location":"architecture/storage/#storage-performance","title":"Storage Performance","text":""},{"location":"architecture/storage/#media-streaming","title":"Media Streaming","text":"<p>Optimized for high-throughput sequential access:</p> <ul> <li>Large block sizes: 1MB+ for video files</li> <li>Read-ahead: Kernel buffer tuning</li> <li>Direct I/O: Bypass page cache when appropriate</li> </ul>"},{"location":"architecture/storage/#database-storage","title":"Database Storage","text":"<p>Optimized for random access and IOPS:</p> <ul> <li>Small block sizes: 4KB-16KB</li> <li>SSD recommended: Fast random reads/writes</li> <li>fsync behavior: WAL for PostgreSQL</li> </ul>"},{"location":"architecture/storage/#cache-storage","title":"Cache Storage","text":"<p>Optimized for fast access:</p> <ul> <li>tmpfs option: In-memory storage</li> <li>SSD preferred: Low latency</li> <li>Persistence: Optional depending on use case</li> </ul>"},{"location":"architecture/storage/#volume-snapshots","title":"Volume Snapshots","text":""},{"location":"architecture/storage/#volumesnapshot-support","title":"VolumeSnapshot Support","text":"<p>If using a CSI driver with snapshot support, VolumeSnapshot resources can create point-in-time copies of PVCs.</p>"},{"location":"architecture/storage/#backup-strategy","title":"Backup Strategy","text":"<p>For manual backups, use kubectl exec to tar data from pods and extract when restoring.</p>"},{"location":"architecture/storage/#storage-monitoring","title":"Storage Monitoring","text":""},{"location":"architecture/storage/#capacity-tracking","title":"Capacity Tracking","text":"Bash<pre><code># Check PV usage\nkubectl get pv\n\n# Check PVC usage\nkubectl get pvc -A\n\n# Describe PVC for details\nkubectl describe pvc &lt;name&gt; -n &lt;namespace&gt;\n\n# Check actual disk usage by namespace\ndu -sh /opt/cluster/*\n</code></pre>"},{"location":"architecture/storage/#metrics-collection","title":"Metrics Collection","text":"<p>Prometheus metrics for storage:</p> <ul> <li>kubelet_volume_stats_capacity_bytes: Total capacity</li> <li>kubelet_volume_stats_used_bytes: Used space</li> <li>kubelet_volume_stats_available_bytes: Available space</li> <li>kubelet_volume_stats_inodes: Inode usage</li> </ul>"},{"location":"architecture/storage/#grafana-dashboards","title":"Grafana Dashboards","text":"<p>Pre-configured dashboards show:</p> <ul> <li>Storage utilization per namespace</li> <li>PVC growth over time</li> <li>I/O performance metrics</li> <li>Capacity forecasting</li> </ul>"},{"location":"architecture/storage/#storage-expansion","title":"Storage Expansion","text":""},{"location":"architecture/storage/#expanding-pvcs","title":"Expanding PVCs","text":"<p>Manual Expansion Required</p> <p>With <code>Retain</code> reclaim policy and local-path provisioner, PVC expansion requires manual steps:</p> <ol> <li>Delete the pod using the PVC</li> <li>Edit the PVC to increase size</li> <li>Manually expand the filesystem on the node</li> <li>Restart the pod</li> </ol> Bash<pre><code># Edit PVC to increase size\nkubectl edit pvc &lt;name&gt; -n &lt;namespace&gt;\n\n# Or patch directly\nkubectl patch pvc &lt;name&gt; -n &lt;namespace&gt; -p '{\"spec\":{\"resources\":{\"requests\":{\"storage\":\"20Gi\"}}}}'\n</code></pre>"},{"location":"architecture/storage/#adding-storage-nodes","title":"Adding Storage Nodes","text":"<p>For multi-node clusters:</p> <ol> <li>Add storage to new node</li> <li>Label node for storage workloads</li> <li>Update storage class topology</li> <li>Migrate workloads if needed</li> </ol>"},{"location":"architecture/storage/#data-migration","title":"Data Migration","text":""},{"location":"architecture/storage/#moving-between-pvcs","title":"Moving Between PVCs","text":"Bash<pre><code># Method 1: Using a temporary pod\nkubectl run -i --tty migrator --image=busybox --restart=Never -- sh\n# Mount both PVCs and copy data\n\n# Method 2: Using kubectl cp\nkubectl cp source-pod:/data ./local-data -n namespace\nkubectl cp ./local-data dest-pod:/data -n namespace\n</code></pre>"},{"location":"architecture/storage/#external-storage-integration","title":"External Storage Integration","text":"<p>To integrate external storage:</p> <ul> <li>NFS: Mount network shares</li> <li>Ceph: Use Rook operator</li> <li>iSCSI: Configure CSI driver</li> <li>Cloud: Use cloud provider CSI</li> </ul>"},{"location":"architecture/storage/#storage-best-practices","title":"Storage Best Practices","text":""},{"location":"architecture/storage/#planning","title":"Planning","text":"<ul> <li>Estimate growth: Plan for 2-3x current usage</li> <li>Separate workloads: Different storage for different needs</li> <li>Monitor trends: Track usage patterns</li> </ul>"},{"location":"architecture/storage/#performance","title":"Performance","text":"<ul> <li>SSD for databases: Use fast storage for DB workloads</li> <li>HDD for media: Cost-effective for sequential access</li> <li>Cache layer: Use Redis/Valkey for frequently accessed data</li> </ul>"},{"location":"architecture/storage/#reliability","title":"Reliability","text":"<ul> <li>Regular backups: Automate backup processes</li> <li>Test restores: Verify backup integrity</li> <li>RAID arrays: Use hardware RAID for redundancy</li> <li>Multiple disks: Spread risk across devices</li> </ul>"},{"location":"architecture/storage/#security","title":"Security","text":"<ul> <li>Encryption at rest: Use disk encryption (LUKS)</li> <li>Access controls: RBAC for PVC access</li> <li>Quotas: Prevent storage exhaustion</li> <li>Audit logs: Track storage access</li> </ul>"},{"location":"architecture/storage/#troubleshooting","title":"Troubleshooting","text":""},{"location":"architecture/storage/#pvc-stuck-in-pending","title":"PVC Stuck in Pending","text":"Bash<pre><code># Check PVC events\nkubectl describe pvc &lt;name&gt; -n &lt;namespace&gt;\n\n# Check storage class\nkubectl get storageclass\n\n# Check provisioner logs\nkubectl logs -n kube-system -l app=local-path-provisioner\n</code></pre>"},{"location":"architecture/storage/#volume-mount-errors","title":"Volume Mount Errors","text":"Bash<pre><code># Check pod events\nkubectl describe pod &lt;name&gt; -n &lt;namespace&gt;\n\n# Check volume status\nkubectl get pv &lt;pv-name&gt;\n\n# Check node capacity\nkubectl describe node &lt;node-name&gt;\n</code></pre>"},{"location":"architecture/storage/#performance-issues","title":"Performance Issues","text":"Bash<pre><code># Check I/O stats\nkubectl top pods -n &lt;namespace&gt;\n\n# Check node I/O\niostat -x 1\n\n# Check disk space by namespace\ndf -h /opt/cluster\ndu -sh /opt/cluster/*\n</code></pre>"},{"location":"architecture/storage/#related-documentation","title":"Related Documentation","text":"<ul> <li>Kubernetes Infrastructure - Cluster configuration</li> <li>Reference: Storage Reference - Detailed specs</li> <li>Services - Service storage requirements</li> </ul>"},{"location":"architecture/storage/#abbreviations","title":"Abbreviations","text":""},{"location":"configuration/","title":"Configuration","text":"<p>Learn how to manage and customize your homelab deployment.</p>"},{"location":"configuration/#configuration-overview","title":"Configuration Overview","text":"<p>The platform uses a layered configuration approach:</p> <ol> <li>Base Configurations: Common settings for all environments</li> <li>Overlays: Environment-specific customizations</li> <li>Secrets: Sensitive data management</li> </ol>"},{"location":"configuration/#configuration-management","title":"Configuration Management","text":"<ul> <li> <p> Base Configurations</p> <p>Core service definitions and shared settings</p> </li> <li> <p> Overlays</p> <p>Environment-specific customizations</p> </li> <li> <p> Secrets</p> <p>Secure credential management</p> </li> </ul>"},{"location":"configuration/#configuration-principles","title":"Configuration Principles","text":""},{"location":"configuration/#gitops-based","title":"GitOps-Based","text":"<p>All configuration stored in Git as the single source of truth.</p>"},{"location":"configuration/#declarative","title":"Declarative","text":"<p>Desired state defined in YAML manifests.</p>"},{"location":"configuration/#environment-separation","title":"Environment Separation","text":"<p>Staging and production configurations isolated.</p>"},{"location":"configuration/#security-first","title":"Security First","text":"<p>Secrets encrypted and managed securely.</p>"},{"location":"configuration/#quick-links","title":"Quick Links","text":"<ul> <li>Architecture: Configuration Management</li> <li>Getting Started</li> <li>Services</li> </ul>"},{"location":"configuration/#abbreviations","title":"Abbreviations","text":""},{"location":"configuration/base-configurations/","title":"Base Configurations","text":"<p>Base configurations contain common settings shared across all environments.</p> <pre><code>graph TD\n    subgraph \"base/\"\n        subgraph \"htpc/\"\n            H1[jellyfin/]\n            H2[sonarr/]\n            H3[radarr/]\n            H4[prowlarr/]\n            H5[transmission/]\n            H6[scraparr/]\n            H7[flaresolverr/]\n            HK[kustomization.yaml]\n            HI[ingress-route.yaml]\n            HP[persistent-volume-claim.yaml]\n        end\n\n        subgraph \"infra/\"\n            I1[traefik/]\n            I2[cert-manager/]\n            I3[monitoring/]\n            I4[metallb/]\n            I5[local-path-provisioner/]\n            IK[kustomization.yaml]\n            II[ingress-route.yaml]\n            IP[persistent-volume-claim.yaml]\n        end\n\n        subgraph \"utils/\"\n            U1[nextcloud/]\n            U2[immich/]\n            U3[homepage/]\n            U4[tandoor/]\n            U5[cnpg/]\n            UK[kustomization.yaml]\n            UI[ingress-route.yaml]\n            UP[persistent-volume-claim.yaml]\n        end\n    end\n\n    style htpc/ fill:#2196f3\n    style infra/ fill:#4caf50\n    style utils/ fill:#ff9800</code></pre>"},{"location":"configuration/base-configurations/#directory-structure","title":"Directory Structure","text":"<p>The base directory is organized into three main namespaces (htpc, infra, utils), each containing service subdirectories and shared resource files for ingress routes and persistent volume claims.</p>"},{"location":"configuration/base-configurations/#service-structure","title":"Service Structure","text":"<p>Each service typically includes standard Kubernetes resources:</p> <ul> <li>Deployment: Application container specifications</li> <li>Service: ClusterIP service for internal communication</li> <li>Kustomization: Lists the service's resource manifests</li> <li>ConfigMap (optional): Non-sensitive configuration data</li> <li>Secret (optional): Sensitive credentials and keys</li> <li>Ingress Route: Added to namespace-level ingress-route.yaml if external access needed</li> <li>Persistent Volume Claim: Added to namespace-level PVC file if storage needed</li> </ul>"},{"location":"configuration/base-configurations/#simple-service-example","title":"Simple Service Example","text":"<p>Most services follow a simple pattern with deployment, service, and kustomization:</p> Jellyfin Service Structure Bash<pre><code>base/htpc/jellyfin/\n\u251c\u2500\u2500 deployment.yaml\n\u251c\u2500\u2500 service.yaml\n\u2514\u2500\u2500 kustomization.yaml\n</code></pre> YAML<pre><code># Kustomization\n---\napiVersion: kustomize.config.k8s.io/v1beta1\nkind: Kustomization\n\nresources:\n  - deployment.yaml\n  - service.yaml\n</code></pre>"},{"location":"configuration/base-configurations/#complex-service-example","title":"Complex Service Example","text":"<p>Some services have additional resources like databases, caches, and jobs:</p> Nextcloud Service Structure Bash<pre><code>base/utils/nextcloud/\n\u251c\u2500\u2500 configmap.yaml\n\u251c\u2500\u2500 kustomization.yaml\n\u251c\u2500\u2500 middleware.yaml\n\u251c\u2500\u2500 nextcloud-cronjob.yaml\n\u251c\u2500\u2500 nextcloud-deployment.yaml\n\u251c\u2500\u2500 nextcloud-service.yaml\n\u251c\u2500\u2500 postgres-cluster.yaml\n\u251c\u2500\u2500 redis-deployment.yaml\n\u251c\u2500\u2500 redis-service.yaml\n\u2514\u2500\u2500 secret/\n</code></pre> YAML<pre><code># Kustomization\n# File: base/utils/nextcloud/kustomization.yaml\n---\napiVersion: kustomize.config.k8s.io/v1beta1\nkind: Kustomization\n\nresources:\n  - secret\n  - configmap.yaml\n  - nextcloud-deployment.yaml\n  - nextcloud-service.yaml\n  - nextcloud-cronjob.yaml\n  - postgres-cluster.yaml\n  - redis-deployment.yaml\n  - redis-service.yaml\n  - middleware.yaml\n\ngeneratorOptions:\n  disableNameSuffixHash: true\n</code></pre>"},{"location":"configuration/base-configurations/#kustomization-files","title":"Kustomization Files","text":""},{"location":"configuration/base-configurations/#namespace-kustomization","title":"Namespace Kustomization","text":"<p>Namespace-level kustomization files list all service subdirectories as resources, shared resources like ingress routes and PVCs, and common labels.</p> View utils kustomization.yaml <p>apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization</p> <p>namespace: utils</p> <p>resources:   - homepage   - nextcloud   - immich   - tandoor   - cnpg   - ingress-route.yaml   - persistent-volume-claim.yaml</p>"},{"location":"configuration/base-configurations/#service-kustomization","title":"Service Kustomization","text":"<p>Service-level kustomization files list the service's resource manifests and apply common labels for the application.</p>"},{"location":"configuration/base-configurations/#common-patterns","title":"Common Patterns","text":""},{"location":"configuration/base-configurations/#deployment","title":"Deployment","text":"<p>Standard Kubernetes Deployments define:</p> <ul> <li>Application container specs (image, ports, environment variables)</li> <li>Replica count and pod labels</li> <li>Resource requirements (CPU, memory limits)</li> <li>Volume mounts and ConfigMap/Secret references</li> <li>Liveness and readiness probes</li> </ul>"},{"location":"configuration/base-configurations/#service","title":"Service","text":"<p>Services expose applications internally with:</p> <ul> <li>Selector labels to identify target pods</li> <li>Port mappings (service port \u2192 container targetPort)</li> <li>Service type (ClusterIP for internal, LoadBalancer for external)</li> </ul>"},{"location":"configuration/base-configurations/#ingressroute","title":"IngressRoute","text":"<p>Traefik IngressRoutes provide external access with:</p> <ul> <li>Entry points (websecure for HTTPS)</li> <li>Host-based routing rules</li> <li>TLS certificate references</li> <li>Middleware for headers, authentication, rate limiting</li> </ul>"},{"location":"configuration/base-configurations/#shared-resources","title":"Shared Resources","text":""},{"location":"configuration/base-configurations/#persistent-volume-claims","title":"Persistent Volume Claims","text":"<p>PVCs request storage with specified access modes (e.g., ReadWriteOnce), storage class (local-path), and capacity requirements.</p> View Utils Namespace PVCs YAML<pre><code>---\n# PVC for Immich Media Library\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: immich-library-pvc\n  namespace: utils\nspec:\n  storageClassName: local-path-utils\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 20Gi\n\n---\n# PVC for Immich Redis persistence\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: immich-valkey-pvc\n  namespace: utils\nspec:\n  storageClassName: local-path-utils\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 5Gi\n\n---\n# PVC for Immich Machine Learning cache\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: immich-ml-cache-pvc\n  namespace: utils\nspec:\n  storageClassName: local-path-utils\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 10Gi\n\n---\n# PVC for Tandoor application data (media, static files)\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: tandoor-data-pvc\n  namespace: utils\nspec:\n  storageClassName: local-path-utils\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 20Gi\n\n---\n# PVC for all Nextcloud data (app, database, redis, backups)\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: nextcloud-pvc\n  namespace: utils\nspec:\n  storageClassName: local-path-utils\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 31Gi\n\n---\n# PVC for Nextcloud redis data\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: nextcloud-redis-pvc\n  namespace: utils\nspec:\n  storageClassName: local-path-utils\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 1Gi\n</code></pre> <p>Each namespace uses its own storage class:</p> <ul> <li><code>local-path-htpc</code> for htpc namespace</li> <li><code>local-path-infra</code> for infra namespace</li> <li><code>local-path-utils</code> for utils namespace</li> </ul> <p>This allows storage to be organized by namespace in the filesystem (e.g., <code>/opt/cluster/utils</code>, <code>/opt/cluster/htpc</code>).</p>"},{"location":"configuration/base-configurations/#ingress-routes","title":"Ingress Routes","text":"<p>Shared IngressRoute files can define multiple host-based routes for services within a namespace, all using the same TLS certificate.</p> View HTPC Namespace IngressRoute YAML<pre><code>---\napiVersion: traefik.io/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: ingressroute\n  namespace: htpc\n  annotations:\n    kubernetes.io/ingress.class: traefik-external\nspec:\n  entryPoints:\n    - websecure\n  routes:\n    - kind: Rule\n      match: Host(`jellyfin.my-homelab.party`)\n      priority: 0\n      services:\n        - kind: Service\n          name: jellyfin\n          port: 8096\n    - kind: Rule\n      match: Host(`prowlarr.my-homelab.party`)\n      priority: 0\n      services:\n        - kind: Service\n          name: prowlarr\n          port: 9696\n    - kind: Rule\n      match: Host(`sonarr.my-homelab.party`)\n      priority: 0\n      services:\n        - kind: Service\n          name: sonarr\n          port: 8989\n    - kind: Rule\n      match: Host(`radarr.my-homelab.party`)\n      priority: 0\n      services:\n        - kind: Service\n          name: radarr\n          port: 7878\n    - kind: Rule\n      match: Host(`transmission.my-homelab.party`)\n      priority: 0\n      services:\n        - kind: Service\n          name: transmission\n          port: 9091\n    - kind: Rule\n      match: Host(`flaresolverr.my-homelab.party`)\n      priority: 0\n      services:\n        - kind: Service\n          name: flaresolverr\n          port: 8191\n</code></pre> <p>This single IngressRoute defines access to all HTPC services (Jellyfin, Sonarr, Radarr, etc.) with host-based routing.</p>"},{"location":"configuration/base-configurations/#best-practices","title":"Best Practices","text":""},{"location":"configuration/base-configurations/#resource-management","title":"Resource Management","text":"<ul> <li>Set resource requests and limits</li> <li>Use appropriate QoS classes</li> <li>Plan for scaling</li> </ul>"},{"location":"configuration/base-configurations/#configuration","title":"Configuration","text":"<ul> <li>Use ConfigMaps for non-sensitive data</li> <li>Use Secrets for sensitive data</li> <li>Externalize configuration</li> </ul>"},{"location":"configuration/base-configurations/#storage","title":"Storage","text":"<ul> <li>Request appropriate storage sizes</li> <li>Use namespace-specific storage classes (e.g., <code>local-path-htpc</code>, <code>local-path-infra</code>, <code>local-path-utils</code>)</li> <li>Use correct access modes (ReadWriteOnce, ReadWriteMany)</li> <li>Plan for growth</li> </ul>"},{"location":"configuration/base-configurations/#security","title":"Security","text":"<ul> <li>Follow principle of least privilege</li> <li>Use RBAC for service accounts where needed</li> <li>Keep images updated</li> <li>Apply security contexts as appropriate for workloads</li> </ul>"},{"location":"configuration/base-configurations/#modifying-base-configurations","title":"Modifying Base Configurations","text":"<pre><code>flowchart LR\n    A[Edit base/ files] --&gt; B[Validate]\n    B --&gt; C[Update Manifests]\n    C --&gt; D[Test in Staging]\n    D --&gt; E{Tests Pass?}\n    E --&gt;|Yes| F[Commit &amp; Push]\n    E --&gt;|No| A\n    F --&gt; G[ArgoCD Auto-Sync]\n    G --&gt; H[Deployed]\n\n    style A fill:#4caf50\n    style B fill:#2196f3\n    style D fill:#ff9800\n    style G fill:#e91e63\n    style H fill:#9c27b0</code></pre>"},{"location":"configuration/base-configurations/#making-changes","title":"Making Changes","text":"<ol> <li>Edit files in <code>base/</code> directory</li> <li>Validate changes: <code>./scripts/validate.sh</code></li> <li>Build manifests: <code>./scripts/update-manifests.sh</code></li> <li>Test in staging first</li> <li>Commit and push changes</li> <li>ArgoCD will sync automatically</li> </ol>"},{"location":"configuration/base-configurations/#adding-new-services","title":"Adding New Services","text":"<ol> <li>Create service directory in appropriate namespace</li> <li>Add service manifests</li> <li>Create kustomization.yaml</li> <li>Add to namespace kustomization</li> <li>Test and deploy</li> </ol>"},{"location":"configuration/base-configurations/#related-documentation","title":"Related Documentation","text":"<ul> <li>Architecture: Configuration Management</li> <li>Overlays</li> <li>Secrets</li> </ul>"},{"location":"configuration/base-configurations/#abbreviations","title":"Abbreviations","text":""},{"location":"configuration/overlays/","title":"Overlays","text":"<p>Overlays customize base configurations for specific environments using Kustomize patches.</p> <pre><code>graph TD\n    subgraph \"Base Layer\"\n        B1[base/infra]\n        B2[base/htpc]\n        B3[base/utils]\n        B4[base/argocd]\n    end\n\n    subgraph \"Overlay Layer\"\n        O1[overlays/infra]\n        O2[overlays/htpc]\n        O3[overlays/utils]\n        O4[overlays/argocd]\n    end\n\n    subgraph \"Environment Components\"\n        direction LR\n        subgraph \"Infrastructure\"\n            E1[production-infra]\n            E3[staging-infra]\n        end\n        subgraph \"Ingress\"\n            E2[production-ingress]\n            E4[staging-ingress]\n        end\n    end\n\n    B1 --&gt; O1\n    B2 --&gt; O2\n    B3 --&gt; O3\n    B4 --&gt; O4\n\n    E1 -.-&gt;|infra only| O1\n    E2 -.-&gt;|all namespaces| O1\n    E2 -.-&gt; O2\n    E2 -.-&gt; O3\n    E2 -.-&gt; O4\n\n    style B1 fill:#4caf50\n    style B2 fill:#2196f3\n    style B3 fill:#ff9800\n    style B4 fill:#e91e63\n    style E1 fill:#9c27b0\n    style E2 fill:#9c27b0</code></pre>"},{"location":"configuration/overlays/#overlay-structure","title":"Overlay Structure","text":"<p>The overlays directory contains environment-specific configurations organized by namespace (argocd, htpc, infra, utils). Each overlay references the corresponding base configuration and uses Kustomize components from the <code>overlays/environment/</code> directory for environment-specific customizations (staging vs production, infrastructure and ingress settings).</p>"},{"location":"configuration/overlays/#environment-types","title":"Environment Types","text":"<pre><code>flowchart LR\n    subgraph \"Staging Environment\"\n        S1[Let's Encrypt&lt;br/&gt;Staging Server]\n        S2[staging-certificate-secret]\n        S3[Test Domains]\n    end\n\n    subgraph \"Production Environment\"\n        P1[Let's Encrypt&lt;br/&gt;Production Server]\n        P2[production-certificate-secret]\n        P3[Live Domains]\n    end\n\n    style S1 fill:#ff9800\n    style S2 fill:#ff9800\n    style S3 fill:#ff9800\n    style P1 fill:#4caf50\n    style P2 fill:#4caf50\n    style P3 fill:#4caf50</code></pre>"},{"location":"configuration/overlays/#staging","title":"Staging","text":"<p>Development and testing environment with:</p> <ul> <li>Let's Encrypt staging certificates (to avoid rate limits during testing)</li> <li>Staging TLS secret names</li> <li>Separate domain configurations</li> </ul>"},{"location":"configuration/overlays/#production","title":"Production","text":"<p>Live environment with:</p> <ul> <li>Let's Encrypt production certificates</li> <li>Production TLS secret names</li> <li>Production domain configurations</li> </ul>"},{"location":"configuration/overlays/#overlay-configuration","title":"Overlay Configuration","text":"<p>The repository uses a component-based approach where namespace overlays reference base configurations and include environment-specific components for infrastructure and ingress customization.</p>"},{"location":"configuration/overlays/#staging-infrastructure-component","title":"Staging Infrastructure Component","text":"<p>The staging infrastructure component patches cert-manager resources to use Let's Encrypt staging server and staging certificate secrets.</p> View staging-infra kustomization.yaml <p>apiVersion: kustomize.config.k8s.io/v1alpha1 kind: Component patches:   # Certificate patch   - target:       kind: Certificate       name: cluster-certificate       namespace: infra     patch: |-       apiVersion: cert-manager.io/v1       kind: Certificate       metadata:         name: cluster-certificate         namespace: infra       spec:         secretName: staging-certificate-secret   # ClusterIssuer patch   - target:       kind: ClusterIssuer       name: letsencrypt-issuer     patch: |-       apiVersion: cert-manager.io/v1       kind: ClusterIssuer       metadata:         name: letsencrypt-issuer       spec:         acme:           server: https://acme-staging-v02.api.letsencrypt.org/directory           privateKeySecretRef:             name: letsencrypt-staging</p>"},{"location":"configuration/overlays/#production-infrastructure-component","title":"Production Infrastructure Component","text":"<p>The production infrastructure component patches cert-manager resources to use Let's Encrypt production server and production certificate secrets.</p> View production-infra kustomization.yaml <p>apiVersion: kustomize.config.k8s.io/v1alpha1 kind: Component patches:   # Certificate patch   - target:       kind: Certificate       name: cluster-certificate       namespace: infra     patch: |-       apiVersion: cert-manager.io/v1       kind: Certificate       metadata:         name: cluster-certificate         namespace: infra       spec:         secretName: production-certificate-secret   # ClusterIssuer patch   - target:       kind: ClusterIssuer       name: letsencrypt-issuer     patch: |-       apiVersion: cert-manager.io/v1       kind: ClusterIssuer       metadata:         name: letsencrypt-issuer       spec:         acme:           server: https://acme-v02.api.letsencrypt.org/directory           privateKeySecretRef:             name: letsencrypt-production</p>"},{"location":"configuration/overlays/#environment-components","title":"Environment Components","text":"<p>The repository uses Kustomize components to apply environment-specific configurations. Components are located in <code>overlays/environment/</code> and referenced by namespace overlays.</p>"},{"location":"configuration/overlays/#infrastructure-components","title":"Infrastructure Components","text":"<p>Infrastructure components (<code>staging-infra</code> and <code>production-infra</code>) patch cert-manager certificates and ClusterIssuers:</p> <ul> <li>Staging: Uses Let's Encrypt staging server for testing</li> <li>Production: Uses Let's Encrypt production server with production certificates</li> </ul>"},{"location":"configuration/overlays/#ingress-components","title":"Ingress Components","text":"<p>Ingress components (<code>staging-ingress</code> and <code>production-ingress</code>) configure environment-specific domain names and TLS settings for IngressRoute resources.</p>"},{"location":"configuration/overlays/#customization-capabilities","title":"Customization Capabilities","text":"<p>While the current implementation focuses on certificate and ingress configuration, Kustomize patches can also modify:</p> <ul> <li>Replicas: Adjust pod counts per environment</li> <li>Resources: Set different CPU/memory limits</li> <li>Images: Override container image tags</li> <li>ConfigMaps: Environment-specific configuration values</li> </ul>"},{"location":"configuration/overlays/#namespace-overlays","title":"Namespace Overlays","text":""},{"location":"configuration/overlays/#htpc-overlay","title":"HTPC Overlay","text":"<p>The HTPC overlay configures media services with appropriate labels.</p> View HTPC kustomization.yaml <p>apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization</p> <p>resources:   - ../../base/htpc</p> <p>components:   - ../environment/production-ingress # Change to staging-ingress for staging</p>"},{"location":"configuration/overlays/#infrastructure-overlay","title":"Infrastructure Overlay","text":"<p>The infrastructure overlay configures core infrastructure services with production labels.</p> View infrastructure kustomization.yaml <p>apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization</p> <p>resources:   - ../../base/infra</p> <p>components:   - ../environment/production-infra # Change to staging-infra for staging   - ../environment/production-ingress # Change to staging-ingress for staging</p>"},{"location":"configuration/overlays/#utils-overlay","title":"Utils Overlay","text":"<p>The utils overlay configures utility services with appropriate labels.</p> View utils kustomization.yaml <p>apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization</p> <p>resources:   - ../../base/utils</p> <p>components:   - ../environment/production-ingress # Change to staging-ingress for staging</p>"},{"location":"configuration/overlays/#argocd-overlay","title":"ArgoCD Overlay","text":"<p>The ArgoCD overlay includes both application definitions and CRDs.</p> View ArgoCD kustomization.yaml <p>apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization</p> <p>resources:   - ../../argocd</p> <p>components:   - ../environment/production-ingress # Change to staging-ingress for staging</p>"},{"location":"configuration/overlays/#kustomize-features","title":"Kustomize Features","text":"<p>Kustomize provides various transformation capabilities. This project currently uses:</p>"},{"location":"configuration/overlays/#components","title":"Components","text":"<p>Modular, reusable configuration pieces that can be selectively included:</p> <ul> <li><code>production-infra</code> / <code>staging-infra</code> - Certificate issuer configuration</li> <li><code>production-ingress</code> / <code>staging-ingress</code> - TLS and ingress settings</li> </ul>"},{"location":"configuration/overlays/#patches","title":"Patches","text":"<p>Modify existing resources using strategic merge or JSON patches:</p> <ul> <li>Certificate secret names</li> <li>ClusterIssuer ACME server URLs</li> <li>IngressRoute TLS settings</li> </ul>"},{"location":"configuration/overlays/#building-overlays","title":"Building Overlays","text":""},{"location":"configuration/overlays/#local-build","title":"Local Build","text":"Bash<pre><code># Build specific namespace overlay\nkustomize build overlays/infra/\n\n# Build all namespace overlays\nkustomize build overlays/htpc/\nkustomize build overlays/infra/\nkustomize build overlays/utils/\nkustomize build overlays/argocd/\n\n# Build and validate\nkustomize build overlays/infra/ | kubectl apply --dry-run=client -f -\n</code></pre>"},{"location":"configuration/overlays/#generate-install-yaml","title":"Generate Install YAML","text":"Bash<pre><code># Generate manifest file (defaults to staging)\n./scripts/update-manifests.sh\n\n# Generate for production\n./scripts/update-manifests.sh production\n\n# Output location (in repository root)\ninstall.yaml\n</code></pre>"},{"location":"configuration/overlays/#best-practices","title":"Best Practices","text":""},{"location":"configuration/overlays/#patch-strategy","title":"Patch Strategy","text":"<ul> <li>Strategic Merge: For simple changes</li> <li>JSON 6902: For complex transformations</li> <li>Keep patches minimal: Only change what's necessary</li> </ul>"},{"location":"configuration/overlays/#organization","title":"Organization","text":"<ul> <li>Logical grouping: Group related patches</li> <li>Clear naming: Descriptive patch file names</li> <li>Documentation: Comment complex patches</li> </ul>"},{"location":"configuration/overlays/#testing","title":"Testing","text":"<ul> <li>Staging first: Always test in staging</li> <li>Validate: Run validation scripts</li> <li>Gradual rollout: Deploy incrementally</li> </ul>"},{"location":"configuration/overlays/#version-control","title":"Version Control","text":"<ul> <li>Separate PRs: One overlay change per PR</li> <li>Review: Code review for all changes</li> <li>Rollback plan: Document rollback procedure</li> </ul>"},{"location":"configuration/overlays/#troubleshooting","title":"Troubleshooting","text":""},{"location":"configuration/overlays/#build-errors","title":"Build Errors","text":"Bash<pre><code># Validate kustomization\nkustomize build &lt;overlay-path&gt;\n\n# Check for missing resources\nls -la base/\n</code></pre>"},{"location":"configuration/overlays/#patch-not-applied","title":"Patch Not Applied","text":"Bash<pre><code># Verify patch syntax\ncat patch-file.yaml\n\n# Check resource names match\nkubectl get &lt;resource-type&gt; -n &lt;namespace&gt;\n</code></pre>"},{"location":"configuration/overlays/#argocd-sync-issues","title":"ArgoCD Sync Issues","text":"Bash<pre><code># Check application status\nargocd app get &lt;app-name&gt;\n\n# View diff\nargocd app diff &lt;app-name&gt;\n\n# Force sync\nargocd app sync &lt;app-name&gt; --force\n</code></pre>"},{"location":"configuration/overlays/#related-documentation","title":"Related Documentation","text":"<ul> <li>Architecture: Configuration Management</li> <li>Base Configurations</li> <li>Secrets</li> </ul>"},{"location":"configuration/overlays/#abbreviations","title":"Abbreviations","text":""},{"location":"configuration/secrets/","title":"Secrets Management","text":"<p>Secure management of sensitive configuration data across environments.</p> <pre><code>flowchart TD\n    subgraph \"Development\"\n        A[Plain Secret YAML]\n    end\n\n    subgraph \"Encryption\"\n        B[SOPS + Age]\n        C[Encrypted Secret]\n    end\n\n    subgraph \"Git Repository\"\n        D[Encrypted YAML&lt;br/&gt;Committed]\n    end\n\n    subgraph \"Kubernetes Cluster\"\n        E[KSOPS Plugin]\n        F[ArgoCD]\n        G[Decrypted Secret]\n        H[Pods]\n    end\n\n    A --&gt;|encrypt-secrets.sh| B\n    B --&gt; C\n    C --&gt; D\n    D --&gt; F\n    F --&gt; E\n    E --&gt; G\n    G --&gt; H\n\n    style A fill:#ff9800\n    style C fill:#2196f3\n    style D fill:#4caf50\n    style G fill:#9c27b0</code></pre>"},{"location":"configuration/secrets/#overview","title":"Overview","text":"<p>Secrets contain sensitive information such as:</p> <ul> <li>Passwords and API keys</li> <li>TLS certificates (managed by cert-manager)</li> <li>Database credentials</li> <li>OAuth tokens</li> <li>Service account keys</li> </ul>"},{"location":"configuration/secrets/#secret-management-strategy","title":"Secret Management Strategy","text":"<p>Security Notice</p> <p>Base64 encoding is NOT encryption. Never commit unencrypted secrets to public repositories.</p>"},{"location":"configuration/secrets/#encryption-at-rest","title":"Encryption at Rest","text":"<ul> <li>Kubernetes Secrets with base64 encoding</li> <li>Etcd encryption for cluster storage</li> <li>External secrets integration possible (Vault, etc.)</li> </ul>"},{"location":"configuration/secrets/#environment-separation","title":"Environment Separation","text":"<ul> <li>Separate secrets for staging and production</li> <li>Different credentials per environment</li> <li>No credential reuse across environments</li> </ul>"},{"location":"configuration/secrets/#access-control","title":"Access Control","text":"<ul> <li>RBAC limits secret access</li> <li>ServiceAccounts with minimal permissions</li> <li>Audit logging enabled</li> </ul>"},{"location":"configuration/secrets/#rotation-policies","title":"Rotation Policies","text":"<ul> <li>Regular credential rotation</li> <li>Automated rotation where supported</li> <li>Document manual rotation procedures</li> </ul>"},{"location":"configuration/secrets/#creating-secrets","title":"Creating Secrets","text":""},{"location":"configuration/secrets/#using-kubectl","title":"Using kubectl","text":"<p>Create secrets using kubectl's <code>create secret</code> command with options:</p> <ul> <li><code>generic</code> for arbitrary key-value pairs from literals or files</li> <li><code>tls</code> for TLS certificates with cert and key files</li> <li>Specify namespace with <code>-n</code> flag</li> </ul>"},{"location":"configuration/secrets/#using-yaml-manifests","title":"Using YAML Manifests","text":"<p>Define secrets in YAML using <code>kind: Secret</code> with <code>stringData</code> for plain text values (Kubernetes will encode them) or <code>data</code> for pre-encoded base64 values.</p>"},{"location":"configuration/secrets/#using-the-encryption-script","title":"Using the Encryption Script","text":"<p>This project uses SOPS with Age encryption for secure secret storage in Git.</p> Secret Encryption Workflow <ol> <li>Create a plain YAML secret file in a <code>secret/</code> directory</li> <li>Mark it for encryption by adding a comment (handled by script)</li> <li>Run the encryption script:</li> </ol> Bash<pre><code>export SOPS_AGE_KEY_FILE=~/.config/sops/age/keys.txt\n./scripts/encrypt-secrets.sh\n</code></pre> <p>The script automatically: - Finds YAML files marked for encryption - Encrypts them using SOPS and Age - Encrypts only <code>data</code> and <code>stringData</code> fields - Updates files in place</p> View KSOPS Generator Configuration YAML<pre><code># base/utils/nextcloud/secret/secret-generator.yaml\n---\napiVersion: viaduct.ai/v1\nkind: ksops\nmetadata:\n  name: nextcloud-credentials\n  annotations:\n    config.kubernetes.io/function: |\n      exec:\n        path: ksops\nfiles:\n  - secrets.yaml\n</code></pre> YAML<pre><code># base/utils/nextcloud/secret/kustomization.yaml\n---\napiVersion: kustomize.config.k8s.io/v1beta1\nkind: Kustomization\n\ngenerators:\n  - secret-generator.yaml\n</code></pre> <p>KSOPS Integration</p> <p>ArgoCD is configured with the KSOPS plugin to automatically decrypt SOPS-encrypted secrets during deployment. The Age private key must be available in the ArgoCD repo-server for decryption to work.</p>"},{"location":"configuration/secrets/#secret-types","title":"Secret Types","text":""},{"location":"configuration/secrets/#opaque-secrets","title":"Opaque Secrets","text":"<p>Generic secret type for arbitrary data. Values in the <code>data</code> field must be base64 encoded.</p>"},{"location":"configuration/secrets/#tls-secrets","title":"TLS Secrets","text":"<p>For TLS certificates (usually managed by cert-manager automatically). Type is <code>kubernetes.io/tls</code> with <code>tls.crt</code> and <code>tls.key</code> data fields containing base64-encoded certificate and private key.</p>"},{"location":"configuration/secrets/#docker-registry-secrets","title":"Docker Registry Secrets","text":"<p>For private container registries. Type is <code>kubernetes.io/dockerconfigjson</code> with <code>.dockerconfigjson</code> field containing base64-encoded Docker config.</p>"},{"location":"configuration/secrets/#service-account-tokens","title":"Service Account Tokens","text":"<p>For Kubernetes service accounts. Type is <code>kubernetes.io/service-account-token</code> with an annotation specifying the service account name.</p>"},{"location":"configuration/secrets/#using-secrets","title":"Using Secrets","text":"<p>Secrets can be consumed in three ways:</p> <pre><code>graph LR\n    S[Secret] --&gt; E[Environment Variables]\n    S --&gt; V[Volume Mounts]\n    S --&gt; A[Entire Secret as Env]\n\n    E --&gt; P1[Single Values]\n    V --&gt; P2[Files]\n    A --&gt; P3[All Keys]\n\n    style S fill:#e91e63\n    style E fill:#4caf50\n    style V fill:#2196f3\n    style A fill:#ff9800</code></pre>"},{"location":"configuration/secrets/#environment-variables","title":"Environment Variables","text":"<p>Inject individual secret values as environment variables using <code>secretKeyRef</code> to reference specific keys from a secret.</p> YAML<pre><code>env:\n  - name: DB_PASSWORD\n    valueFrom:\n      secretKeyRef:\n        name: database-credentials\n        key: password\n</code></pre>"},{"location":"configuration/secrets/#volume-mounts","title":"Volume Mounts","text":"<p>Mount secrets as files in a container at a specified path. Each secret key becomes a file, useful for configuration files or certificates. Always use <code>readOnly: true</code> for security.</p> YAML<pre><code>volumeMounts:\n  - name: secret-volume\n    mountPath: /etc/secrets\n    readOnly: true\nvolumes:\n  - name: secret-volume\n    secret:\n      secretName: app-secrets\n</code></pre>"},{"location":"configuration/secrets/#entire-secret-as-env","title":"Entire Secret as Env","text":"<p>Load all keys from a secret as environment variables at once using <code>envFrom</code> with <code>secretRef</code>.</p> YAML<pre><code>envFrom:\n  - secretRef:\n      name: app-secrets\n</code></pre>"},{"location":"configuration/secrets/#service-specific-secrets","title":"Service-Specific Secrets","text":""},{"location":"configuration/secrets/#cloudflare-api-token","title":"Cloudflare API Token","text":"<p>Required for cert-manager DNS-01 challenges to verify domain ownership. Store as an Opaque secret in the <code>infra</code> namespace with the key <code>cloudflare-token</code>.</p> View Cloudflare Token Secret Structure YAML<pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: cloudflare-token-secret\n  namespace: infra\ntype: Opaque\nstringData:\n  cloudflare-token: your-api-token-here\n</code></pre> <p>This secret is encrypted with SOPS in the repository: <code>base/infra/cert-manager/issuers/secret-cloudflare-token.yaml</code></p>"},{"location":"configuration/secrets/#database-credentials","title":"Database Credentials","text":"<p>PostgreSQL connection details stored as Opaque secrets in the appropriate namespace, typically containing <code>username</code>, <code>password</code>, and <code>database</code> keys.</p> View Nextcloud Database Secret Structure <p>The Nextcloud secret includes both application and database credentials:</p> <ul> <li><code>NEXTCLOUD_ADMIN_USER</code> - Admin username</li> <li><code>NEXTCLOUD_ADMIN_PASSWORD</code> - Admin password</li> <li><code>DB_USERNAME</code> - PostgreSQL username</li> <li><code>DB_PASSWORD</code> - PostgreSQL password</li> </ul> <p>Location: <code>base/utils/nextcloud/secret/secrets.yaml</code> (SOPS encrypted)</p>"},{"location":"configuration/secrets/#application-secrets","title":"Application Secrets","text":"<p>Application-specific secrets contain credentials needed for initial setup or administrative access.</p> Media Services Secrets <p>Scraparr requires API keys for all Arr services:</p> <ul> <li><code>SONARR_API_KEY</code></li> <li><code>RADARR_API_KEY</code></li> <li><code>PROWLARR_API_KEY</code></li> <li><code>JELLYFIN_API_KEY</code></li> </ul> <p>Location: <code>base/htpc/scraparr/secrets.yaml</code> (SOPS encrypted)</p>"},{"location":"configuration/secrets/#secret-best-practices","title":"Secret Best Practices","text":""},{"location":"configuration/secrets/#security","title":"Security","text":"<ul> <li>Never commit plaintext secrets to version control</li> <li>Use strong passwords: Generate complex credentials</li> <li>Rotate regularly: Change secrets periodically</li> <li>Limit access: Use RBAC to restrict access</li> <li>Audit: Monitor secret access logs</li> </ul>"},{"location":"configuration/secrets/#organization","title":"Organization","text":"<ul> <li>Descriptive names: Clear secret naming</li> <li>Namespace isolation: Secrets per namespace</li> <li>Documentation: Document secret purposes</li> <li>Template files: Provide example secrets</li> </ul>"},{"location":"configuration/secrets/#automation","title":"Automation","text":"<ul> <li>Automated rotation: Use automated tools where possible</li> <li>Secret sync: External secrets operators</li> <li>Validation: Check secret format before use</li> </ul>"},{"location":"configuration/secrets/#external-secret-management","title":"External Secret Management","text":""},{"location":"configuration/secrets/#hashicorp-vault","title":"HashiCorp Vault","text":"<p>For production environments, integrate with HashiCorp Vault using annotations for agent injection to dynamically retrieve secrets.</p>"},{"location":"configuration/secrets/#external-secrets-operator","title":"External Secrets Operator","text":"<p>Sync secrets from external sources using ExternalSecret CRDs that reference a SecretStore backend and specify refresh intervals and data mappings.</p>"},{"location":"configuration/secrets/#sealed-secrets","title":"Sealed Secrets","text":"<p>Encrypt secrets for safe Git storage using kubeseal to create SealedSecret resources that can only be decrypted by the cluster controller.</p>"},{"location":"configuration/secrets/#troubleshooting","title":"Troubleshooting","text":""},{"location":"configuration/secrets/#secret-not-found","title":"Secret Not Found","text":"Bash<pre><code># List secrets in namespace\nkubectl get secrets -n &lt;namespace&gt;\n\n# Describe secret\nkubectl describe secret &lt;secret-name&gt; -n &lt;namespace&gt;\n\n# Check RBAC permissions\nkubectl auth can-i get secrets -n &lt;namespace&gt;\n</code></pre>"},{"location":"configuration/secrets/#incorrect-values","title":"Incorrect Values","text":"Bash<pre><code># View secret data (base64 encoded)\nkubectl get secret &lt;secret-name&gt; -n &lt;namespace&gt; -o yaml\n\n# Decode specific key\nkubectl get secret &lt;secret-name&gt; -n &lt;namespace&gt; \\\n  -o jsonpath='{.data.password}' | base64 -d\n</code></pre>"},{"location":"configuration/secrets/#pod-cant-access-secret","title":"Pod Can't Access Secret","text":"Bash<pre><code># Check pod events\nkubectl describe pod &lt;pod-name&gt; -n &lt;namespace&gt;\n\n# Verify secret exists\nkubectl get secret &lt;secret-name&gt; -n &lt;namespace&gt;\n\n# Check volume mounts\nkubectl describe pod &lt;pod-name&gt; -n &lt;namespace&gt; | grep -A5 Mounts\n</code></pre>"},{"location":"configuration/secrets/#secret-rotation","title":"Secret Rotation","text":""},{"location":"configuration/secrets/#manual-rotation","title":"Manual Rotation","text":"<ol> <li>Update secret value</li> <li>Apply new secret</li> <li>Restart pods to pick up new value</li> </ol> Bash<pre><code># Update secret\nkubectl create secret generic app-secret \\\n  --from-literal=password=newpassword \\\n  --dry-run=client -o yaml | kubectl apply -f -\n\n# Restart deployment\nkubectl rollout restart deployment/&lt;deployment-name&gt; -n &lt;namespace&gt;\n</code></pre>"},{"location":"configuration/secrets/#automated-rotation","title":"Automated Rotation","text":"<p>For services with automated rotation support:</p> <ul> <li>Configure rotation schedule</li> <li>Set up monitoring</li> <li>Test rotation process</li> <li>Document recovery procedure</li> </ul>"},{"location":"configuration/secrets/#checklist","title":"Checklist","text":"<p>Regular secret management checklist:</p> <ul> <li> All secrets are encrypted</li> <li> No secrets in Git (plaintext)</li> <li> RBAC configured correctly</li> <li> Rotation schedule defined</li> <li> Backup secrets securely</li> <li> Document secret purposes</li> <li> Test secret access</li> <li> Monitor secret usage</li> <li> Audit secret access logs</li> </ul>"},{"location":"configuration/secrets/#related-documentation","title":"Related Documentation","text":"<ul> <li>Architecture: Security</li> <li>Base Configurations</li> <li>Getting Started: Scripts</li> </ul>"},{"location":"configuration/secrets/#abbreviations","title":"Abbreviations","text":""},{"location":"getting-started/","title":"Getting Started","text":"<p>Welcome to the deployment guide for My Kubernetes Homelab Platform. This section will walk you through everything you need to know to get your homelab up and running.</p>"},{"location":"getting-started/#overview","title":"Overview","text":"<p>The deployment process is designed to be straightforward and automated. You'll need:</p> <ol> <li>A running k3s cluster</li> <li>Basic knowledge of Kubernetes and kubectl</li> <li>Git for version control</li> <li>About 30 minutes for initial setup</li> </ol>"},{"location":"getting-started/#whats-next","title":"What's Next?","text":"<p>Follow these guides in order:</p> <ol> <li>Prerequisites - Set up your environment</li> <li>Installation - Deploy the platform</li> <li>Scripts Reference - Understand available automation scripts</li> </ol> <p>Quick Start</p> <p>If you already have k3s installed and configured, you can jump directly to the Installation guide.</p>"},{"location":"getting-started/#abbreviations","title":"Abbreviations","text":""},{"location":"getting-started/installation/","title":"Installation","text":"<p>This guide walks you through the step-by-step process of deploying the homelab platform.</p>"},{"location":"getting-started/installation/#overview","title":"Overview","text":"<p>The installation process consists of three main steps:</p> <pre><code>flowchart LR\n    A[Clone Repository] --&gt; B[Bootstrap Environment]\n    B --&gt; C[Deploy ArgoCD]\n    C --&gt; D[Access Applications]\n\n    B -.installs.- E[k3s + Tools]\n    C -.deploys.- F[ArgoCD]\n    F -.syncs.- G[All Applications]</code></pre> <ol> <li>Clone the repository</li> <li>Bootstrap the environment</li> <li>Deploy with ArgoCD</li> </ol> <p>The entire process typically takes 15-30 minutes, depending on your internet speed and cluster resources.</p>"},{"location":"getting-started/installation/#step-1-clone-the-repository","title":"Step 1: Clone the Repository","text":"<p>Clone the homelab repository to your local machine or deployment server:</p> Bash<pre><code># Clone the repository\ngit clone https://github.com/chaitanya2692/my-homelab.git\n\n# Navigate to the directory\ncd my-homelab\n</code></pre> <p>Branch Selection</p> <p>The <code>main</code> branch contains the stable configuration. For development or testing, you may want to use a different branch.</p>"},{"location":"getting-started/installation/#step-2-bootstrap-the-environment","title":"Step 2: Bootstrap the Environment","text":"<p>The bootstrap script installs essential tools and prepares your environment:</p> <pre><code>flowchart TD\n    A[Run bootstrap.sh] --&gt; B[Update System Packages]\n    B --&gt; C[Install Homebrew]\n    C --&gt; D[Install CLI Tools]\n    D --&gt; E[Install k3s]\n    E --&gt; F[Configure kubeconfig]\n    F --&gt; G[Create Storage Directories]\n    G --&gt; H[Setup Complete]\n\n    D -.installs.- I[kubectl, helm, kustomize&lt;br/&gt;k9s, kubeconform]\n    E -.flags.- J[--disable servicelb&lt;br/&gt;--disable traefik&lt;br/&gt;--disable local-storage]\n    F -.copies.- K[k3s.yaml to&lt;br/&gt;~/.kube/config]\n    G -.creates.- L[/opt/cluster/htpc&lt;br/&gt;/opt/cluster/utils&lt;br/&gt;/opt/cluster/infra]</code></pre> Bash<pre><code># Run the bootstrap script\n./scripts/bootstrap.sh\n</code></pre>"},{"location":"getting-started/installation/#what-bootstrap-does","title":"What Bootstrap Does","text":"<p>The bootstrap script performs comprehensive system setup:</p> <ul> <li>\u2705 Updates system packages</li> <li>\u2705 Installs Homebrew (for package management)</li> <li>\u2705 Installs required CLI tools (kubectl, helm, kustomize, k9s, kubeconform)</li> <li>\u2705 Installs Docker</li> <li>\u2705 Installs secret management tools (SOPS, ksops, age)</li> <li>\u2705 Installs K3s with custom flags (disables servicelb, traefik, local-storage)</li> <li>\u2705 Configures kubeconfig</li> <li>\u2705 Creates cluster storage directories at <code>/opt/cluster</code></li> <li>\u2705 Installs development tools (yq, jq, pre-commit)</li> </ul> <p>Bootstrap Script</p> <p>The bootstrap script is idempotent for most operations - it checks if tools are already installed before attempting installation.</p> <p>Age Key Required</p> <p>Ensure you have an Age encryption key at <code>~/key.txt</code> before running bootstrap. The script will move it to <code>~/.sops/key.txt</code>.</p>"},{"location":"getting-started/installation/#step-3-deploy-argocd","title":"Step 3: Deploy ArgoCD","text":"<p>ArgoCD is the GitOps tool that manages all deployments:</p> <pre><code>flowchart TD\n    A[Run kickstart.sh] --&gt; B[Build ArgoCD CRDs]\n    B --&gt; C[Apply CRDs]\n    C --&gt; D[Wait for CRD Established]\n    D --&gt; E[Create argocd Namespace]\n    E --&gt; F[Create SOPS Secret]\n    F --&gt; G[Build ArgoCD App]\n    G --&gt; H[Apply ArgoCD]\n    H --&gt; I[Wait for Pods Running]\n    I --&gt; J[Display Admin Password]\n\n    B -.uses.- K[kustomize build argocd/crds&lt;br/&gt;--enable-helm --enable-alpha-plugins]\n    F -.from.- L[/home/chaitanya/.sops/key.txt]\n    G -.uses.- M[kustomize build argocd/app&lt;br/&gt;--enable-helm --enable-alpha-plugins]\n    J -.retrieves.- N[argocd-initial-admin-secret]</code></pre> Bash<pre><code># Kickstart ArgoCD installation\n./scripts/kickstart.sh\n</code></pre>"},{"location":"getting-started/installation/#what-kickstart-does","title":"What Kickstart Does","text":"<p>The kickstart script:</p> <ol> <li>Builds and applies ArgoCD CRDs using Kustomize from <code>argocd/crds</code></li> <li>Waits for CRDs to be established in the cluster</li> <li>Creates argocd namespace (if it doesn't exist)</li> <li>Creates SOPS secret from your Age key for decrypting secrets</li> <li>Deploys ArgoCD application and all components</li> <li>Waits for all pods to be running</li> <li>Displays the admin password for ArgoCD access</li> </ol> <p>Initial Deployment Time</p> <p>The first deployment can take 10-20 minutes as all images are pulled and services start up.</p> <p>SOPS Key Location</p> <p>The kickstart script expects the SOPS Age key at <code>/home/chaitanya/.sops/key.txt</code>. Adjust the path in the script if yours is located elsewhere.</p>"},{"location":"getting-started/installation/#step-4-access-argocd","title":"Step 4: Access ArgoCD","text":"<p>Once the kickstart script completes, you can access ArgoCD:</p>"},{"location":"getting-started/installation/#get-admin-password","title":"Get Admin Password","text":"Bash<pre><code># Retrieve the ArgoCD admin password\nkubectl get secrets/argocd-initial-admin-secret -n argocd --template={{.data.password}} | base64 -d\n</code></pre>"},{"location":"getting-started/installation/#access-the-ui","title":"Access the UI","text":"<ol> <li> <p>Port Forward (for local access):</p> Bash<pre><code>kubectl port-forward svc/argocd-server -n argocd 8080:443\n</code></pre> <p>Then open: <code>https://localhost:8080</code></p> </li> <li> <p>Load Balancer (if configured):</p> <p>Navigate to: <code>https://argocd.yourdomain.com</code></p> </li> </ol>"},{"location":"getting-started/installation/#login","title":"Login","text":"<ul> <li>Username: <code>admin</code></li> <li>Password: Retrieved from the secret above</li> </ul> <p>Change Default Password</p> <p>For security, change the admin password after first login using the ArgoCD UI or CLI.</p>"},{"location":"getting-started/installation/#step-5-verify-deployment","title":"Step 5: Verify Deployment","text":"<p>Check that all applications are deployed and healthy:</p>"},{"location":"getting-started/installation/#using-kubectl","title":"Using kubectl","text":"Bash<pre><code># Check all namespaces\nkubectl get namespaces\n\n# Check pods in each namespace\nkubectl get pods -n infra\nkubectl get pods -n utils\nkubectl get pods -n htpc\n\n# Check ArgoCD applications\nkubectl get applications -n argocd\n</code></pre>"},{"location":"getting-started/installation/#using-argocd-ui","title":"Using ArgoCD UI","text":"<p>In the ArgoCD interface:</p> <ol> <li>Verify all applications show \"Synced\" and \"Healthy\"</li> <li>Check for any synchronization errors</li> <li>Review application details for any warnings</li> </ol>"},{"location":"getting-started/installation/#post-installation-configuration","title":"Post-Installation Configuration","text":""},{"location":"getting-started/installation/#configure-secrets","title":"Configure Secrets","text":"<p>After deployment, configure service-specific secrets using SOPS for encryption. The <code>encrypt-secrets.sh</code> script will encrypt any YAML files containing the <code>SOPS_SECRET_MARKER</code>.</p> <p>See Secrets Management for detailed instructions.</p>"},{"location":"getting-started/installation/#configure-ingress","title":"Configure Ingress","text":"<p>Update ingress configurations with your domain:</p> <ol> <li>Edit base ingress routes in <code>base/*/ingress-route.yaml</code></li> <li>Update overlay configurations for your environment</li> <li>Commit and push changes (ArgoCD will auto-sync)</li> </ol>"},{"location":"getting-started/installation/#configure-storage","title":"Configure Storage","text":"<p>Verify storage provisioning:</p> Bash<pre><code># Check persistent volumes\nkubectl get pv\n\n# Check persistent volume claims\nkubectl get pvc -A\n</code></pre>"},{"location":"getting-started/installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/installation/#common-issues","title":"Common Issues","text":"ArgoCD pods not starting <p>Symptom: ArgoCD pods remain in Pending or CrashLoopBackOff state.</p> <p>Solution:</p> Bash<pre><code># Check pod status and events\nkubectl get pods -n argocd\nkubectl describe pod -n argocd &lt;pod-name&gt;\n\n# Verify SOPS secret exists\nkubectl get secret sops-age -n argocd\n\n# Check ArgoCD server logs\nkubectl logs -n argocd -l app.kubernetes.io/name=argocd-server\n\n# Check resource availability\nkubectl top nodes\nkubectl top pods -n argocd\n</code></pre> Services not accessible <p>Symptom: Cannot access services through ingress.</p> <p>Solution:</p> Bash<pre><code># Check Traefik status\nkubectl get pods -n infra -l app.kubernetes.io/name=traefik\n\n# Check ingress routes\nkubectl get ingressroute -A\n\n# Check LoadBalancer IP\nkubectl get svc -n infra traefik\n\n# Verify MetalLB is running\nkubectl get pods -n infra -l app.kubernetes.io/name=metallb\n</code></pre> Certificate issues <p>Symptom: TLS certificates not being issued.</p> <p>Solution:</p> Bash<pre><code># Check cert-manager pods\nkubectl get pods -n infra -l app.kubernetes.io/name=cert-manager\n\n# Check certificate requests\nkubectl get certificaterequest -A\nkubectl get certificate -A\n\n# Check cert-manager logs\nkubectl logs -n infra -l app.kubernetes.io/name=cert-manager\n\n# Verify ClusterIssuer\nkubectl get clusterissuer\n</code></pre> Storage provisioning fails <p>Symptom: PVCs remain in Pending state.</p> <p>Solution:</p> Bash<pre><code># Check local-path-provisioner\nkubectl get pods -n infra -l app.kubernetes.io/name=local-path-provisioner\n\n# Verify storage directories exist\nls -la /opt/cluster/\n\n# Check PVC events\nkubectl describe pvc -n &lt;namespace&gt; &lt;pvc-name&gt;\n\n# List storage classes\nkubectl get storageclass\n</code></pre>"},{"location":"getting-started/installation/#getting-help","title":"Getting Help","text":"<p>If you encounter issues:</p> <ol> <li>Check the ArgoCD documentation</li> <li>Review application logs: <code>kubectl logs -n &lt;namespace&gt; &lt;pod-name&gt;</code></li> <li>Open an issue on the GitHub repository</li> </ol>"},{"location":"getting-started/installation/#next-steps","title":"Next Steps","text":"<p>Now that your platform is deployed:</p> <ul> <li>\ud83d\udcd6 Review the Architecture documentation</li> <li>\ud83d\udd27 Explore Configuration options</li> <li>\ud83d\ude80 Browse available Services</li> <li>\ud83d\udcdc Learn about automation Scripts</li> </ul>"},{"location":"getting-started/installation/#abbreviations","title":"Abbreviations","text":""},{"location":"getting-started/prerequisites/","title":"Prerequisites","text":"<p>Before deploying the homelab platform, ensure you have the following prerequisites in place.</p>"},{"location":"getting-started/prerequisites/#system-requirements","title":"System Requirements","text":""},{"location":"getting-started/prerequisites/#hardware","title":"Hardware","text":"<ul> <li>CPU: Minimum 4 cores (8 cores recommended)</li> <li>RAM: Minimum 8GB (16GB+ recommended)</li> <li>Storage: Minimum 100GB available disk space</li> <li>Network: Stable internet connection with static IP or DDNS</li> </ul>"},{"location":"getting-started/prerequisites/#operating-system","title":"Operating System","text":"<ul> <li>Ubuntu 20.04 LTS or newer (recommended)</li> <li>Debian 10 or newer</li> <li>Other Linux distributions with systemd support</li> </ul>"},{"location":"getting-started/prerequisites/#software-dependencies","title":"Software Dependencies","text":""},{"location":"getting-started/prerequisites/#required-tools","title":"Required Tools","text":"k3skubectlGit <p>The lightweight Kubernetes distribution that powers the platform.</p> Bash<pre><code># Install k3s (automatically installed by bootstrap.sh with custom flags)\ncurl -fL https://get.k3s.io | sh -s - --disable servicelb --disable traefik --disable local-storage\n\n# Verify installation\nsudo k3s kubectl get nodes\n</code></pre> <p>Bootstrap Automation</p> <p>The bootstrap script installs k3s with these flags automatically. Manual installation is only needed if not using the bootstrap script.</p> <p>For multi-node setups, refer to the k3s documentation.</p> <p>Command-line tool for interacting with Kubernetes.</p> Bash<pre><code># kubectl is included with k3s\n# Create an alias for convenience\necho \"alias kubectl='sudo k3s kubectl'\" &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n\n# Or copy kubeconfig for non-root access\nmkdir -p ~/.kube\nsudo cp /etc/rancher/k3s/k3s.yaml ~/.kube/config\nsudo chown $USER:$USER ~/.kube/config\nchmod 600 ~/.kube/config\n</code></pre> <p>Version control system for cloning the repository.</p> Bash<pre><code># Install Git\nsudo apt update\nsudo apt install -y git\n\n# Verify installation\ngit --version\n</code></pre>"},{"location":"getting-started/prerequisites/#additional-tools","title":"Additional Tools","text":"<p>Installed by Bootstrap</p> <p>These tools are automatically installed by the <code>bootstrap.sh</code> script:</p> <ul> <li>helm: Package manager for Kubernetes</li> <li>k9s: Terminal-based UI for Kubernetes</li> <li>kustomize: Template-free Kubernetes configuration</li> <li>sops and age: Secret encryption tools</li> <li>kubeconform: Kubernetes manifest validation</li> </ul>"},{"location":"getting-started/prerequisites/#network-configuration","title":"Network Configuration","text":""},{"location":"getting-started/prerequisites/#ip-address-planning","title":"IP Address Planning","text":"<p>The platform requires a dedicated IP range for LoadBalancer services:</p> <ul> <li>MetalLB IP Range: 192.168.1.240/28 (16 addresses)</li> <li>Traefik LoadBalancer: 192.168.1.245 (static assignment)</li> </ul> <p>IP Conflicts</p> <p>Ensure the IP range doesn't overlap with your DHCP server's allocation pool.</p>"},{"location":"getting-started/prerequisites/#dns-setup","title":"DNS Setup","text":"<p>For external access with TLS certificates:</p> <ol> <li>Domain Name: Register or use an existing domain</li> <li>DNS Provider: Cloudflare recommended (for DNS-01 challenges)</li> <li>Wildcard DNS: Point <code>*.yourdomain.com</code> to your external IP</li> </ol>"},{"location":"getting-started/prerequisites/#firewall-rules","title":"Firewall Rules","text":"<p>Open the following ports if you have a firewall:</p> Port Protocol Service Purpose 80 TCP HTTP Traefik ingress (redirects to 443) 443 TCP HTTPS Traefik ingress (TLS) 6443 TCP Kubernetes API k3s API server"},{"location":"getting-started/prerequisites/#storage-preparation","title":"Storage Preparation","text":""},{"location":"getting-started/prerequisites/#cluster-storage-directories","title":"Cluster Storage Directories","text":"<p>The bootstrap script automatically creates storage directories at <code>/opt/cluster</code>:</p> Bash<pre><code># These are created automatically by bootstrap.sh\n/opt/cluster/htpc\n/opt/cluster/utils\n/opt/cluster/infra\n</code></pre>"},{"location":"getting-started/prerequisites/#local-path-provisioner","title":"Local Path Provisioner","text":"<p>The platform uses local-path-provisioner for dynamic storage provisioning with namespace-specific storage classes. Storage paths are automatically created by the bootstrap script at:</p> <ul> <li><code>/opt/cluster/htpc</code> - Media services storage</li> <li><code>/opt/cluster/infra</code> - Infrastructure services storage</li> <li><code>/opt/cluster/utils</code> - Utility services storage</li> </ul>"},{"location":"getting-started/prerequisites/#media-storage","title":"Media Storage","text":"<p>For media services, prepare a dedicated storage location:</p> Text Only<pre><code>```bash\n# Example: External drive mount\nsudo mkdir -p /mnt/media\n# Mount your external storage here\n```\n</code></pre>"},{"location":"getting-started/prerequisites/#credentials-and-secrets","title":"Credentials and Secrets","text":"<p>Prepare the following credentials before deployment:</p>"},{"location":"getting-started/prerequisites/#age-encryption-key","title":"Age Encryption Key","text":"<p>Required Before Bootstrap</p> <p>An Age encryption key must exist at <code>~/key.txt</code> before running the bootstrap script. The script will move it to <code>~/.sops/key.txt</code>.</p> <p>Generate an Age key:</p> Bash<pre><code># Install age (if not already installed)\nsudo apt install age\n\n# Generate a new key\nage-keygen -o ~/key.txt\n\n# Backup your key securely!\n# Without this key, you cannot decrypt secrets\n</code></pre> <p>Backup Your Key</p> <p>Store your Age key in a secure location (password manager, encrypted backup). Without it, you cannot decrypt your secrets!</p>"},{"location":"getting-started/prerequisites/#required-secrets","title":"Required Secrets","text":"<ul> <li>Age Key (for SOPS encryption) - REQUIRED</li> <li>Cloudflare API Token (for cert-manager DNS-01 challenges)</li> <li>ArgoCD Admin Password (generated during installation)</li> <li>Service-specific credentials (database passwords, API keys, etc.)</li> </ul> <p>Secret Management</p> <p>Secrets should be created before deployment. See the Secrets configuration guide for details.</p>"},{"location":"getting-started/prerequisites/#validation-checklist","title":"Validation Checklist","text":"<p>Before proceeding to installation, verify:</p> <ul> <li> k3s cluster is running</li> <li> kubectl can access the cluster</li> <li> Git is installed</li> <li> IP range is reserved and available</li> <li> DNS configuration is complete (if using external access)</li> <li> Storage paths are prepared</li> <li> Required secrets are documented</li> </ul> <p>Ready to Install</p> <p>Once all prerequisites are met, proceed to the Installation guide.</p>"},{"location":"getting-started/prerequisites/#abbreviations","title":"Abbreviations","text":""},{"location":"getting-started/scripts-reference/","title":"Scripts Reference","text":"<p>The homelab platform includes several automation scripts to simplify common operations. All scripts are located in the <code>scripts/</code> directory.</p>"},{"location":"getting-started/scripts-reference/#script-overview","title":"Script Overview","text":"Script Purpose When to Use \ud83d\udee0\ufe0f bootstrap.sh Install essential libraries in a new Ubuntu VM Initial setup on a fresh system \u2705 validate.sh Config Check Before applying changes \ud83d\ude80 deploy.sh Deployment Manual deployment without ArgoCD \ud83d\udca3 nuke.sh Reset Cluster Complete cleanup and reset \u26a1 kickstart.sh Install ArgoCD and deploy services Initial platform deployment \ud83d\udee0\ufe0f update-manifests.sh Kustomize build Script Generate deployment manifests \ud83d\udd10 encrypt-secrets.sh Encode secrets in the repo Managing sensitive configuration"},{"location":"getting-started/scripts-reference/#detailed-script-documentation","title":"Detailed Script Documentation","text":""},{"location":"getting-started/scripts-reference/#bootstrapsh","title":"bootstrap.sh","text":"<p>Purpose: Prepares a fresh Ubuntu system with all required dependencies.</p> <pre><code>flowchart TD\n    A[Run bootstrap.sh] --&gt; B[Update System Packages]\n    B --&gt; C[Install Essential Tools]\n    C --&gt; D[Install Homebrew]\n    D --&gt; E[Install CLI Tools]\n    E --&gt; F[Install Docker]\n    F --&gt; G[Install Secret Management Tools]\n    G --&gt; H[Install k3s]\n    H --&gt; I[Configure kubeconfig]\n    I --&gt; J[Create Storage Directories]\n    J --&gt; K[Setup Complete]\n\n    C -.installs.- L[curl, wget, git, jq, build-essential]\n    E -.installs.- M[kubeconform, k9s, helm&lt;br/&gt;kustomize, yq, pre-commit]\n    G -.installs.- N[sops, ksops, age&lt;br/&gt;moves ~/key.txt to ~/.sops/]\n    H -.flags.- O[--disable servicelb&lt;br/&gt;--disable traefik&lt;br/&gt;--disable local-storage]\n    I -.copies.- P[/etc/rancher/k3s/k3s.yaml&lt;br/&gt;to ~/.kube/config]\n    J -.creates.- Q[/opt/cluster/htpc&lt;br/&gt;/opt/cluster/utils&lt;br/&gt;/opt/cluster/infra]</code></pre> <p>Usage:</p> Bash<pre><code>./scripts/bootstrap.sh\n</code></pre> <p>What it does:</p> <ul> <li>Updates system packages (<code>apt update &amp;&amp; apt upgrade</code>)</li> <li>Installs essential tools: <code>curl</code>, <code>wget</code>, <code>git</code>, <code>unzip</code>, <code>jq</code>, <code>build-essential</code></li> <li>Installs Homebrew (if not present)</li> <li>Installs via Homebrew: <code>kubeconform</code>, <code>k9s</code>, <code>kustomize</code></li> <li>Installs Docker</li> <li>Installs Helm from official script</li> <li>Installs SOPS (latest version from GitHub)</li> <li>Installs ksops (kustomize SOPS plugin)</li> <li>Installs Age encryption tool and sets up key in <code>~/.sops/key.txt</code></li> <li>Installs yq (YAML processor)</li> <li>Installs pip and pre-commit</li> <li>Installs K3s with flags: <code>--disable servicelb --disable traefik --disable local-storage</code></li> <li>Configures kubeconfig in <code>~/.kube/config</code></li> <li>Creates cluster storage directories: <code>/opt/cluster/{htpc,utils,infra}</code></li> </ul> <p>Prerequisites:</p> <ul> <li>Ubuntu 20.04+ or Debian 10+</li> <li>Sudo access</li> <li>Internet connectivity</li> <li>Age key file at <code>~/key.txt</code> (will be moved to <code>~/.sops/key.txt</code>)</li> </ul> <p>Output:</p> Text Only<pre><code>Bootstrap complete! Please log out and log back in to ensure all changes take effect.\n</code></pre> <p>First-time Setup Only</p> <p>This script modifies system packages and configurations. Run it only on initial setup or when setting up a new node.</p> <p>Age Key Required</p> <p>The script expects an Age encryption key file at <code>~/key.txt</code>. If not found, the script will exit with an error.</p>"},{"location":"getting-started/scripts-reference/#validatesh","title":"validate.sh","text":"<p>Purpose: Validates Kubernetes manifests and configuration files before deployment.</p> <pre><code>flowchart TD\n    A[Run validate.sh] --&gt; B[Validate YAML Files]\n    B --&gt; C[Validate Kubernetes Manifests]\n    C --&gt; D[Validate Kustomize Overlays]\n    D --&gt; E[Cleanup Charts]\n    E --&gt; F[Validation Complete]\n\n    B -.uses.- G[yq on all *.yaml files]\n    C -.uses.- H[kubeconform with&lt;br/&gt;--skip Secret&lt;br/&gt;--strict --ignore-missing-schemas]\n    D -.builds.- I[All kustomization.yaml files&lt;br/&gt;with --enable-helm --enable-alpha-plugins]\n    E -.removes.- J[Temporary charts/ directories]</code></pre> <p>Usage:</p> Bash<pre><code>./scripts/validate.sh\n</code></pre> <p>What it does:</p> <ul> <li>Validates all YAML files in the repository using <code>yq</code></li> <li>Validates Kubernetes manifests using <code>kubeconform</code> (skips Secrets)</li> <li>Validates all kustomization overlays by building and checking output</li> <li>Cleans up temporary chart directories after validation</li> </ul> <p>Validation Flags:</p> <ul> <li><code>--load-restrictor=LoadRestrictionsNone</code>: Allows Kustomize to load files from outside the base</li> <li><code>--enable-helm</code>: Enables Helm chart inflation</li> <li><code>--enable-alpha-plugins</code>: Enables alpha plugins</li> <li><code>--enable-exec</code>: Enables exec plugins (for ksops)</li> <li><code>-skip=Secret</code>: Skips Secret validation (encrypted secrets can't be validated)</li> <li><code>-strict</code>: Strict validation mode</li> <li><code>-ignore-missing-schemas</code>: Ignores missing schemas</li> <li><code>-verbose</code>: Verbose output</li> </ul> <p>When to use:</p> <ul> <li>Before committing changes</li> <li>Before deploying to production</li> <li>As part of CI/CD pipeline</li> <li>After modifying YAML files</li> </ul> <p>Output:</p> Text Only<pre><code>INFO - Validating YAML files\nINFO - Validating ./base/htpc/kustomization.yaml\nINFO - Validating Kubernetes manifests\nINFO - Validating kustomize overlays\nINFO - Validating kustomization ./overlays/htpc/\n...\n</code></pre> <p>CI/CD Integration</p> <p>This script is ideal for pre-commit hooks and CI/CD pipelines to catch errors before deployment.</p>"},{"location":"getting-started/scripts-reference/#deploysh","title":"deploy.sh","text":"<p>Purpose: Deploy pre-generated manifests from <code>install.yaml</code>, separating CRDs from other resources.</p> <p>Usage:</p> Bash<pre><code>./scripts/deploy.sh\n</code></pre> <p>What it does:</p> <ul> <li>Separates CRDs from non-CRD resources in <code>install.yaml</code></li> <li>Applies CRDs first and waits for them to be established</li> <li>Applies remaining resources</li> <li>Cleans up temporary files</li> </ul> <p>When to use:</p> <ul> <li>Deploying from pre-built manifests</li> <li>Testing generated configurations</li> <li>Manual deployment scenarios</li> <li>When not using ArgoCD</li> </ul> <p>Prerequisites:</p> <ul> <li><code>install.yaml</code> must exist (generated by <code>update-manifests.sh</code>)</li> <li>kubectl must be configured with cluster access</li> </ul> <p>Production Use</p> <p>For production, use ArgoCD instead of manual deployment to maintain GitOps principles.</p>"},{"location":"getting-started/scripts-reference/#nukesh","title":"nuke.sh","text":"<p>Purpose: Complete K3s uninstall and reinstall.</p> <p>Usage:</p> Bash<pre><code>./scripts/nuke.sh\n</code></pre> <p>What it does:</p> <ul> <li>Uninstalls existing K3s installation completely using k3s-uninstall script</li> <li>Reinstalls K3s with custom flags: <code>--disable servicelb --disable traefik</code> (note: does NOT disable local-storage)</li> <li>Copies kubeconfig from <code>/etc/rancher/k3s/k3s.yaml</code> to <code>~/.kube/config</code></li> </ul> <p>When to use:</p> <ul> <li>Complete cluster reset needed</li> <li>Starting fresh from scratch</li> <li>Troubleshooting persistent K3s issues</li> <li>Cleaning up failed installations</li> </ul> <p>Destructive Operation</p> <p>This script completely removes K3s and all cluster data. All deployments, configurations, and persistent volumes will be lost. Ensure you have backups before running.</p> <p>Flag Difference</p> <p>Unlike bootstrap.sh which disables servicelb, traefik, AND local-storage, nuke.sh only disables servicelb and traefik. Update the script if you need consistent behavior.</p>"},{"location":"getting-started/scripts-reference/#kickstartsh","title":"kickstart.sh","text":"<p>Purpose: Initial ArgoCD installation and application deployment.</p> <p>Usage:</p> Bash<pre><code>./scripts/kickstart.sh\n</code></pre> <p>What it does:</p> <ol> <li>Builds and applies ArgoCD CRDs using Kustomize</li> <li>Waits for CRDs to be established (specifically <code>applications.argoproj.io</code>)</li> <li>Creates ArgoCD namespace (if not exists)</li> <li>Creates SOPS-Age secret from <code>/home/chaitanya/.sops/key.txt</code> for encrypted secrets</li> <li>Builds and applies ArgoCD application resources</li> <li>Waits for all pods in the argocd namespace to be running</li> <li>Displays admin password for accessing ArgoCD UI</li> </ol> <p>Prerequisites:</p> <ul> <li>kubectl configured and connected to cluster</li> <li>SOPS Age key at <code>/home/chaitanya/.sops/key.txt</code> (hardcoded path in script)</li> <li>Kustomize, kubectl, and required tools installed</li> </ul> <p>When to use:</p> <ul> <li>Initial platform setup</li> <li>After running nuke.sh</li> <li>Setting up a new cluster</li> </ul> <p>Output:</p> <p>The script displays the ArgoCD initial admin password:</p> Text Only<pre><code>ArgoCD secret password:\n&lt;password-here&gt;\n</code></pre> <p>To access the ArgoCD UI before the ingress route is active, port-forward the service:</p> Bash<pre><code>kubectl port-forward svc/argocd-server -n argocd --address 0.0.0.0 8080:443\n</code></pre> <p>One-time Setup</p> <p>After successful kickstart, ArgoCD manages all deployments automatically.</p>"},{"location":"getting-started/scripts-reference/#update-manifestssh","title":"update-manifests.sh","text":"<p>Purpose: Build Kustomize manifests and generate combined install.yaml.</p> <pre><code>flowchart TD\n    A[Run update-manifests.sh] --&gt; B{Changes Detected?}\n    B --&gt;|No| C[Skip Build]\n    B --&gt;|Yes| D[Update Environment References]\n    D --&gt; E[Build htpc Overlay]\n    E --&gt; F[Build utils Overlay]\n    F --&gt; G[Build infra Overlay]\n    G --&gt; H[Build argocd Overlay]\n    H --&gt; I[Combine into install.yaml]\n    I --&gt; J[Cleanup Charts]\n    J --&gt; K[Build Complete]\n\n    B -.checks.- L[argocd/ base/&lt;br/&gt;overlays/ scripts/]\n    D -.updates.- M[kustomization.yaml files&lt;br/&gt;to staging or production]\n    E -.uses.- N[kustomize build&lt;br/&gt;--enable-helm&lt;br/&gt;--enable-alpha-plugins]</code></pre> <p>Usage:</p> Bash<pre><code>./scripts/update-manifests.sh [environment]\n</code></pre> <p>Parameters:</p> <ul> <li><code>environment</code> (optional): Target environment (<code>staging</code> or <code>production</code>). Defaults to <code>staging</code>.</li> </ul> <p>What it does:</p> <ul> <li>Checks for changes in <code>argocd</code>, <code>base</code>, <code>overlays</code>, or <code>scripts</code> directories</li> <li>Updates environment references in kustomization files</li> <li>Runs <code>kustomize build</code> for each overlay (htpc, utils, infra, argocd)</li> <li>Generates a combined <code>install.yaml</code> file in the repository root</li> <li>Cleans up temporary chart directories</li> </ul> <p>When to use:</p> <ul> <li>After modifying base configurations or overlays</li> <li>Before manual deployment with <code>deploy.sh</code></li> <li>Testing Kustomize builds</li> <li>Generating deployment artifacts</li> </ul> <p>Output Location:</p> <p>Generated file: <code>install.yaml</code> (in repository root)</p> <p>Smart Updates</p> <p>The script only rebuilds if changes are detected in relevant directories, saving time on unchanged configurations.</p>"},{"location":"getting-started/scripts-reference/#encrypt-secretssh","title":"encrypt-secrets.sh","text":"<p>Purpose: Encrypt Kubernetes secrets using SOPS and Age encryption.</p> <pre><code>flowchart TD\n    A[Run encrypt-secrets.sh] --&gt; B{SOPS_AGE_KEY_FILE Set?}\n    B --&gt;|No| C[Error: Exit]\n    B --&gt;|Yes| D{Key File Exists?}\n    D --&gt;|No| C\n    D --&gt;|Yes| E[Find All YAML Files]\n    E --&gt; F{Contains SOPS_SECRET_MARKER?}\n    F --&gt;|No| G[Skip File]\n    F --&gt;|Yes| H[Encrypt data/stringData Fields]\n    H --&gt; I[Remove Marker]\n    I --&gt; J[Add YAML Separator]\n    J --&gt; K[Update File In-Place]\n    K --&gt; L[Continue to Next File]\n\n    H -.uses.- M[sops --encrypt --age&lt;br/&gt;--encrypted-regex '^data|stringData'$']\n    L --&gt; F</code></pre> <p>Usage:</p> Bash<pre><code># Set the SOPS age key file location\nexport SOPS_AGE_KEY_FILE=$HOME/.sops/key.txt\n\n# Run the encryption script\n./scripts/encrypt-secrets.sh\n</code></pre> <p>Prerequisites:</p> <ul> <li><code>SOPS_AGE_KEY_FILE</code> environment variable must be set</li> <li>Age key file must exist at the specified location</li> <li>Secret YAML files must contain the <code>SOPS_SECRET_MARKER</code> comment</li> </ul> <p>What it does:</p> <ul> <li>Searches for all YAML files in the repository</li> <li>Identifies files containing <code>SOPS_SECRET_MARKER</code></li> <li>Encrypts the <code>data</code> and <code>stringData</code> fields using SOPS with Age</li> <li>Removes the marker and adds YAML document separator</li> <li>Updates files in place</li> </ul> <p>When to use:</p> <ul> <li>After adding new secrets to YAML files</li> <li>Before committing secrets to version control</li> <li>When rotating encryption keys</li> <li>Setting up secrets for new environments</li> </ul> <p>Secret Format:</p> <p>Mark files for encryption by adding a comment:</p> YAML<pre><code># SOPS_SECRET_MARKER\napiVersion: v1\nkind: Secret\nmetadata:\n  name: my-secret\nstringData:\n  password: mysecretpassword\n</code></pre> <p>Secure Secret Management</p> <p>SOPS encryption allows secrets to be safely committed to version control while keeping values encrypted at rest.</p>"},{"location":"getting-started/scripts-reference/#script-best-practices","title":"Script Best Practices","text":""},{"location":"getting-started/scripts-reference/#running-scripts-safely","title":"Running Scripts Safely","text":"<ol> <li>Always validate first: Run <code>validate.sh</code> before deployment scripts</li> <li>Use dry-run: Test with <code>--dry-run</code> flag when available</li> <li>Check cluster context: Verify you're targeting the correct cluster</li> <li>Review output: Read script output carefully for errors or warnings</li> </ol>"},{"location":"getting-started/scripts-reference/#automation","title":"Automation","text":"<p>These scripts can be integrated into CI/CD pipelines. For example, in GitHub Actions, you can run validation, update manifests, and perform dry-run deployments as part of your workflow steps.</p>"},{"location":"getting-started/scripts-reference/#troubleshooting-scripts","title":"Troubleshooting Scripts","text":"<p>If a script fails:</p> <ol> <li>Check prerequisites: Ensure required tools are installed</li> <li>Verify permissions: Ensure you have cluster access</li> <li>Review logs: Check script output for error messages</li> <li>Manual execution: Try running commands manually for debugging</li> </ol>"},{"location":"getting-started/scripts-reference/#custom-scripts","title":"Custom Scripts","text":"<p>To add custom scripts:</p> <ol> <li>Place them in the <code>scripts/</code> directory</li> <li>Make them executable: <code>chmod +x scripts/myscript.sh</code></li> <li>Follow existing script patterns</li> <li>Add documentation to this page</li> </ol>"},{"location":"getting-started/scripts-reference/#additional-resources","title":"Additional Resources","text":"<ul> <li>ArgoCD CLI Documentation</li> <li>Kustomize Reference</li> <li>kubectl Cheat Sheet</li> </ul>"},{"location":"getting-started/scripts-reference/#abbreviations","title":"Abbreviations","text":""},{"location":"includes/abbreviations/","title":"Abbreviations","text":""},{"location":"includes/abbreviations/#abbreviations_1","title":"Abbreviations","text":""},{"location":"reference/","title":"Reference","text":"<p>Technical reference documentation for the homelab platform.</p>"},{"location":"reference/#reference-documentation","title":"Reference Documentation","text":"<ul> <li> <p> Storage Reference</p> <p>Complete PVC specifications and capacity planning</p> </li> <li> <p> Network Reference</p> <p>IP addressing, ports, and load balancer configuration</p> </li> <li> <p> Scripts API</p> <p>Detailed automation script documentation</p> </li> </ul>"},{"location":"reference/#quick-reference","title":"Quick Reference","text":""},{"location":"reference/#common-commands","title":"Common Commands","text":"Bash<pre><code># Check cluster status\nkubectl get nodes\nkubectl get pods -A\n\n# Check ArgoCD applications\nkubectl get applications -n argocd\n\n# View service logs\nkubectl logs -n &lt;namespace&gt; &lt;pod-name&gt;\n\n# Port forward to service\nkubectl port-forward -n &lt;namespace&gt; svc/&lt;service&gt; &lt;local-port&gt;:&lt;remote-port&gt;\n</code></pre>"},{"location":"reference/#common-paths","title":"Common Paths","text":"<ul> <li>Storage: <code>/opt/local-path-provisioner</code></li> <li>Kubeconfig: <code>/etc/rancher/k3s/k3s.yaml</code></li> <li>k3s service: <code>/etc/systemd/system/k3s.service</code></li> </ul>"},{"location":"reference/#common-ports","title":"Common Ports","text":"<ul> <li>HTTP: 80</li> <li>HTTPS: 443</li> <li>Kubernetes API: 6443</li> <li>ArgoCD: 8080 (port-forward)</li> <li>Grafana: 3000 (port-forward)</li> </ul>"},{"location":"reference/#related-documentation","title":"Related Documentation","text":"<ul> <li>Architecture</li> <li>Getting Started</li> <li>Configuration</li> </ul>"},{"location":"reference/#abbreviations","title":"Abbreviations","text":""},{"location":"reference/network-reference/","title":"Network Reference","text":"<p>IP addressing, port allocations, and load balancer configuration reference.</p>"},{"location":"reference/network-reference/#network-architecture-overview","title":"Network Architecture Overview","text":"<pre><code>flowchart TB\n    Internet[Internet] --&gt; Router[Home Router]\n    Router --&gt; Server[Homelab Server&lt;br/&gt;Ubuntu 22.04]\n\n    subgraph \"k3s Cluster\"\n        Server --&gt; k3s[k3s Control Plane]\n        k3s --&gt; MetalLB[MetalLB Controller&lt;br/&gt;IP Pool: 192.168.1.240/28]\n        MetalLB --&gt; Traefik[Traefik LoadBalancer&lt;br/&gt;192.168.1.245]\n\n        Traefik --&gt; Infra[infra namespace]\n        Traefik --&gt; Utils[utils namespace]\n        Traefik --&gt; HTPC[htpc namespace]\n\n        Infra --&gt; InfraApps[ArgoCD, Grafana&lt;br/&gt;Prometheus, Jaeger]\n        Utils --&gt; UtilsApps[Nextcloud, Immich&lt;br/&gt;Homepage, Tandoor]\n        HTPC --&gt; HTPCApps[Jellyfin, Sonarr&lt;br/&gt;Radarr, Prowlarr]\n    end</code></pre>"},{"location":"reference/network-reference/#ip-address-allocation","title":"IP Address Allocation","text":""},{"location":"reference/network-reference/#metallb-ip-pool","title":"MetalLB IP Pool","text":"<p>IP Range: <code>192.168.1.240/28</code></p> Start IP End IP Total Addresses Usable Addresses 192.168.1.240 192.168.1.255 16 16"},{"location":"reference/network-reference/#reserved-ip-assignments","title":"Reserved IP Assignments","text":"IP Address Service Purpose 192.168.1.245 Traefik Primary ingress controller LoadBalancer 192.168.1.246-255 Available Future services"},{"location":"reference/network-reference/#ip-range-considerations","title":"IP Range Considerations","text":"<p>Network Planning</p> <p>Ensure the MetalLB IP range does not overlap with:</p> <ul> <li>DHCP server allocation pool</li> <li>Static IP assignments</li> <li>Other network services</li> </ul>"},{"location":"reference/network-reference/#port-allocations","title":"Port Allocations","text":""},{"location":"reference/network-reference/#external-ports-traefik-loadbalancer","title":"External Ports (Traefik LoadBalancer)","text":"Port Protocol Service Purpose 80 TCP HTTP Automatic redirect to HTTPS 443 TCP HTTPS TLS-encrypted traffic"},{"location":"reference/network-reference/#kubernetes-api","title":"Kubernetes API","text":"Port Protocol Service Purpose 6443 TCP k3s API Server Kubernetes API access"},{"location":"reference/network-reference/#internal-service-ports","title":"Internal Service Ports","text":""},{"location":"reference/network-reference/#infrastructure-services","title":"Infrastructure Services","text":"Service Port Protocol Purpose ArgoCD Server 80, 443 TCP GitOps UI (HTTP/HTTPS) ArgoCD Metrics 8083 TCP Metrics endpoint Grafana 80 TCP Dashboards Prometheus 9090 TCP Metrics API Loki 3100 TCP Log ingestion Jaeger Query 16686 TCP Trace UI Jaeger Collector 14250, 4317 TCP Trace collection"},{"location":"reference/network-reference/#personal-cloud-services","title":"Personal Cloud Services","text":"Service Port Protocol Purpose Nextcloud 80 TCP Web interface Immich 3001 TCP Web interface (Helm chart default) Immich ML 3003 TCP ML processing (Helm chart default) Homepage 3000 TCP Dashboard Tandoor 80, 8080 TCP Web interface (HTTP and Gunicorn) <p>Helm Chart Defaults</p> <p>Immich ports are based on the official Helm chart defaults. The actual ports are managed by the chart and may vary with different versions.</p>"},{"location":"reference/network-reference/#media-services","title":"Media Services","text":"Service Port Protocol Purpose Jellyfin 8096 TCP Web interface and streaming Jellyfin HTTPS 8920 TCP Secure streaming Sonarr 8989 TCP Web interface Radarr 7878 TCP Web interface Prowlarr 9696 TCP Web interface Transmission 9091 TCP Web interface FlareSolverr 8191 TCP CAPTCHA solver API Scraparr 7100 TCP Metadata API"},{"location":"reference/network-reference/#data-layer","title":"Data Layer","text":"Service Port Protocol Purpose PostgreSQL 5432 TCP Database connection Redis 6379 TCP Cache connection Valkey 6379 TCP Cache connection"},{"location":"reference/network-reference/#dns-configuration","title":"DNS Configuration","text":""},{"location":"reference/network-reference/#domain-structure","title":"Domain Structure","text":"Text Only<pre><code>example.com                     # Root domain\n\u251c\u2500\u2500 *.example.com              # Wildcard (all services)\n\u251c\u2500\u2500 argocd.example.com         # ArgoCD UI\n\u251c\u2500\u2500 grafana.example.com        # Grafana dashboards\n\u251c\u2500\u2500 nextcloud.example.com      # Nextcloud\n\u251c\u2500\u2500 immich.example.com         # Immich\n\u251c\u2500\u2500 jellyfin.example.com       # Jellyfin\n\u2514\u2500\u2500 ...                        # Other services\n</code></pre>"},{"location":"reference/network-reference/#dns-records","title":"DNS Records","text":""},{"location":"reference/network-reference/#a-record-root","title":"A Record (Root)","text":"Text Only<pre><code>Type: A\nName: @\nContent: &lt;external-ip&gt;\nProxy: Enabled (Cloudflare)\n</code></pre>"},{"location":"reference/network-reference/#cname-record-wildcard","title":"CNAME Record (Wildcard)","text":"Text Only<pre><code>Type: CNAME\nName: *\nContent: @\nProxy: Enabled (Cloudflare)\n</code></pre>"},{"location":"reference/network-reference/#internal-dns","title":"Internal DNS","text":"<p>For local-only access:</p> Bash<pre><code># /etc/hosts or local DNS server\n192.168.1.245 argocd.local.domain\n192.168.1.245 grafana.local.domain\n192.168.1.245 nextcloud.local.domain\n</code></pre>"},{"location":"reference/network-reference/#network-topology","title":"Network Topology","text":"<pre><code>graph TD\n    Internet[Internet] --&gt; Router[Router]\n    Router --&gt; Switch[Network Switch]\n    Switch --&gt; Server[Homelab Server]\n\n    subgraph \"Homelab Server\"\n        Server --&gt; k3s[k3s Cluster]\n        k3s --&gt; MetalLB[MetalLB]\n        MetalLB --&gt; Traefik[Traefik&lt;br/&gt;192.168.1.245]\n        Traefik --&gt; Services[Services]\n    end\n\n    subgraph \"Services\"\n        Services --&gt; Infra[Infrastructure]\n        Services --&gt; Utils[Utilities]\n        Services --&gt; HTPC[Media]\n    end</code></pre>"},{"location":"reference/network-reference/#firewall-configuration","title":"Firewall Configuration","text":""},{"location":"reference/network-reference/#required-inbound-rules","title":"Required Inbound Rules","text":"Port Protocol Source Description 80 TCP Any HTTP (redirects to HTTPS) 443 TCP Any HTTPS 6443 TCP Admin IPs Kubernetes API (restrict)"},{"location":"reference/network-reference/#optional-inbound-rules","title":"Optional Inbound Rules","text":"Port Protocol Source Description 22 TCP Admin IPs SSH access (if enabled)"},{"location":"reference/network-reference/#outbound-rules","title":"Outbound Rules","text":"Port Protocol Destination Description 80, 443 TCP Any HTTP/HTTPS (updates, downloads) 53 UDP DNS Servers DNS queries"},{"location":"reference/network-reference/#network-policies","title":"Network Policies","text":""},{"location":"reference/network-reference/#default-deny","title":"Default Deny","text":"YAML<pre><code>apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: default-deny-all\n  namespace: utils\nspec:\n  podSelector: {}\n  policyTypes:\n    - Ingress\n    - Egress\n</code></pre>"},{"location":"reference/network-reference/#allow-from-traefik","title":"Allow from Traefik","text":"YAML<pre><code>apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: allow-from-traefik\n  namespace: utils\nspec:\n  podSelector:\n    matchLabels:\n      app: my-app\n  policyTypes:\n    - Ingress\n  ingress:\n    - from:\n        - namespaceSelector:\n            matchLabels:\n              name: infra\n        - podSelector:\n            matchLabels:\n              app.kubernetes.io/name: traefik\n      ports:\n        - protocol: TCP\n          port: 8080\n</code></pre>"},{"location":"reference/network-reference/#allow-dns","title":"Allow DNS","text":"YAML<pre><code>apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: allow-dns\nspec:\n  podSelector: {}\n  policyTypes:\n    - Egress\n  egress:\n    - to:\n        - namespaceSelector:\n            matchLabels:\n              name: kube-system\n        - podSelector:\n            matchLabels:\n              k8s-app: kube-dns\n      ports:\n        - protocol: UDP\n          port: 53\n</code></pre>"},{"location":"reference/network-reference/#load-balancer-configuration","title":"Load Balancer Configuration","text":""},{"location":"reference/network-reference/#metallb-layer-2-configuration","title":"MetalLB Layer 2 Configuration","text":"<p>Actual Configuration:</p> YAML<pre><code>---\napiVersion: metallb.io/v1beta1\nkind: IPAddressPool\nmetadata:\n  name: first-pool\nspec:\n  addresses:\n    - 192.168.1.240/28\n---\napiVersion: metallb.io/v1beta1\nkind: L2Advertisement\nmetadata:\n  name: empty\n</code></pre> <p>The MetalLB IPAddressPool and L2Advertisement are deployed in the <code>infra</code> namespace via Kustomize.</p> <p>Example with Namespace (for reference):</p> YAML<pre><code>apiVersion: metallb.io/v1beta1\nkind: IPAddressPool\nmetadata:\n  name: first-pool\n  namespace: infra\nspec:\n  addresses:\n    - 192.168.1.240/28\n\n---\napiVersion: metallb.io/v1beta1\nkind: L2Advertisement\nmetadata:\n  name: empty\n  namespace: infra\n</code></pre>"},{"location":"reference/network-reference/#service-loadbalancer-example","title":"Service LoadBalancer Example","text":"<p>Traefik is deployed as a LoadBalancer service. The actual configuration is managed via Helm values:</p> YAML<pre><code>  enabled: true\n\nservice:\n  enabled: true\n  type: LoadBalancer\n  spec:\n    loadBalancerIP: 192.168.1.245\n    externalTrafficPolicy: Local\n</code></pre> <p>This creates a LoadBalancer service that MetalLB assigns to <code>192.168.1.245</code>. The Helm chart handles port mappings automatically:</p> <ul> <li>Port 80 (web) \u2192 redirects to HTTPS</li> <li>Port 443 (websecure) \u2192 TLS-encrypted traffic</li> <li>Port 8082 (metrics) \u2192 Prometheus metrics</li> </ul>"},{"location":"reference/network-reference/#ingress-configuration","title":"Ingress Configuration","text":""},{"location":"reference/network-reference/#ingressroute-example","title":"IngressRoute Example","text":"YAML<pre><code>apiVersion: traefik.containo.us/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: service-ingress\n  namespace: utils\nspec:\n  entryPoints:\n    - websecure\n  routes:\n    - match: Host(`service.example.com`)\n      kind: Rule\n      services:\n        - name: service\n          port: 80\n      middlewares:\n        - name: security-headers\n  tls:\n    secretName: wildcard-cert\n</code></pre>"},{"location":"reference/network-reference/#middleware-example","title":"Middleware Example","text":"YAML<pre><code>apiVersion: traefik.containo.us/v1alpha1\nkind: Middleware\nmetadata:\n  name: security-headers\n  namespace: infra\nspec:\n  headers:\n    sslRedirect: true\n    stsSeconds: 31536000\n    stsIncludeSubdomains: true\n    stsPreload: true\n    forceSTSHeader: true\n    contentTypeNosniff: true\n    browserXssFilter: true\n    referrerPolicy: \"same-origin\"\n</code></pre>"},{"location":"reference/network-reference/#troubleshooting","title":"Troubleshooting","text":""},{"location":"reference/network-reference/#network-troubleshooting","title":"Network Troubleshooting","text":"Bash<pre><code># Test external access\ncurl -I https://service.example.com\n\n# Test internal service\nkubectl run -it --rm debug --image=curlimages/curl --restart=Never -- \\\n  curl http://service.namespace.svc.cluster.local\n\n# Test DNS resolution\nkubectl run -it --rm debug --image=busybox --restart=Never -- \\\n  nslookup service.namespace.svc.cluster.local\n\n# Check network policies\nkubectl get networkpolicy -A\nkubectl describe networkpolicy &lt;name&gt; -n &lt;namespace&gt;\n</code></pre>"},{"location":"reference/network-reference/#metallb-debugging","title":"MetalLB Debugging","text":"Bash<pre><code># Check speaker pods\nkubectl get pods -n infra -l app=metallb,component=speaker\n\n# Check controller logs\nkubectl logs -n infra -l app=metallb,component=controller\n\n# Check IP assignments\nkubectl get svc -A | grep LoadBalancer |\n\n# Describe service\nkubectl describe svc traefik -n infra\n</code></pre>"},{"location":"reference/network-reference/#traefik-debugging","title":"Traefik Debugging","text":"Bash<pre><code># Check Traefik pods\nkubectl get pods -n infra -l app.kubernetes.io/name=traefik\n\n# View Traefik logs\nkubectl logs -n infra -l app.kubernetes.io/name=traefik\n\n# Check IngressRoutes\nkubectl get ingressroute -A\n\n# Describe IngressRoute\nkubectl describe ingressroute &lt;name&gt; -n &lt;namespace&gt;\n\n# Access Traefik dashboard\nkubectl port-forward -n infra svc/traefik 9000:9000\n# Visit http://localhost:9000/dashboard/\n</code></pre>"},{"location":"reference/network-reference/#related-documentation","title":"Related Documentation","text":"<ul> <li>Architecture: Networking</li> <li>Architecture: Security</li> <li>Services: Core Platform</li> </ul>"},{"location":"reference/network-reference/#abbreviations","title":"Abbreviations","text":""},{"location":"reference/scripts-api/","title":"Scripts API","text":"<p>Detailed documentation for automation scripts with parameters, options, and usage examples.</p>"},{"location":"reference/scripts-api/#script-overview","title":"Script Overview","text":"<pre><code>flowchart LR\n    A[Fresh System] --&gt; B[bootstrap.sh]\n    B --&gt; C[kickstart.sh]\n    C --&gt; D[Running Platform]\n\n    D --&gt; E[validate.sh]\n    E -.CI/CD.- F[update-manifests.sh]\n    F -.optional.- G[deploy.sh]\n\n    D --&gt; H[encrypt-secrets.sh]\n    D --&gt; I[nuke.sh]\n    I --&gt; B\n\n    style B fill:#90EE90\n    style C fill:#87CEEB\n    style E fill:#FFD700\n    style I fill:#FF6B6B</code></pre>"},{"location":"reference/scripts-api/#script-location","title":"Script Location","text":"<p>All scripts are located in the <code>scripts/</code> directory at the repository root.</p>"},{"location":"reference/scripts-api/#bootstrapsh","title":"bootstrap.sh","text":"<p>Install essential tools and prepare a fresh Ubuntu system.</p>"},{"location":"reference/scripts-api/#bootstrapsh-synopsis","title":"bootstrap.sh Synopsis","text":"Bash<pre><code>./scripts/bootstrap.sh\n</code></pre>"},{"location":"reference/scripts-api/#bootstrapsh-description","title":"bootstrap.sh Description","text":"<p>Prepares a fresh Ubuntu system with all required dependencies for running the homelab platform.</p>"},{"location":"reference/scripts-api/#bootstrapsh-what-it-does","title":"bootstrap.sh What It Does","text":"<ol> <li>Updates system packages</li> <li>Installs essential tools (curl, wget, git, jq, build-essential)</li> <li>Installs Homebrew (if not present)</li> <li>Installs kubeconform via Homebrew</li> <li>Installs k9s via Homebrew</li> <li>Installs Docker (if not present)</li> <li>Installs Helm</li> <li>Installs kustomize via Homebrew</li> <li>Installs SOPS (latest version from GitHub)</li> <li>Installs ksops (kustomize SOPS plugin)</li> <li>Installs age encryption tool</li> <li>Moves Age key from <code>~/key.txt</code> to <code>~/.sops/key.txt</code></li> <li>Installs yq (YAML processor)</li> <li>Installs pip and pre-commit</li> <li>Installs K3s with flags: <code>--disable servicelb --disable traefik --disable local-storage</code></li> <li>Configures kubeconfig at <code>~/.kube/config</code></li> <li>Creates cluster storage directories at <code>/opt/cluster/{htpc,utils,infra}</code></li> <li>Sets proper permissions on storage directories</li> </ol>"},{"location":"reference/scripts-api/#bootstrapsh-prerequisites","title":"bootstrap.sh Prerequisites","text":"<ul> <li>Ubuntu 20.04+ or Debian 10+</li> <li>Sudo access</li> <li>Internet connectivity</li> <li>Age key file at <code>~/key.txt</code> (will be moved to <code>~/.sops/key.txt</code>)</li> </ul> <p>Age Key Required</p> <p>The script will exit with an error if <code>~/key.txt</code> is not found. Generate it first with <code>age-keygen -o ~/key.txt</code>.</p>"},{"location":"reference/scripts-api/#bootstrapsh-exit-codes","title":"bootstrap.sh Exit Codes","text":"Code Meaning 0 Success 1 General error"},{"location":"reference/scripts-api/#bootstrapsh-example","title":"bootstrap.sh Example","text":"Bash<pre><code># Run the bootstrap script\n./scripts/bootstrap.sh\n</code></pre>"},{"location":"reference/scripts-api/#validatesh","title":"validate.sh","text":"<p>Validate Kubernetes manifests and configuration files.</p>"},{"location":"reference/scripts-api/#validatesh-synopsis","title":"validate.sh Synopsis","text":"Bash<pre><code>./scripts/validate.sh\n</code></pre>"},{"location":"reference/scripts-api/#validatesh-description","title":"validate.sh Description","text":"<p>Runs comprehensive validation on YAML files and Kubernetes manifests in the repository.</p>"},{"location":"reference/scripts-api/#validatesh-what-it-does","title":"validate.sh What It Does","text":"<ol> <li>YAML syntax validation using yq</li> <li>Kubernetes schema validation using kubeconform</li> <li>Validates all kustomization overlays</li> <li>Cleans up temporary chart directories</li> </ol>"},{"location":"reference/scripts-api/#validatesh-exit-codes","title":"validate.sh Exit Codes","text":"Code Meaning 0 All validations passed 1 Validation errors found"},{"location":"reference/scripts-api/#validatesh-example","title":"validate.sh Example","text":"Bash<pre><code># Run validation from repository root\n./scripts/validate.sh\n</code></pre>"},{"location":"reference/scripts-api/#deploysh","title":"deploy.sh","text":"<p>Deploy manifests by separating CRDs from other resources.</p>"},{"location":"reference/scripts-api/#synopsis","title":"Synopsis","text":"Bash<pre><code>./scripts/deploy.sh\n</code></pre>"},{"location":"reference/scripts-api/#description","title":"Description","text":"<p>Deploys Kubernetes manifests by properly handling CRDs and non-CRD resources separately.</p>"},{"location":"reference/scripts-api/#what-it-does","title":"What It Does","text":"<ol> <li>Separates CRDs from non-CRD resources in install.yaml</li> <li>Applies CRDs first</li> <li>Waits for CRDs to be established</li> <li>Applies non-CRD resources</li> <li>Cleans up temporary files</li> </ol>"},{"location":"reference/scripts-api/#exit-codes","title":"Exit Codes","text":"Code Meaning 0 Deployment successful 1 Deployment failed"},{"location":"reference/scripts-api/#example","title":"Example","text":"Bash<pre><code># Deploy all resources\n./scripts/deploy.sh\n</code></pre>"},{"location":"reference/scripts-api/#nukesh","title":"nuke.sh","text":"<p>Complete k3s cluster reset and reinstallation.</p>"},{"location":"reference/scripts-api/#nukesh-synopsis","title":"nuke.sh Synopsis","text":"Bash<pre><code>./scripts/nuke.sh\n</code></pre>"},{"location":"reference/scripts-api/#nukesh-description","title":"nuke.sh Description","text":"<p>Performs complete uninstallation and reinstallation of k3s without default components.</p> <p>Destructive Operation</p> <p>This operation uninstalls k3s completely and reinstalls it fresh.</p>"},{"location":"reference/scripts-api/#nukesh-what-it-does","title":"nuke.sh What It Does","text":"<ol> <li>Uninstalls existing k3s installation using <code>/usr/local/bin/k3s-uninstall.sh</code></li> <li>Reinstalls k3s with flags: <code>--disable servicelb --disable traefik</code> (note: does NOT disable local-storage)</li> <li>Copies kubeconfig from <code>/etc/rancher/k3s/k3s.yaml</code> to <code>~/.kube/config</code></li> </ol> <p>Inconsistent Flags</p> <p>Unlike <code>bootstrap.sh</code> which disables servicelb, traefik, AND local-storage, <code>nuke.sh</code> only disables servicelb and traefik.</p>"},{"location":"reference/scripts-api/#nukesh-exit-codes","title":"nuke.sh Exit Codes","text":"Code Meaning 0 Reset successful 1 Reset failed"},{"location":"reference/scripts-api/#nukesh-example","title":"nuke.sh Example","text":"Bash<pre><code># Reset and reinstall k3s\n./scripts/nuke.sh\n</code></pre>"},{"location":"reference/scripts-api/#kickstartsh","title":"kickstart.sh","text":"<p>Install ArgoCD and bootstrap the platform.</p>"},{"location":"reference/scripts-api/#kickstartsh-synopsis","title":"kickstart.sh Synopsis","text":"Bash<pre><code>./scripts/kickstart.sh\n</code></pre>"},{"location":"reference/scripts-api/#kickstartsh-description","title":"kickstart.sh Description","text":"<p>Performs initial ArgoCD installation and displays access credentials.</p>"},{"location":"reference/scripts-api/#kickstartsh-what-it-does","title":"kickstart.sh What It Does","text":"<ol> <li>Builds and applies ArgoCD CRDs</li> <li>Waits for Application CRD to be established</li> <li>Creates argocd namespace</li> <li>Creates sops-age secret from <code>/home/chaitanya/.sops/key.txt</code></li> <li>Deploys ArgoCD application resources</li> <li>Waits for all pods to be running</li> <li>Displays ArgoCD admin password</li> </ol>"},{"location":"reference/scripts-api/#output","title":"Output","text":"<p>The script displays installation progress and provides the ArgoCD initial admin password.</p>"},{"location":"reference/scripts-api/#kickstartsh-exit-codes","title":"kickstart.sh Exit Codes","text":"Code Meaning 0 Installation successful 1 Installation failed"},{"location":"reference/scripts-api/#kickstartsh-example","title":"kickstart.sh Example","text":"Bash<pre><code># Install ArgoCD\n./scripts/kickstart.sh\n\n# After installation, access ArgoCD UI via port-forward:\n# kubectl port-forward svc/argocd-server -n argocd --address 0.0.0.0 8080:443\n</code></pre>"},{"location":"reference/scripts-api/#update-manifestssh","title":"update-manifests.sh","text":"<p>Build Kustomize manifests and generate install files.</p>"},{"location":"reference/scripts-api/#update-manifestssh-synopsis","title":"update-manifests.sh Synopsis","text":"Bash<pre><code>./scripts/update-manifests.sh [ENVIRONMENT]\n</code></pre>"},{"location":"reference/scripts-api/#update-manifestssh-description","title":"update-manifests.sh Description","text":"<p>Builds Kustomize overlays and generates deployment manifests for specified environment.</p>"},{"location":"reference/scripts-api/#update-manifestssh-what-it-does","title":"update-manifests.sh What It Does","text":"<ol> <li>Checks for changes in relevant files (argocd, base, overlays, scripts)</li> <li>Updates environment in kustomization files</li> <li>Builds each overlay (htpc, utils, infra, argocd) with kustomize</li> <li>Generates consolidated install.yaml file</li> <li>Cleans up temporary chart directories</li> </ol>"},{"location":"reference/scripts-api/#update-manifestssh-arguments","title":"update-manifests.sh Arguments","text":"Argument Description Default ENVIRONMENT Target environment (staging/production) staging"},{"location":"reference/scripts-api/#update-manifestssh-output-location","title":"update-manifests.sh Output Location","text":"<p>Generated file is placed at <code>install.yaml</code> in the repository root.</p>"},{"location":"reference/scripts-api/#update-manifestssh-exit-codes","title":"update-manifests.sh Exit Codes","text":"Code Meaning 0 Build successful or no changes 1 Build failed"},{"location":"reference/scripts-api/#update-manifestssh-example","title":"update-manifests.sh Example","text":"Bash<pre><code># Build for staging environment (default)\n./scripts/update-manifests.sh\n\n# Build for production environment\n./scripts/update-manifests.sh production\n</code></pre>"},{"location":"reference/scripts-api/#encrypt-secretssh","title":"encrypt-secrets.sh","text":"<p>Encrypt Kubernetes secrets using SOPS and Age.</p>"},{"location":"reference/scripts-api/#encrypt-secretssh-synopsis","title":"encrypt-secrets.sh Synopsis","text":"Bash<pre><code>SOPS_AGE_KEY_FILE=/path/to/key.txt ./scripts/encrypt-secrets.sh\n</code></pre>"},{"location":"reference/scripts-api/#encrypt-secretssh-description","title":"encrypt-secrets.sh Description","text":"<p>Manages secret encryption using SOPS and Age for secure storage in Git.</p>"},{"location":"reference/scripts-api/#encrypt-secretssh-what-it-does","title":"encrypt-secrets.sh What It Does","text":"<ol> <li>Checks for SOPS_AGE_KEY_FILE environment variable</li> <li>Finds all YAML files with SOPS_SECRET_MARKER comment</li> <li>Encrypts matching files using SOPS with Age</li> <li>Removes the marker and adds YAML separator</li> <li>Reports number of files encrypted</li> </ol>"},{"location":"reference/scripts-api/#encrypt-secretssh-environment-variables","title":"encrypt-secrets.sh Environment Variables","text":"Variable Description Required SOPS_AGE_KEY_FILE Path to Age key file Yes"},{"location":"reference/scripts-api/#encrypt-secretssh-input-format","title":"encrypt-secrets.sh Input Format","text":"<p>Input files should be Kubernetes Secret manifests with the <code># SOPS_SECRET_MARKER</code> comment:</p> YAML<pre><code># SOPS_SECRET_MARKER\napiVersion: v1\nkind: Secret\nmetadata:\n  name: example-secret\nstringData:\n  username: myuser\n  password: mypassword\n</code></pre>"},{"location":"reference/scripts-api/#encrypt-secretssh-output-format","title":"encrypt-secrets.sh Output Format","text":"<p>The script encrypts the <code>data</code> and <code>stringData</code> fields in place using SOPS:</p> YAML<pre><code>---\napiVersion: v1\nkind: Secret\nmetadata:\n    name: example-secret\nstringData:\n    username: ENC[AES256_GCM,...]\n    password: ENC[AES256_GCM,...]\nsops:\n    ...\n</code></pre>"},{"location":"reference/scripts-api/#encrypt-secretssh-exit-codes","title":"encrypt-secrets.sh Exit Codes","text":"Code Meaning 0 Operation successful 1 Operation failed or missing key file"},{"location":"reference/scripts-api/#encrypt-secretssh-example","title":"encrypt-secrets.sh Example","text":"Bash<pre><code># Encrypt all secrets with marker\nexport SOPS_AGE_KEY_FILE=/home/chaitanya/.sops/key.txt\n./scripts/encrypt-secrets.sh\n</code></pre>"},{"location":"reference/scripts-api/#common-script-patterns","title":"Common Script Patterns","text":""},{"location":"reference/scripts-api/#error-handling","title":"Error Handling","text":"<p>All scripts follow consistent error handling:</p> Bash<pre><code>set -euo pipefail  # Exit on error, undefined variables, pipe failures\n</code></pre>"},{"location":"reference/scripts-api/#logging","title":"Logging","text":"<p>Standard logging format:</p> Text Only<pre><code>[INFO] Starting operation\n[WARN] Warning message\n[ERROR] Error occurred\n[SUCCESS] Operation completed\n</code></pre>"},{"location":"reference/scripts-api/#prerequisites-check","title":"Prerequisites Check","text":"<p>Scripts check for required tools:</p> Bash<pre><code>command -v kubectl &gt;/dev/null 2&gt;&amp;1 |  | { |\n  echo \"kubectl is required\"\n  exit 2\n}\n</code></pre>"},{"location":"reference/scripts-api/#integration-with-cicd","title":"Integration with CI/CD","text":""},{"location":"reference/scripts-api/#github-actions-example","title":"GitHub Actions Example","text":"YAML<pre><code>- name: Validate\n  run: ./scripts/validate.sh\n\n- name: Build\n  run: ./scripts/update-manifests.sh\n\n- name: Deploy (dry-run)\n  run: ./scripts/deploy.sh --dry-run\n</code></pre>"},{"location":"reference/scripts-api/#pre-commit-hook","title":"Pre-commit Hook","text":"<p>```.git/hooks/pre-commit</p>"},{"location":"reference/scripts-api/#binbash","title":"!/bin/bash","text":"<p>./scripts/validate.sh Text Only<pre><code>## Troubleshooting Scripts\n\n### Enable Debug Mode\n\n```bash\n# Run with debug output\nbash -x ./scripts/script-name.sh\n</code></pre></p>"},{"location":"reference/scripts-api/#check-script-permissions","title":"Check Script Permissions","text":"Bash<pre><code># Ensure scripts are executable\nchmod +x scripts/*.sh\n</code></pre>"},{"location":"reference/scripts-api/#view-script-source","title":"View Script Source","text":"Bash<pre><code># Read script to understand behavior\ncat scripts/script-name.sh\nless scripts/script-name.sh\n</code></pre>"},{"location":"reference/scripts-api/#related-documentation","title":"Related Documentation","text":"<ul> <li>Getting Started: Scripts Reference</li> <li>Architecture: CI/CD</li> <li>Configuration Management</li> </ul>"},{"location":"reference/scripts-api/#abbreviations","title":"Abbreviations","text":""},{"location":"reference/storage-reference/","title":"Storage Reference","text":"<p>Complete specifications and details for persistent storage in the platform.</p>"},{"location":"reference/storage-reference/#storage-architecture","title":"Storage Architecture","text":"<pre><code>flowchart TD\n    A[Local Path Provisioner] --&gt; B[StorageClass: local-path-infra]\n    A --&gt; C[StorageClass: local-path-htpc]\n    A --&gt; D[StorageClass: local-path-utils]\n\n    B --&gt; E[/opt/cluster/infra]\n    C --&gt; F[/opt/cluster/htpc]\n    D --&gt; G[/opt/cluster/utils]\n\n    E --&gt; H[Infra PVCs&lt;br/&gt;26GB Total]\n    F --&gt; I[HTPC PVCs&lt;br/&gt;500GB Total]\n    G --&gt; J[Utils PVCs&lt;br/&gt;87GB Total]\n\n    H -.contains.- K[Grafana: 5GB&lt;br/&gt;Jaeger: 10GB&lt;br/&gt;Traefik: 1GB&lt;br/&gt;Alloy: 10GB]\n    I -.contains.- L[htpc-pvc: 500GB&lt;br/&gt;Media + App Data]\n    J -.contains.- M[Immich: 35GB&lt;br/&gt;Nextcloud: 32GB&lt;br/&gt;Tandoor: 20GB]</code></pre>"},{"location":"reference/storage-reference/#storage-classes","title":"Storage Classes","text":""},{"location":"reference/storage-reference/#local-path-per-namespace","title":"local-path (per namespace)","text":"<p>Default storage class using local-path-provisioner with namespace-specific configurations.</p>"},{"location":"reference/storage-reference/#specifications","title":"Specifications","text":"Property Value Provisioner rancher.io/local-path Volume Binding Mode WaitForFirstConsumer Reclaim Policy Retain Volume Expansion No (by default) Access Modes ReadWriteOnce Namespace Variants local-path-infra, local-path-utils, local-path-htpc"},{"location":"reference/storage-reference/#configuration","title":"Configuration","text":"<p>StorageClass uses the <code>rancher.io/local-path</code> provisioner with <code>WaitForFirstConsumer</code> binding mode and <code>Retain</code> reclaim policy. Namespace-specific variants are named <code>local-path-infra</code>, <code>local-path-utils</code>, and <code>local-path-htpc</code>.</p> <p>Actual StorageClass Configuration:</p> YAML<pre><code>---\napiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: local-path-infra\n  annotations:\n    storageclass.kubernetes.io/is-default-class: \"false\"\nprovisioner: rancher.io/local-path\nreclaimPolicy: Retain\nvolumeBindingMode: WaitForFirstConsumer\nparameters:\n  nodePath: /opt/cluster/infra\n---\napiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: local-path-htpc\n  annotations:\n    storageclass.kubernetes.io/is-default-class: \"false\"\nprovisioner: rancher.io/local-path\nreclaimPolicy: Retain\nvolumeBindingMode: WaitForFirstConsumer\nparameters:\n  nodePath: /opt/cluster/htpc\n---\napiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: local-path-utils\n  annotations:\n    storageclass.kubernetes.io/is-default-class: \"false\"\nprovisioner: rancher.io/local-path\nreclaimPolicy: Retain\nvolumeBindingMode: WaitForFirstConsumer\nparameters:\n  nodePath: /opt/cluster/utils\n</code></pre>"},{"location":"reference/storage-reference/#persistent-volume-claims","title":"Persistent Volume Claims","text":""},{"location":"reference/storage-reference/#infrastructure-namespace-infra","title":"Infrastructure Namespace (infra)","text":"PVC Name Size Purpose Access Mode Design Considerations grafana-data-pvc 5GB Dashboard storage RWO Fast random access, low latency jaeger-data-pvc 10GB Trace storage RWO High write frequency, sequential access traefik-data-pvc 1GB Traefik persistence RWO Configuration and state alloy-data-pvc 10GB Alloy data storage RWO Observability data collection"},{"location":"reference/storage-reference/#utilities-namespace-utils","title":"Utilities Namespace (utils)","text":"PVC Name Size Purpose Access Mode Design Considerations immich-library-pvc 20GB Photos/Videos RWO Mixed IO patterns, large files immich-valkey-pvc 5GB Cache data RWO In-memory performance, persistence immich-ml-cache-pvc 10GB ML Models RWO Read-optimized, infrequent writes nextcloud-pvc 31GB File storage RWO Mixed workload, many small files nextcloud-redis-pvc 1GB Redis cache RWO Fast access, persistence tandoor-data-pvc 20GB Recipe data RWO Small files, frequent access"},{"location":"reference/storage-reference/#media-namespace-htpc","title":"Media Namespace (htpc)","text":"PVC Name Size Purpose Access Mode Design Considerations htpc-pvc 500GB Media &amp; App Data RWO High throughput, large sequential files <p>Dynamic Provisioning</p> <p>All volumes are dynamically provisioned by local-path-provisioner. No manual PV creation required.</p>"},{"location":"reference/storage-reference/#capacity-planning","title":"Capacity Planning","text":""},{"location":"reference/storage-reference/#total-allocated-storage","title":"Total Allocated Storage","text":"Namespace Total Size Number of PVCs infra 26GB 4 utils 87GB 6 htpc 500GB 1"},{"location":"reference/storage-reference/#grand-total-613gb","title":"Grand Total: 613GB","text":""},{"location":"reference/storage-reference/#growth-projections","title":"Growth Projections","text":""},{"location":"reference/storage-reference/#infra-namespace","title":"Infra Namespace","text":"<ul> <li>Grafana: ~100MB/month (dashboard data)</li> <li>Jaeger: ~2GB/week (traces, retention: 7 days)</li> </ul>"},{"location":"reference/storage-reference/#utils-namespace","title":"Utils Namespace","text":"<ul> <li>Nextcloud: User-dependent, ~1-10GB/month</li> <li>Immich: Photo-dependent, ~5-20GB/month</li> <li>Tandoor: ~10MB/month (recipes)</li> </ul>"},{"location":"reference/storage-reference/#htpc-namespace","title":"HTPC Namespace","text":"<ul> <li>Media library: Highly variable, 10-100GB/month depending on usage</li> </ul>"},{"location":"reference/storage-reference/#recommended-minimums","title":"Recommended Minimums","text":"<p>For optimal performance:</p> <ul> <li>System Disk: 100GB minimum</li> <li>Media Storage: 500GB+ recommended</li> <li>SSD: Recommended for database workloads</li> <li>HDD: Acceptable for media storage</li> </ul>"},{"location":"reference/storage-reference/#storage-performance","title":"Storage Performance","text":""},{"location":"reference/storage-reference/#iops-requirements","title":"IOPS Requirements","text":"Workload Type IOPS Range Recommended Storage Database (PostgreSQL) 1000-5000 SSD Cache (Redis/Valkey) 5000-10000 SSD Media Streaming 50-200 HDD/SSD Application Logs 500-1000 SSD"},{"location":"reference/storage-reference/#throughput-requirements","title":"Throughput Requirements","text":"Workload Type Throughput Recommended 4K Media Streaming 50-100 MB/s HDD/SSD Database Backups 100-500 MB/s SSD Log Aggregation 10-50 MB/s SSD"},{"location":"reference/storage-reference/#volume-snapshot-configuration","title":"Volume Snapshot Configuration","text":"<p>If supported by the CSI driver, volume snapshots can be created using VolumeSnapshotClass and VolumeSnapshot resources. The snapshot references the source PVC and uses the configured snapshot class with appropriate deletion policies.</p>"},{"location":"reference/storage-reference/#backup-strategy","title":"Backup Strategy","text":""},{"location":"reference/storage-reference/#recommended-backup-schedule","title":"Recommended Backup Schedule","text":"Data Type Frequency Retention Critical (Grafana) Daily 30 days User Data (Nextcloud, Immich) Daily 90 days Media Metadata Weekly 30 days Application Config On change Forever (Git)"},{"location":"reference/storage-reference/#backup-methods","title":"Backup Methods","text":""},{"location":"reference/storage-reference/#manual-backup","title":"Manual Backup","text":"Bash<pre><code># Backup PVC data\nkubectl exec -n utils nextcloud-pod -- tar czf - /data &gt; nextcloud-backup.tar.gz\n\n# Restore\nkubectl exec -n utils nextcloud-pod -- tar xzf - -C / &lt; nextcloud-backup.tar.gz\n</code></pre>"},{"location":"reference/storage-reference/#automated-backup-velero","title":"Automated Backup (Velero)","text":"Bash<pre><code># Install Velero\nvelero install --provider aws --plugins velero/velero-plugin-for-aws:latest\n\n# Create backup\nvelero backup create &lt;backup-name&gt; --include-namespaces utils\n\n# Restore\nvelero restore create --from-backup &lt;backup-name&gt;\n</code></pre>"},{"location":"reference/storage-reference/#storage-monitoring","title":"Storage Monitoring","text":"<pre><code>flowchart LR\n    A[kubelet] --&gt; B[Volume Metrics]\n    B --&gt; C[Prometheus]\n    C --&gt; D[Grafana Dashboard]\n\n    B -.exposes.- E[capacity_bytes&lt;br/&gt;used_bytes&lt;br/&gt;available_bytes&lt;br/&gt;inodes_used]\n\n    D --&gt; F[Alerts]\n    F -.triggers.- G[Low Disk Space&lt;br/&gt;High IOPS&lt;br/&gt;Slow Performance]</code></pre>"},{"location":"reference/storage-reference/#key-metrics","title":"Key Metrics","text":""},{"location":"reference/storage-reference/#capacity-metrics","title":"Capacity Metrics","text":"<ul> <li><code>kubelet_volume_stats_capacity_bytes</code></li> <li><code>kubelet_volume_stats_used_bytes</code></li> <li><code>kubelet_volume_stats_available_bytes</code></li> <li><code>kubelet_volume_stats_inodes_used</code></li> </ul>"},{"location":"reference/storage-reference/#performance-metrics","title":"Performance Metrics","text":"<ul> <li>Disk I/O operations per second</li> <li>Read/write throughput</li> <li>Latency</li> <li>Queue depth</li> </ul>"},{"location":"reference/storage-reference/#grafana-queries","title":"Grafana Queries","text":""},{"location":"reference/storage-reference/#storage-utilization","title":"Storage Utilization","text":"PromQL<pre><code>(kubelet_volume_stats_used_bytes / kubelet_volume_stats_capacity_bytes) * 100\n</code></pre>"},{"location":"reference/storage-reference/#available-space","title":"Available Space","text":"PromQL<pre><code>kubelet_volume_stats_available_bytes / 1024 / 1024 / 1024\n</code></pre>"},{"location":"reference/storage-reference/#troubleshooting","title":"Troubleshooting","text":""},{"location":"reference/storage-reference/#common-issues","title":"Common Issues","text":""},{"location":"reference/storage-reference/#pvc-stuck-in-pending","title":"PVC Stuck in Pending","text":"Bash<pre><code># Check events\nkubectl describe pvc &lt;pvc-name&gt; -n &lt;namespace&gt;\n\n# Check storage class\nkubectl get storageclass\n\n# Check provisioner logs\nkubectl logs -n kube-system -l app=local-path-provisioner\n</code></pre>"},{"location":"reference/storage-reference/#out-of-disk-space","title":"Out of Disk Space","text":"Bash<pre><code># Check disk usage\ndf -h /opt/cluster\n\n# Find large directories by namespace\ndu -sh /opt/cluster/*\n\n# Check specific namespace storage\ndu -sh /opt/cluster/htpc\ndu -sh /opt/cluster/infra\ndu -sh /opt/cluster/utils\n\n# Clean up old data\nkubectl delete pvc &lt;unused-pvc&gt; -n &lt;namespace&gt;\n</code></pre>"},{"location":"reference/storage-reference/#performance-issues","title":"Performance Issues","text":"Bash<pre><code># Check I/O stats\niostat -x 1\n\n# Check for high I/O wait\ntop\nvmstat 1\n\n# Identify heavy I/O processes\niotop\n</code></pre>"},{"location":"reference/storage-reference/#related-documentation","title":"Related Documentation","text":"<ul> <li>Architecture: Storage</li> <li>Configuration</li> <li>Services</li> </ul>"},{"location":"reference/storage-reference/#abbreviations","title":"Abbreviations","text":""},{"location":"services/","title":"Services","text":"<p>The platform hosts a comprehensive collection of services across three main categories: core infrastructure, personal cloud applications, and media management.</p>"},{"location":"services/#service-categories","title":"Service Categories","text":"<ul> <li> <p> Core Platform</p> <p>Essential infrastructure services</p> <p>k3s, ArgoCD, Traefik, cert-manager, MetalLB, Local Path Provisioner</p> </li> <li> <p> Observability Stack</p> <p>Monitoring, logging, and tracing</p> <p>Prometheus, Grafana, Loki, Jaeger, Alloy</p> </li> <li> <p> Personal Cloud</p> <p>File sync, photos, recipes, dashboard</p> <p>Nextcloud, Homepage, Immich, Tandoor</p> </li> <li> <p> Media Services</p> <p>Complete media automation stack</p> <p>Jellyfin, Sonarr, Radarr, Prowlarr, more</p> </li> <li> <p> Hardware Setup</p> <p>Dedicated playback hardware</p> <p>Homatics Box, CoreElec, Kodi configuration</p> </li> <li> <p> Data Layer</p> <p>Databases and caching</p> <p>CloudNativePG, Valkey, Redis</p> </li> </ul>"},{"location":"services/#service-overview","title":"Service Overview","text":"<p>All services are deployed as Kubernetes workloads with:</p> <ul> <li>Declarative configuration: YAML manifests</li> <li>Persistent storage: Where needed</li> <li>Ingress routing: HTTPS access via Traefik</li> <li>Monitoring: Prometheus metrics</li> <li>Logging: Centralized via Loki</li> <li>High availability: Configurable replicas</li> </ul>"},{"location":"services/#service-access","title":"Service Access","text":"<p>Services are accessible via:</p> <ul> <li>Internal: ClusterIP services within Kubernetes</li> <li>External: LoadBalancer or IngressRoute via Traefik</li> <li>HTTPS: TLS certificates from cert-manager</li> <li>Dashboard: Homepage service dashboard</li> </ul>"},{"location":"services/#service-architecture","title":"Service Architecture","text":"<pre><code>graph TD\n    A[User] --&gt; B[Traefik]\n    B --&gt; C[Core Platform]\n    B --&gt; D[Personal Cloud]\n    B --&gt; E[Media Services]\n\n    C --&gt; F[Infrastructure]\n    D --&gt; G[Applications]\n    E --&gt; H[Media Stack]\n\n    F --&gt; I[Storage]\n    G --&gt; I\n    H --&gt; I\n\n    F --&gt; J[Observability]\n    G --&gt; J\n    H --&gt; J</code></pre>"},{"location":"services/#next-steps","title":"Next Steps","text":"<p>Explore detailed documentation for each service category:</p> <ul> <li>Core Platform - Infrastructure services</li> <li>Observability Stack - Monitoring services</li> <li>Personal Cloud - Cloud applications</li> <li>Media Services - Media automation</li> <li>Hardware Setup - Client hardware</li> <li>Data Layer - Databases and caching</li> </ul>"},{"location":"services/#abbreviations","title":"Abbreviations","text":""},{"location":"services/core-platform/","title":"Core Platform Services","text":"<p>The core platform consists of essential infrastructure components that power the entire homelab.</p> <pre><code>graph TB\n    subgraph \"Foundation\"\n        K3S[k3s&lt;br/&gt;Kubernetes]\n    end\n\n    subgraph \"Deployment\"\n        ARGO[ArgoCD&lt;br/&gt;GitOps]\n    end\n\n    subgraph \"Networking\"\n        TRAEFIK[Traefik&lt;br/&gt;Ingress]\n        CERT[cert-manager&lt;br/&gt;TLS]\n        METAL[MetalLB&lt;br/&gt;Load Balancer]\n    end\n\n    subgraph \"Storage\"\n        LPP[Local Path&lt;br/&gt;Provisioner]\n    end\n\n    K3S --&gt; ARGO\n    K3S --&gt; TRAEFIK\n    K3S --&gt; CERT\n    K3S --&gt; METAL\n    K3S --&gt; LPP\n\n    ARGO -.manages.-&gt; TRAEFIK\n    ARGO -.manages.-&gt; CERT\n    ARGO -.manages.-&gt; METAL\n    ARGO -.manages.-&gt; LPP\n\n    CERT -.provides certs.-&gt; TRAEFIK\n    METAL -.provides IPs.-&gt; TRAEFIK\n\n    style K3S fill:#326ce5\n    style ARGO fill:#e8733b\n    style TRAEFIK fill:#24a1c1\n    style CERT fill:#ff9900\n    style METAL fill:#2196f3\n    style LPP fill:#4caf50</code></pre>"},{"location":"services/core-platform/#service-overview","title":"Service Overview","text":"Logo Service Description Version k3s Lightweight Kubernetes Latest ArgoCD GitOps Deployment Latest Traefik Ingress Controller Latest cert-manager Certificate Management Latest MetalLB Load Balancer Latest Local Path Provisioner Storage Provisioner Latest"},{"location":"services/core-platform/#k3s","title":"k3s","text":"<p>k3s is a certified Kubernetes distribution built for IoT and Edge computing.</p>"},{"location":"services/core-platform/#key-features","title":"Key Features","text":"<ul> <li>Lightweight (&lt; 100MB binary)</li> <li>Quick installation</li> <li>Built-in components</li> <li>Production-ready</li> </ul>"},{"location":"services/core-platform/#configuration","title":"Configuration","text":"Bash<pre><code># Install k3s\ncurl -sfL https://get.k3s.io | sh -\n\n# Check status\nsudo systemctl status k3s\n</code></pre> <p>Learn more about Kubernetes Infrastructure \u2192</p>"},{"location":"services/core-platform/#argocd","title":"ArgoCD","text":"<p>ArgoCD is a declarative, GitOps continuous delivery tool for Kubernetes.</p>"},{"location":"services/core-platform/#argocd-key-features","title":"ArgoCD Key Features","text":"<ul> <li>Git as source of truth</li> <li>Automated deployment</li> <li>Visual UI</li> <li>Drift detection</li> </ul>"},{"location":"services/core-platform/#access","title":"Access","text":"Bash<pre><code># Port forward to ArgoCD server\nkubectl port-forward svc/argocd-server -n argocd 8080:443\n</code></pre> <p>Then visit <code>https://localhost:8080</code></p> <p>Authentication</p> <p>ArgoCD authentication is configured through the ArgoCD ConfigMap. Default credentials may be set during initial deployment or configured via SSO.</p> <p>Learn more about CI/CD \u2192</p>"},{"location":"services/core-platform/#traefik","title":"Traefik","text":"<p>Traefik is a modern reverse proxy and load balancer.</p>"},{"location":"services/core-platform/#traefik-key-features","title":"Traefik Key Features","text":"<ul> <li>Automatic service discovery</li> <li>Let's Encrypt integration</li> <li>Middleware support</li> <li>Dashboard and metrics</li> </ul>"},{"location":"services/core-platform/#traefik-configuration","title":"Traefik Configuration","text":"<p>IngressRoute CRDs define routing rules with host matching, service references, and TLS certificates.</p> <p>Learn more about Networking \u2192</p>"},{"location":"services/core-platform/#cert-manager","title":"cert-manager","text":"<p>cert-manager automates the management and issuance of TLS certificates.</p>"},{"location":"services/core-platform/#cert-manager-key-features","title":"cert-manager Key Features","text":"<ul> <li>Let's Encrypt integration</li> <li>Automatic renewal</li> <li>DNS-01 challenges</li> <li>Wildcard certificates</li> </ul>"},{"location":"services/core-platform/#certificate-request","title":"Certificate Request","text":"<p>Certificate resources specify:</p> <ul> <li>Secret name for storing the certificate</li> <li>ClusterIssuer reference (e.g., letsencrypt-production)</li> <li>DNS names including wildcards (e.g., *.example.com)</li> <li>Automatic renewal before expiration</li> </ul> <p>Learn more about Security \u2192</p>"},{"location":"services/core-platform/#metallb","title":"MetalLB","text":"<p>MetalLB is a load-balancer implementation for bare metal Kubernetes clusters.</p>"},{"location":"services/core-platform/#metallb-key-features","title":"MetalLB Key Features","text":"<ul> <li>Layer 2 mode (ARP)</li> <li>BGP mode available</li> <li>IP address pools</li> <li>Automatic assignment</li> </ul>"},{"location":"services/core-platform/#metallb-configuration","title":"MetalLB Configuration","text":"<p>IPAddressPool defines the range of IPs MetalLB can assign. L2Advertisement announces these IPs on the local network using ARP.</p> View MetalLB Configuration YAML<pre><code>---\napiVersion: metallb.io/v1beta1\nkind: IPAddressPool\nmetadata:\n  name: first-pool\nspec:\n  addresses:\n    - 192.168.1.240/28\n---\napiVersion: metallb.io/v1beta1\nkind: L2Advertisement\nmetadata:\n  name: empty\n</code></pre> <p>This configuration:</p> <ul> <li>Defines IP pool: <code>192.168.1.240/28</code> (16 addresses: .240-.255)</li> <li>Uses Layer 2 mode (ARP) for IP advertisement</li> <li>Automatically assigns IPs to LoadBalancer services</li> </ul> <p>Learn more about Networking \u2192</p>"},{"location":"services/core-platform/#local-path-provisioner","title":"Local Path Provisioner","text":"<p>Local Path Provisioner provides persistent local storage for Kubernetes workloads.</p>"},{"location":"services/core-platform/#storage-features","title":"Storage Features","text":"<ul> <li>Dynamic volume provisioning</li> <li>Local host path storage</li> <li>Multiple storage classes</li> <li>Automatic directory creation</li> </ul>"},{"location":"services/core-platform/#storage-classes","title":"Storage Classes","text":"<p>The platform uses separate storage classes for different namespaces:</p> <ul> <li>local-path-infra: Infrastructure services (<code>/opt/cluster/infra</code>)</li> <li>local-path-utils: Utility services (<code>/opt/cluster/utils</code>)</li> <li>local-path-htpc: Media services (<code>/opt/cluster/htpc</code>)</li> </ul> <p>Each uses the <code>rancher.io/local-path</code> provisioner with <code>WaitForFirstConsumer</code> volume binding mode and <code>Retain</code> reclaim policy.</p> View Storage Classes Configuration YAML<pre><code>---\napiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: local-path-infra\n  annotations:\n    storageclass.kubernetes.io/is-default-class: \"false\"\nprovisioner: rancher.io/local-path\nreclaimPolicy: Retain\nvolumeBindingMode: WaitForFirstConsumer\nparameters:\n  nodePath: /opt/cluster/infra\n---\napiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: local-path-htpc\n  annotations:\n    storageclass.kubernetes.io/is-default-class: \"false\"\nprovisioner: rancher.io/local-path\nreclaimPolicy: Retain\nvolumeBindingMode: WaitForFirstConsumer\nparameters:\n  nodePath: /opt/cluster/htpc\n---\napiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: local-path-utils\n  annotations:\n    storageclass.kubernetes.io/is-default-class: \"false\"\nprovisioner: rancher.io/local-path\nreclaimPolicy: Retain\nvolumeBindingMode: WaitForFirstConsumer\nparameters:\n  nodePath: /opt/cluster/utils\n</code></pre> <p>Key Configuration Points:</p> <ul> <li><code>volumeBindingMode: WaitForFirstConsumer</code> - Delays volume binding until pod is scheduled</li> <li><code>reclaimPolicy: Retain</code> - Preserves data when PVC is deleted</li> <li><code>nodePath</code> - Namespace-specific directory on the host node</li> </ul> <p>Learn more about Storage \u2192</p>"},{"location":"services/core-platform/#related-documentation","title":"Related Documentation","text":"<ul> <li>Architecture - System architecture</li> <li>Getting Started - Deployment guide</li> <li>Configuration - Configuration management</li> </ul>"},{"location":"services/core-platform/#abbreviations","title":"Abbreviations","text":""},{"location":"services/data-layer/","title":"Data Layer Services","text":"<p>Database and caching services that power the platform's applications.</p>"},{"location":"services/data-layer/#service-overview","title":"Service Overview","text":"Logo Service Description Version CloudNativePG PostgreSQL Operator Latest Valkey Caching Layer (Immich) (via Immich chart) Redis Caching Layer (Nextcloud) Latest"},{"location":"services/data-layer/#cloudnativepg","title":"CloudNativePG","text":"<p>CloudNativePG is a Kubernetes operator for PostgreSQL.</p>"},{"location":"services/data-layer/#features","title":"Features","text":"<ul> <li>High Availability: Automated failover</li> <li>Backup/Restore: Point-in-time recovery</li> <li>Monitoring: Prometheus metrics</li> <li>Declarative: Kubernetes-native configuration</li> <li>Streaming Replication: Built-in replication</li> </ul>"},{"location":"services/data-layer/#configuration","title":"Configuration","text":"<p>CNPG Cluster resources define instance count, PostgreSQL parameters, bootstrap configuration, storage requirements, and monitoring settings.</p> View CNPG Cluster configuration <p>See <code>base/utils/cnpg/</code> directory for cluster configurations.</p>"},{"location":"services/data-layer/#usage","title":"Usage","text":"<p>Applications connect using standard PostgreSQL connection strings pointing to the cluster read-write service endpoint.</p>"},{"location":"services/data-layer/#monitoring","title":"Monitoring","text":"<ul> <li>Prometheus metrics exported</li> <li>Dashboard in Grafana</li> <li>Backup status tracking</li> <li>Replication lag monitoring</li> </ul>"},{"location":"services/data-layer/#valkey","title":"Valkey","text":"<p>Valkey is a high-performance caching layer (Redis fork).</p>"},{"location":"services/data-layer/#valkey-usage","title":"Valkey Usage","text":"<p>Primary caching layer for Immich:</p> <ul> <li>Image thumbnails</li> <li>ML model cache</li> <li>Session storage</li> <li>Query results</li> </ul>"},{"location":"services/data-layer/#valkey-configuration","title":"Valkey Configuration","text":"<p>Valkey pods run the Valkey container with persistent storage mounted for data persistence.</p>"},{"location":"services/data-layer/#valkey-storage","title":"Valkey Storage","text":"<ul> <li>PVC: 5GB</li> <li>Persistence enabled</li> <li>Regular snapshots</li> </ul>"},{"location":"services/data-layer/#redis","title":"Redis","text":"<p>Redis is an in-memory data structure store.</p>"},{"location":"services/data-layer/#redis-usage","title":"Redis Usage","text":"<p>Caching specifically for Nextcloud:</p> <ul> <li>File locking</li> <li>Session storage</li> <li>Local cache</li> <li>Distributed cache</li> </ul>"},{"location":"services/data-layer/#redis-configuration","title":"Redis Configuration","text":"<p>Redis runs as a standard Kubernetes Deployment with:</p> <ul> <li>Single replica (non-HA setup)</li> <li>Redis 8.4.0 image</li> <li>Port 6379 exposed for connections</li> <li>Persistent volume mounted at <code>/data</code></li> </ul>"},{"location":"services/data-layer/#redis-storage","title":"Redis Storage","text":"<ul> <li>PVC: 1GB (Nextcloud)</li> <li>Persistence enabled</li> <li>Data stored in /data mount</li> </ul>"},{"location":"services/data-layer/#database-best-practices","title":"Database Best Practices","text":""},{"location":"services/data-layer/#performance","title":"Performance","text":"<ul> <li>Connection pooling: Use PgBouncer</li> <li>Indexing: Create appropriate indexes</li> <li>Vacuuming: Regular maintenance</li> <li>Monitoring: Track query performance</li> </ul>"},{"location":"services/data-layer/#backup","title":"Backup","text":"<ul> <li>Automated backups: Daily backups</li> <li>Point-in-time recovery: WAL archiving</li> <li>Backup testing: Regular restore tests</li> <li>Off-site storage: External backup location</li> </ul>"},{"location":"services/data-layer/#security","title":"Security","text":"<ul> <li>Strong passwords: Complex credentials</li> <li>Network policies: Restrict access</li> <li>Encryption: TLS connections</li> <li>Least privilege: Minimal permissions</li> </ul>"},{"location":"services/data-layer/#database-monitoring","title":"Database Monitoring","text":"<ul> <li>Connection counts: Monitor active connections</li> <li>Query performance: Slow query log</li> <li>Resource usage: CPU, memory, disk I/O</li> <li>Replication lag: For HA setups</li> </ul>"},{"location":"services/data-layer/#troubleshooting","title":"Troubleshooting","text":""},{"location":"services/data-layer/#postgresql-issues","title":"PostgreSQL Issues","text":"Bash<pre><code># Check cluster status\nkubectl get cluster -n utils\n\n# View pod logs\nkubectl logs -n utils postgres-cluster-1\n\n# Check replication status\nkubectl exec -n utils postgres-cluster-1 -- psql -U postgres -c \"SELECT * FROM pg_stat_replication;\"\n\n# Check database size\nkubectl exec -n utils postgres-cluster-1 -- psql -U postgres -c \"SELECT pg_database_size('dbname');\"\n</code></pre>"},{"location":"services/data-layer/#redisvalkey-issues","title":"Redis/Valkey Issues","text":"Bash<pre><code># Check pod status\nkubectl get pods -n utils -l app=redis\n\n# View logs\nkubectl logs -n utils redis-0\n\n# Test connection\nkubectl exec -n utils redis-0 -- redis-cli ping\n\n# Check memory usage\nkubectl exec -n utils redis-0 -- redis-cli info memory\n</code></pre>"},{"location":"services/data-layer/#connection-issues","title":"Connection Issues","text":"Bash<pre><code># Test database connection\nkubectl run -it --rm psql --image=postgres:alpine --restart=Never -- \\\n  psql -h postgres-cluster-rw -U app -d app\n\n# Test Redis connection\nkubectl run -it --rm redis-cli --image=redis:alpine --restart=Never -- \\\n  redis-cli -h redis PING\n</code></pre>"},{"location":"services/data-layer/#related-documentation","title":"Related Documentation","text":"<ul> <li>Architecture: Storage</li> <li>Services: Personal Cloud</li> <li>Configuration</li> </ul>"},{"location":"services/data-layer/#abbreviations","title":"Abbreviations","text":""},{"location":"services/hardware-setup/","title":"Hardware Setup for Bitstreaming","text":"<p>Advanced hardware configuration for lossless audio/video passthrough and optimal media playback.</p>"},{"location":"services/hardware-setup/#overview","title":"Overview","text":"<p>For optimal quality with high-end audio/video formats, a dedicated client setup eliminates transcoding issues common with TV-integrated clients.</p> <p>Hardware Optimization</p> <p>This setup prioritizes direct play over compatibility, ensuring lossless transmission of advanced formats like Dolby Vision 7 and Dolby Atmos through the entire chain.</p>"},{"location":"services/hardware-setup/#hardware-components","title":"Hardware Components","text":""},{"location":"services/hardware-setup/#client-device","title":"Client Device","text":"<p>Homatics Box R 4K Plus running CoreElec</p>"},{"location":"services/hardware-setup/#capabilities","title":"Capabilities","text":"<ul> <li>Hardware-accelerated decoding</li> <li>HDMI passthrough</li> <li>Dolby Vision 7.6 (with FEL)</li> <li>HDR10/HDR10+</li> <li>Dolby Atmos</li> <li>DTS:X</li> <li>Lossless audio codecs</li> </ul> <p>Reference: Device Codec Compatibility</p>"},{"location":"services/hardware-setup/#advantages-over-webos","title":"Advantages over WebOS","text":"<ul> <li>Avoids transcoding limitations</li> <li>No AAC audio conversion</li> <li>No HDR fallbacks from Dolby Vision 7</li> <li>Direct bitstreaming support</li> </ul>"},{"location":"services/hardware-setup/#connection-chain","title":"Connection Chain","text":"Text Only<pre><code>Router \u2192 LAN \u2192 Homatics Box \u2192 HDMI \u2192 Samsung HW-Q995D Soundbar \u2192 HDMI eARC \u2192 LG G4 TV\n</code></pre>"},{"location":"services/hardware-setup/#compatibility","title":"Compatibility","text":"<ul> <li>Full Dolby Vision 7.6 (with FEL) support</li> <li>Dolby TrueHD Atmos lossless audio passthrough</li> <li>Reference: Test Results</li> </ul>"},{"location":"services/hardware-setup/#key-advantages","title":"Key Advantages","text":"<ul> <li>Eliminates audio transcoding to AAC</li> <li>Prevents video fallbacks to standard HDR</li> <li>Reduces latency and server load</li> <li>Future-proof for 8K/120Hz with HDMI 2.1</li> </ul>"},{"location":"services/hardware-setup/#installation-instructions","title":"Installation Instructions","text":""},{"location":"services/hardware-setup/#initial-installation","title":"Initial Installation","text":""},{"location":"services/hardware-setup/#step-1-prepare-usb-drive","title":"Step 1: Prepare USB Drive","text":"<ol> <li>Download CoreELEC 21.3</li> <li>Flash to USB drive using Balena Etcher</li> </ol>"},{"location":"services/hardware-setup/#step-2-configure-device-tree","title":"Step 2: Configure Device Tree","text":"<ol> <li>Browse to Device Trees folder on USB drive</li> <li>Copy <code>sc2_s905x4_sei_smb_280.dtb</code> to root folder (same level as <code>kernel.img</code>)</li> <li>Rename to <code>dtb.img</code> (ignore warnings)</li> </ol>"},{"location":"services/hardware-setup/#step-3-add-dolby-vision-support","title":"Step 3: Add Dolby Vision Support","text":"<ol> <li>Download dovi.ko</li> <li>Copy to same location as <code>dtb.img</code></li> </ol>"},{"location":"services/hardware-setup/#step-4-boot-coreelec","title":"Step 4: Boot CoreELEC","text":"<ol> <li>Insert USB drive into Homatics Box</li> <li>Insert power adapter</li> <li>Device should boot to CoreELEC</li> </ol> <p>Boot Troubleshooting</p> <p>If device doesn't boot from USB: - Restart from Android TV GUI until USB is recognized - Try reset button technique from official documentation - Reboot from Android recovery menu</p>"},{"location":"services/hardware-setup/#step-5-complete-setup","title":"Step 5: Complete Setup","text":"<ol> <li>Follow initial setup wizard</li> <li>Enable SSH (recommended for debugging)</li> </ol>"},{"location":"services/hardware-setup/#kodi-configuration","title":"Kodi Configuration","text":""},{"location":"services/hardware-setup/#cache-settings","title":"Cache Settings","text":""},{"location":"services/hardware-setup/#settings--services--caching","title":"Settings \u2192 Services \u2192 Caching","text":"<p>Enable expert settings and configure:</p> Setting Value Purpose Buffer mode All network filesystems Optimizes network streaming Memory Size 512MB Sufficient buffer for 4K Remuxes Read Factor 10.00x Reduces buffering during playback"},{"location":"services/hardware-setup/#audio-settings","title":"Audio Settings","text":""},{"location":"services/hardware-setup/#settings--services--audio","title":"Settings \u2192 Services \u2192 Audio","text":"<p>Configure for lossless ATMOS passthrough:</p> Setting Value Audio Output Device ALSA:AML-AUGESOUND, HDMI Multi Ch PCM Number of Channels 7.1 Output Configuration Best Match Keep Audio Device Alive Always Enable Audio Passthrough Enabled Passthrough Output Device ALSA:AML-AUGESOUND, HDMI Enable all audio codecs AC3, E-AC3, DTS, TrueHD, DTS-HD <p>Audio Device Persistence</p> <p>\"Keep Audio Device Alive\" prevents audio device reinitialization between tracks.</p>"},{"location":"services/hardware-setup/#display-settings","title":"Display Settings","text":""},{"location":"services/hardware-setup/#settings--services--display","title":"Settings \u2192 Services \u2192 Display","text":"<p>Enable expert settings and configure:</p> Setting Value Purpose Disable Noise Reduction Enabled Preserves original video quality Dolby Vision LED Mode TV-Led Optimizes DV tone mapping"},{"location":"services/hardware-setup/#debug-logging-optional","title":"Debug Logging (Optional)","text":""},{"location":"services/hardware-setup/#settings--services--logging","title":"Settings \u2192 Services \u2192 Logging","text":"Setting Value Note Enable Debug logging For troubleshooting only Disable after resolving issues (consumes CPU)"},{"location":"services/hardware-setup/#system-configuration","title":"System Configuration","text":""},{"location":"services/hardware-setup/#network-settings","title":"Network Settings","text":""},{"location":"services/hardware-setup/#settings--coreelec--network","title":"Settings \u2192 CoreELEC \u2192 Network","text":"<ul> <li>Turn off wireless connection</li> <li>Use wired Ethernet for stable streaming of high-bitrate content</li> </ul>"},{"location":"services/hardware-setup/#update-settings","title":"Update Settings","text":""},{"location":"services/hardware-setup/#settings--coreelec--updates","title":"Settings \u2192 CoreELEC \u2192 Updates","text":"<ul> <li>Turn off all auto-update settings</li> <li>Prevents automatic updates that may cause instability</li> </ul>"},{"location":"services/hardware-setup/#jellyfin-integration","title":"Jellyfin Integration","text":""},{"location":"services/hardware-setup/#install-jellyfin-add-on","title":"Install Jellyfin Add-on","text":"<ol> <li>Install Jellyfin for Kodi</li> <li>Navigate GUI to add all libraries</li> <li>Shutdown device</li> <li>Connect to Dolby Vision display or soundbar with passthrough</li> <li>Ensure wired LAN connection</li> </ol>"},{"location":"services/hardware-setup/#playback-verification","title":"Playback Verification","text":""},{"location":"services/hardware-setup/#testing-dolby-vision","title":"Testing Dolby Vision","text":""},{"location":"services/hardware-setup/#expected-behavior","title":"Expected Behavior","text":"<ul> <li>Dolby Vision 7.6 with FEL content should play correctly</li> <li>May experience a few frame drops initially while TV switches modes</li> </ul>"},{"location":"services/hardware-setup/#workaround-for-initial-drops","title":"Workaround for Initial Drops","text":"<ol> <li>Rewind movie to beginning</li> <li>Playback should be perfect after display has switched to desired mode</li> </ol>"},{"location":"services/hardware-setup/#verification-checklist","title":"Verification Checklist","text":"<ul> <li> Dolby Vision badge appears during playback</li> <li> Audio outputs as Dolby Atmos or DTS:X (not AAC)</li> <li> No transcoding on server</li> <li> Smooth playback without buffering</li> <li> HDR/DV metadata displays correctly</li> </ul>"},{"location":"services/hardware-setup/#troubleshooting","title":"Troubleshooting","text":""},{"location":"services/hardware-setup/#no-audio","title":"No Audio","text":"<ul> <li>Check passthrough settings</li> <li>Verify soundbar HDMI connection</li> <li>Ensure eARC is enabled</li> <li>Check audio codec support</li> </ul>"},{"location":"services/hardware-setup/#video-not-playing","title":"Video Not Playing","text":"<ul> <li>Verify video codec support</li> <li>Check network bandwidth</li> <li>Review Jellyfin server logs</li> <li>Test with different content</li> </ul>"},{"location":"services/hardware-setup/#frame-drops","title":"Frame Drops","text":"<ul> <li>Check network stability</li> <li>Increase buffer size</li> <li>Verify media source quality</li> <li>Monitor CPU usage</li> </ul>"},{"location":"services/hardware-setup/#dolby-vision-issues","title":"Dolby Vision Issues","text":"<ul> <li>Verify dovi.ko is loaded</li> <li>Check TV DV support</li> <li>Review display settings</li> <li>Test with known DV content</li> </ul>"},{"location":"services/hardware-setup/#performance-optimization","title":"Performance Optimization","text":""},{"location":"services/hardware-setup/#network","title":"Network","text":"<ul> <li>Use Gigabit Ethernet</li> <li>Quality Cat6 or better cables</li> <li>Minimize network hops</li> <li>QoS for streaming traffic</li> </ul>"},{"location":"services/hardware-setup/#storage","title":"Storage","text":"<ul> <li>Fast storage on Jellyfin server</li> <li>Sufficient bandwidth for 4K remux</li> <li>Regular maintenance</li> </ul>"},{"location":"services/hardware-setup/#playback","title":"Playback","text":"<ul> <li>Close background apps</li> <li>Keep CoreELEC updated</li> <li>Monitor device temperature</li> <li>Clean cache periodically</li> </ul>"},{"location":"services/hardware-setup/#related-documentation","title":"Related Documentation","text":"<ul> <li>Media Services - Server-side configuration</li> <li>Architecture - System architecture</li> </ul>"},{"location":"services/hardware-setup/#abbreviations","title":"Abbreviations","text":""},{"location":"services/media-services/","title":"Media Services","text":"<p>Complete media automation stack for content discovery, acquisition, and streaming.</p>"},{"location":"services/media-services/#service-overview","title":"Service Overview","text":"Logo Service Description Version Jellyfin Media Streaming Latest Sonarr TV Management Latest Radarr Movie Management Latest Prowlarr Index Management Latest Transmission BitTorrent Client Latest FlareSolverr CAPTCHA Solver Latest Scraparr Metadata Scraper Latest"},{"location":"services/media-services/#media-stack-architecture","title":"Media Stack Architecture","text":"<p>The media management system is built on four key pillars:</p>"},{"location":"services/media-services/#1-content-discovery-","title":"1. Content Discovery \ud83d\udd0d","text":"<p>Automated series and movie tracking with quality management.</p>"},{"location":"services/media-services/#components","title":"Components","text":"<ul> <li>Sonarr: TV series management</li> <li>Radarr: Movie management</li> <li>Prowlarr: Indexer aggregation</li> </ul>"},{"location":"services/media-services/#process","title":"Process","text":"<pre><code>graph TD\n  A[Series/Movie Added] --&gt; B[Quality Profile Check]\n  B --&gt; C[Search Indexers]\n  C --&gt; D[Filter Results]\n  D --&gt; E[Queue for Download]</code></pre>"},{"location":"services/media-services/#2-download-orchestration-","title":"2. Download Orchestration \ud83d\udce5","text":"<p>Automated download management with verification.</p>"},{"location":"services/media-services/#download-components","title":"Download Components","text":"<ul> <li>Transmission: BitTorrent client</li> <li>FlareSolverr: CAPTCHA bypass</li> <li>Prowlarr: Indexer integration</li> </ul>"},{"location":"services/media-services/#download-process","title":"Download Process","text":"<pre><code>graph TD\n  A[Download Request] --&gt; B[Transmission]\n  B --&gt; C[Progress Monitoring]\n  C --&gt; D[Hash Verification]\n  D --&gt; E[Completion Handling]</code></pre>"},{"location":"services/media-services/#3-post-processing-pipeline-","title":"3. Post-Processing Pipeline \ud83d\udd04","text":"<p>Automated file organization and metadata management.</p>"},{"location":"services/media-services/#post-processing-components","title":"Post-Processing Components","text":"<ul> <li>Sonarr/Radarr: File organization</li> <li>Scraparr: Metadata scraping</li> </ul>"},{"location":"services/media-services/#post-processing-flow","title":"Post-Processing Flow","text":"<pre><code>graph TD\n  A[Download Complete] --&gt; B[Quality Check]\n  B --&gt; C[Rename/Organize]\n  C --&gt; D[Fetch Subtitles]\n  D --&gt; E[Update Library]</code></pre>"},{"location":"services/media-services/#4-media-serving-strategy-","title":"4. Media Serving Strategy \ud83c\udfac","text":"<p>Optimized streaming with hardware transcoding support.</p>"},{"location":"services/media-services/#serving-components","title":"Serving Components","text":"<ul> <li>Jellyfin: Media server</li> <li>Client devices: Playback</li> </ul>"},{"location":"services/media-services/#streaming-flow","title":"Streaming Flow","text":"<pre><code>graph TD\n  A[Client Request] --&gt; B[Format Check]\n  B --&gt; C{Can Direct Play?}\n  C --&gt; | Yes | D[Direct Play&lt;br/&gt;Original Format&lt;br/&gt;No Processing] |\n  C --&gt; | No | E{Can Direct Stream?} |\n  E --&gt; | Yes | F[Direct Stream&lt;br/&gt;Remux Container&lt;br/&gt;No Re-encoding] |\n  E --&gt; | No | G[Transcode&lt;br/&gt;Re-encode&lt;br/&gt;Server Processing] |\n  D --&gt; H[Bitstreaming Supported?]\n  F --&gt; H\n  H --&gt; | Yes | I[Hardware Passthrough] |\n  H --&gt; | No | J[Software Decode] |</code></pre>"},{"location":"services/media-services/#service-details","title":"Service Details","text":""},{"location":"services/media-services/#jellyfin","title":"Jellyfin","text":"<p>Open-source media server for streaming content.</p>"},{"location":"services/media-services/#jellyfin-features","title":"Jellyfin Features","text":"<ul> <li>No subscription required</li> <li>Hardware acceleration support (Intel QuickSync via <code>/dev/dri/renderD128</code>)</li> <li>Multiple client apps</li> <li>Live TV and DVR support</li> <li>Mobile sync</li> </ul> View Jellyfin Hardware Acceleration Config <p>Jellyfin is configured with Intel GPU hardware acceleration:</p> YAML<pre><code># Volume mount for GPU access\nvolumeMounts:\n  - name: \"render-device\"\n    mountPath: \"/dev/dri/renderD128\"\n\nvolumes:\n  - name: \"render-device\"\n    hostPath:\n      path: \"/dev/dri/renderD128\"\n\n# Security context for device access\nsecurityContext:\n  privileged: true\n  supplementalGroups:\n    - 992  # render group\n</code></pre> <p>This configuration enables: - Intel QuickSync hardware transcoding - Reduced CPU usage during transcoding - Support for multiple concurrent streams - Faster transcoding speeds</p>"},{"location":"services/media-services/#sonarr","title":"Sonarr","text":"<p>TV series management and automation.</p>"},{"location":"services/media-services/#sonarr-features","title":"Sonarr Features","text":"<ul> <li>Automatic episode downloading</li> <li>Quality management</li> <li>Calendar integration</li> <li>Series monitoring</li> <li>Upgrade management</li> </ul>"},{"location":"services/media-services/#radarr","title":"Radarr","text":"<p>Movie management and automation.</p>"},{"location":"services/media-services/#radarr-features","title":"Radarr Features","text":"<ul> <li>Automatic movie downloading</li> <li>Quality profiles</li> <li>Release monitoring</li> <li>Upgrade system</li> <li>List integration</li> </ul>"},{"location":"services/media-services/#prowlarr","title":"Prowlarr","text":"<p>Indexer manager and proxy.</p>"},{"location":"services/media-services/#prowlarr-features","title":"Prowlarr Features","text":"<ul> <li>Centralized indexer management</li> <li>Automatic synchronization</li> <li>Statistics tracking</li> <li>History logging</li> </ul>"},{"location":"services/media-services/#transmission","title":"Transmission","text":"<p>Lightweight BitTorrent client.</p>"},{"location":"services/media-services/#transmission-features","title":"Transmission Features","text":"<ul> <li>Web interface</li> <li>RSS feed support</li> <li>Bandwidth management</li> <li>Ratio limits</li> <li>Peer exchange</li> </ul>"},{"location":"services/media-services/#flaresolverr","title":"FlareSolverr","text":"<p>Proxy server to bypass Cloudflare protection.</p>"},{"location":"services/media-services/#flaresolverr-features","title":"FlareSolverr Features","text":"<ul> <li>CAPTCHA solving</li> <li>JavaScript rendering</li> <li>Cookie management</li> <li>Session handling</li> </ul>"},{"location":"services/media-services/#scraparr","title":"Scraparr","text":"<p>Metadata scraping service.</p>"},{"location":"services/media-services/#scraparr-features","title":"Scraparr Features","text":"<ul> <li>IMDb scraping</li> <li>TMDB integration</li> <li>Automatic metadata updates</li> <li>Prometheus metrics</li> </ul>"},{"location":"services/media-services/#storage","title":"Storage","text":"<p>All media services share a common PVC:</p> View HTPC Storage Configuration YAML<pre><code>---\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: htpc-pvc\nspec:\n  storageClassName: local-path-htpc\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 500Gi\n</code></pre> <p>Storage Details:</p> <ul> <li>htpc-pvc: 500Gi shared persistent volume</li> <li>Storage Class: <code>local-path-htpc</code> (stores at <code>/opt/cluster/htpc</code>)</li> <li>Access Mode: ReadWriteOnce (single node access)</li> <li>Usage: Media library and application data</li> </ul> <p>Directory Structure:</p> Text Only<pre><code>/opt/cluster/htpc/\n\u251c\u2500\u2500 jellyfin/config/     # Jellyfin configuration\n\u251c\u2500\u2500 sonarr/config/       # Sonarr configuration\n\u251c\u2500\u2500 radarr/config/       # Radarr configuration\n\u251c\u2500\u2500 prowlarr/config/     # Prowlarr configuration\n\u251c\u2500\u2500 transmission/        # Download client data\n\u2514\u2500\u2500 data/media/          # Shared media library\n    \u251c\u2500\u2500 tv/              # TV shows\n    \u2514\u2500\u2500 movies/          # Movies\n</code></pre> <p>Performance Characteristics:</p> <ul> <li>High throughput for large sequential files</li> <li>Optimized for streaming workloads</li> <li>Local disk performance</li> </ul>"},{"location":"services/media-services/#monitoring","title":"Monitoring","text":""},{"location":"services/media-services/#grafana-dashboard","title":"Grafana Dashboard","text":"<p>The HTPC dashboard monitors:</p> <ul> <li>Service health</li> <li>Error rates</li> <li>Resource usage</li> <li>Download queue</li> <li>Library stats</li> </ul>"},{"location":"services/media-services/#metrics","title":"Metrics","text":"<ul> <li>Download speed</li> <li>Queue size</li> <li>Disk usage</li> <li>API response times</li> <li>Error rates</li> </ul>"},{"location":"services/media-services/#related-documentation","title":"Related Documentation","text":"<ul> <li>Hardware Setup - Client configuration</li> <li>Architecture: Storage</li> <li>Architecture: Observability</li> </ul>"},{"location":"services/media-services/#abbreviations","title":"Abbreviations","text":""},{"location":"services/observability-stack/","title":"Observability Stack","text":"<p>The observability stack provides comprehensive monitoring, logging, and tracing capabilities.</p>"},{"location":"services/observability-stack/#service-overview","title":"Service Overview","text":"Logo Service Description Version Prometheus Metrics Collection Latest Grafana Visualization (kube-prometheus-stack) Loki Log Aggregation Latest Jaeger Distributed Tracing Latest Alloy OpenTelemetry Collector Latest"},{"location":"services/observability-stack/#prometheus","title":"Prometheus","text":"<p>Metrics collection and time-series database.</p>"},{"location":"services/observability-stack/#features","title":"Features","text":"<ul> <li>Service discovery</li> <li>PromQL query language</li> <li>AlertManager integration</li> <li>Long-term storage</li> </ul> <p>Learn more \u2192</p>"},{"location":"services/observability-stack/#grafana","title":"Grafana","text":"<p>Visualization and dashboard platform.</p>"},{"location":"services/observability-stack/#pre-configured-dashboards","title":"Pre-configured Dashboards","text":"<ul> <li>ArgoCD Operations</li> <li>cert-manager Status</li> <li>Kubernetes Cluster</li> <li>Loki Logs</li> <li>Scraparr Metrics</li> <li>HTPC Services</li> <li>System Health</li> <li>Media Status</li> <li>Application Metrics</li> </ul>"},{"location":"services/observability-stack/#access","title":"Access","text":"Bash<pre><code>kubectl port-forward -n infra svc/grafana 3000:80\n</code></pre> <p>Default: <code>admin</code> / <code>admin</code> (change on first login)</p>"},{"location":"services/observability-stack/#loki","title":"Loki","text":"<p>Log aggregation system.</p>"},{"location":"services/observability-stack/#loki-features","title":"Loki Features","text":"<ul> <li>Label-based queries</li> <li>LogQL query language</li> <li>Integration with Grafana</li> <li>Efficient storage</li> </ul>"},{"location":"services/observability-stack/#jaeger","title":"Jaeger","text":"<p>Distributed tracing platform.</p>"},{"location":"services/observability-stack/#jaeger-capabilities","title":"Jaeger Capabilities","text":"<ul> <li>Request flow visualization</li> <li>Latency analysis</li> <li>Error tracking</li> <li>Service dependencies</li> </ul>"},{"location":"services/observability-stack/#alloy","title":"Alloy","text":"<p>OpenTelemetry collector for logs and traces.</p>"},{"location":"services/observability-stack/#alloy-features","title":"Alloy Features","text":"<ul> <li>Log collection</li> <li>Trace collection</li> <li>Pipeline processing</li> <li>Service discovery</li> </ul>"},{"location":"services/observability-stack/#related-documentation","title":"Related Documentation","text":"<ul> <li>Architecture: Observability</li> <li>Configuration</li> </ul>"},{"location":"services/observability-stack/#abbreviations","title":"Abbreviations","text":""},{"location":"services/personal-cloud/","title":"Personal Cloud Services","text":"<p>Personal cloud applications for file management, photos, recipes, and service dashboard.</p> <pre><code>graph TB\n    subgraph \"Dashboard\"\n        HP[Homepage&lt;br/&gt;Service Dashboard]\n    end\n\n    subgraph \"File Management\"\n        NC[Nextcloud&lt;br/&gt;Files &amp; Collaboration]\n        NCDB[(PostgreSQL)]\n        NCRD[Redis Cache]\n        NC --&gt; NCDB\n        NC --&gt; NCRD\n    end\n\n    subgraph \"Photo Management\"\n        IM[Immich&lt;br/&gt;Photos &amp; Videos]\n        IMDB[(PostgreSQL)]\n        IMVK[Valkey Cache]\n        IMML[ML Service]\n        IM --&gt; IMDB\n        IM --&gt; IMVK\n        IM --&gt; IMML\n    end\n\n    subgraph \"Recipe Management\"\n        TD[Tandoor&lt;br/&gt;Recipes]\n        TDDB[(PostgreSQL)]\n        TD --&gt; TDDB\n    end\n\n    HP -.links to.-&gt; NC\n    HP -.links to.-&gt; IM\n    HP -.links to.-&gt; TD\n\n    style HP fill:#4caf50\n    style NC fill:#0082c9\n    style IM fill:#4250af\n    style TD fill:#ff6b35</code></pre>"},{"location":"services/personal-cloud/#service-overview","title":"Service Overview","text":"Logo Service Description Version Nextcloud File Sync &amp; Share Latest Homepage Service Dashboard Latest Immich Photo Management Latest Tandoor Recipe Management Latest"},{"location":"services/personal-cloud/#nextcloud","title":"Nextcloud","text":"<p>Self-hosted file sync and collaboration platform.</p>"},{"location":"services/personal-cloud/#nextcloud-features","title":"Nextcloud Features","text":"<ul> <li>File synchronization</li> <li>Calendar and contacts</li> <li>Document editing</li> <li>Mobile apps</li> <li>Extensive app ecosystem</li> </ul>"},{"location":"services/personal-cloud/#nextcloud-storage","title":"Nextcloud Storage","text":"View Nextcloud Storage Configuration <p>Storage is distributed across multiple PVCs:</p> <ul> <li>nextcloud-pvc: 31Gi - Main application data</li> <li>nextcloud-redis-pvc: 1Gi - Redis cache persistence</li> <li>PostgreSQL: 10Gi - Database storage (managed by CNPG)</li> </ul> <p>Database Configuration:</p> <ul> <li>Engine: CloudNativePG (PostgreSQL operator)</li> <li>Storage: 10Gi with <code>local-path-utils</code> storage class</li> <li>Backup: 30-day retention with volume snapshots</li> <li>Parameters: <code>max_connections: 100</code>, <code>shared_buffers: 256MB</code></li> </ul> <p>Components:</p> <ul> <li>Nextcloud application pod</li> <li>Redis cache for session and file locking</li> <li>PostgreSQL database cluster</li> <li>Cronjob for background tasks</li> </ul>"},{"location":"services/personal-cloud/#nextcloud-access","title":"Nextcloud Access","text":"<p>Via Traefik ingress with TLS</p>"},{"location":"services/personal-cloud/#homepage","title":"Homepage","text":"<p>Customizable service dashboard.</p>"},{"location":"services/personal-cloud/#homepage-features","title":"Homepage Features","text":"<ul> <li>Service status widgets</li> <li>System metrics</li> <li>Docker integration</li> <li>Kubernetes integration</li> <li>Weather widgets</li> </ul>"},{"location":"services/personal-cloud/#homepage-configuration","title":"Homepage Configuration","text":"<p>Configured via ConfigMaps and supports dynamic service discovery.</p> <p>Features:</p> <ul> <li>Kubernetes service discovery</li> <li>Widget-based layout</li> <li>Health status monitoring</li> <li>Custom bookmarks</li> <li>Weather and time widgets</li> </ul> <p>Configuration Location: <code>base/utils/homepage/</code></p> <p>Access: Serves as the main landing page with links to all services</p>"},{"location":"services/personal-cloud/#immich","title":"Immich","text":"<p>High-performance photo and video management solution.</p>"},{"location":"services/personal-cloud/#immich-features","title":"Immich Features","text":"<ul> <li>Mobile apps (iOS/Android)</li> <li>ML-powered search</li> <li>Facial recognition</li> <li>Location tracking</li> <li>Timeline view</li> <li>Shared albums</li> </ul>"},{"location":"services/personal-cloud/#immich-storage","title":"Immich Storage","text":"View Immich Storage Configuration YAML<pre><code># Immich PVCs from base/utils/persistent-volume-claim.yaml\n\n# Media Library\n- name: immich-library-pvc\n  storage: 20Gi\n  storageClass: local-path-utils\n\n# Valkey Cache\n- name: immich-valkey-pvc\n  storage: 5Gi\n  storageClass: local-path-utils\n\n# ML Models Cache\n- name: immich-ml-cache-pvc\n  storage: 10Gi\n  storageClass: local-path-utils\n\n# PostgreSQL Database (managed by CNPG)\n# Configured in base/utils/immich/postgres-cluster.yaml\n</code></pre> <p>Total Storage: 35Gi+ (library, cache, ML models, database)</p> <p>Database: CloudNativePG-managed PostgreSQL cluster</p>"},{"location":"services/personal-cloud/#immich-components","title":"Immich Components","text":"<ul> <li>Web interface</li> <li>Mobile apps</li> <li>ML service</li> <li>Valkey cache</li> </ul>"},{"location":"services/personal-cloud/#tandoor","title":"Tandoor","text":"<p>Recipe management and meal planning.</p>"},{"location":"services/personal-cloud/#tandoor-features","title":"Tandoor Features","text":"<ul> <li>Recipe organization</li> <li>Shopping lists</li> <li>Meal planning</li> <li>Multi-user support</li> <li>Import from websites</li> <li>Nutrition tracking</li> </ul>"},{"location":"services/personal-cloud/#tandoor-storage","title":"Tandoor Storage","text":"View Tandoor Storage Configuration <ul> <li>tandoor-data-pvc: 20Gi - Application data (media, static files)</li> <li>PostgreSQL: Managed by CNPG operator</li> <li>Storage Class: <code>local-path-utils</code></li> </ul> <p>Components:</p> <ul> <li>Tandoor application pod</li> <li>PostgreSQL database cluster (CNPG)</li> <li>Static media storage</li> </ul>"},{"location":"services/personal-cloud/#tandoor-access","title":"Tandoor Access","text":"<p>Web interface via Traefik</p>"},{"location":"services/personal-cloud/#related-documentation","title":"Related Documentation","text":"<ul> <li>Architecture</li> <li>Storage</li> <li>Configuration</li> </ul>"},{"location":"services/personal-cloud/#abbreviations","title":"Abbreviations","text":""}]}